---
title: "Importer et manipuler des donn√©es avec {{< fa brands r-project >}}"
echo: false
number-sections: true
---

::: {.badge}
<a href="https://datalab.sspcloud.fr/launcher/ide/rstudio?autoLaunch=true&init.personalInit=¬´https%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fr-geographie%2Fmain%2Fsspcloud%2Finit.sh¬ª&networking.user.enabled=true&onyxia.friendlyName=¬´rstudio-cours-ENS¬ª" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/Tester%20via%20SSP%20cloud%20-%20SSPCloud?logo=R&labelColor=black&color=%231965b8" alt="Onyxia"></a><br>
:::

<details>
<summary>
D√©rouler les _slides_ ci-dessous ou [cliquer ici](/slides/wrangling.qmd)
pour afficher les slides en plein √©cran.
</summary>


``` {.yaml code-preview="/slides/wrangling.qmd"}
```

</details>


Dans ce deuxi√®me TP,
nous allons apprendre √† importer et
manipuler des donn√©es avec
{{< fa brands r-project >}}. 

Si vous √™tes int√©ress√©s par `Python` {{< fa brands python >}},
une version tr√®s proche de ce TP est disponible dans [mon cours de l'ENSAE](https://pythonds.linogaliana.fr/content/manipulation/02b_pandas_TP.html).


::: {.callout-note}

Certains exemples de code pr√©sentent des annotations sur le c√¥t√©,
passez votre souris dessus pour les afficher, comme ci-dessous

```{r}
#| echo: true
#| output: false
"une annotation explicative m'accompagne √† droite" #<1>
```
1. Je m'affiche quand on passe la souris sur moi üê≠ !

:::

Dans ce chapitre, nous allons principalement utiliser les packages suivants
du `tidyverse`: 

- `readr` pour l'import de donn√©es ;
- `dplyr` pour la manipulation de donn√©es.

::: {.callout-note}

Le `tidyverse` n'est pas le seul √©cosyst√®me complet pour analyser des donn√©es.

N√©anmoins, pour une introduction √† {{< fa brands r-project >}}, c'est 
certainement le plus raisonnable √† adopter. 

Les √©cosyst√®mes
concurrents ou compl√©mentaires (`data.table`, `arrow`, `duckdb`) n√©cessitent
d√©j√† une bonne compr√©hension du `tidyverse` et de ses limites. 

:::

Dans ce tutoriel, nous allons utiliser deux sources de donn√©es :

* Les √©missions de gaz √† effet de serre estim√©es au niveau communal par l'`ADEME`. Le jeu de donn√©es est
disponible sur [data.gouv](https://www.data.gouv.fr/fr/datasets/inventaire-de-gaz-a-effet-de-serre-territorialise/#_)
et requ√™table directement dans {{< fa brands r-project >}} avec
[cet url](https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert) (ce sera l'objet du premier exercice)[^notedownload].
* Id√©alement, on utiliserait directement les donn√©es
[disponibles sur le site de l'Insee](https://www.insee.fr/fr/statistiques/3560121) mais celles-ci n√©cessitent un peu de travail
de nettoyage qui n'entre pas dans le cadre de ce TP. 
Pour faciliter l'import de donn√©es Insee, il est recommand√© d'utiliser les _packages_
[`doremifasol`](https://github.com/InseeFrLab/DoReMIFaSol) et [`insee`](https://github.com/pyr-opendatafr/R-Insee-Data) qui simplifient l'acc√®s aux donn√©es
de l'Insee disponibles sur le site web [insee.fr](https://www.insee.fr/fr/accueil)
ou via des API. 

[^notedownload]: 

  `readr` offre la possibilit√© d'importer des donn√©es directement depuis un url. C'est l'option 
  prise dans ce tutoriel. Si vous pr√©f√®rez, pour des 
  raisons d'acc√®s au r√©seau ou de performance, importer depuis un poste local,
  vous pouvez t√©l√©charger les donn√©es et changer
  les commandes d'import avec le chemin ad√©quat plut√¥t que l'url. 


# Etapes pr√©liminaires: installer les _packages_

{{< fa brands r-project >}} est un langage _open source_. N'importe qui peut
donc proposer du code {{< fa brands r-project >}} pour accro√Ætre les 
fonctionnalit√©s du langage. Un ensemble coh√©rent de fonctionnalit√©s s'appelle
une __librairie__ ou un __package__. 

Comme l'√©quipe qui g√®re le langage {{< fa brands r-project >}} n'a pas vocation
√† int√©grer toutes les librairies dans le langage de base (celui-ci se doit
de rester, comme son nom l'indique, basique), il existe des espaces
communautaires o√π les gens peuvent mettre √† disposition leurs _packages_. Dans
l'√©cosyst√®me {{< fa brands r-project >}}, les deux principaux[^bioconductor] sont:

- Le `CRAN` (_Comprehensive R Archive Network_): le d√©p√¥t officiel et historique
de librairies {{< fa brands r-project >}}.
Pour installer un _package_ stock√© dans cet espace, on utilise `install.package` ;
- `Github` {{< fa brands github >}}: le r√©seau social du code _open source_. 
Pour installer un _package_ stock√© dans cet espace, on utilise `remotes::install_github`[^remotes]

[^bioconductor]: Il existe √©galement `bioconductor` mais celui-ci √©tant surtout orient√© biostatistiques (une des communaut√©s acad√©miques ayant adopt√© {{< fa brands r-project >}} le plus t√¥t), nous ne l'utilisons pas vraiment

[^remotes]:
    `remotes::install_github` signifie d'utiliser la fonction `install_github` du _package_ `remotes`. Autrement dit, il faut un _package_ pour installer d'autres _packages_ ü§Ø.
    C'est parce que `Github` n'existait pas lors de la cr√©ation de {{< fa brands r-project >}} (ann√©es 1990) et que cette fonctionnalit√© n'a pas √©t√© ajout√© depuis. 

::: {.callout-note}

En g√©n√©ral, les _packages_ avec une certaine
maturit√© sont sur le CRAN. `Github` a un aspect plus fourre-tout o√π on trouve
des mines d'or √† c√¥t√© de choses de qualit√© plus variable. 

Certains _packages_ que nous verrons ne sont pas sur le CRAN car la proc√©dure
de validation pour pouvoir y d√©poser son _package_ est assez lourde et
fatiguante pour des d√©veloppeurs b√©n√©voles, g√©n√©ralement non r√©mun√©r√© 
pour ce travail et qui effectuent souvent cela la nuit. 

:::

Nous allons supposer que les principales librairies du `tidyverse` sont
d√©j√† install√©es. Sinon, vous pouvez les installer en suivant la documentation
en ligne. 

Pour installer un package disponible sur le CRAN, par exemple
le package [`insee`](https://cran.r-project.org/web/packages/insee/index.html),
vous pouvez faire:

```{r}
#| eval: false
#| echo: true
install.packages("insee")
```

Pour installer un package disponible sur `Github` {{< fa brands github >}},
par exemple [`doremifasol`](https://github.com/InseeFrLab/DoReMIFaSol)
qui est disponible sur le d√©p√¥t du compte `InseeFrLab`, on fait:


```{r}
#| eval: false
#| echo: true
remotes::install_github('inseefrlab/DoReMIFaSol')
```

# Importer les donn√©es

## Import d'un csv de l'Ademe

Pour commencer, nous allons importer les donn√©es de l'Ademe √† l'aide du
_package_ [`readr`](https://readr.tidyverse.org/)[^readcsv]. 

::: {.callout-tip}
## Exercice 1: lire un csv avec `readr` et observer les donn√©es

Voici l'URL sur lequel les donn√©es sont disponibles

```{r}
#| echo: true
url <- "https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert"
```


1. Utiliser le _package_  `readr` pour importer ces donn√©es. Nommer cet objet `emissions`[^nomdf]
2. Afficher les premi√®res lignes avec `head` et observer la diff√©rence d'affichage avec, par exemple,
ce `dataframe`:

```{r}
#| echo: true
library(readr)
emissions <- read_csv(url)
```

```{r}
#| echo: true
data.frame(
  "com" = c(1,2),
  "val" = rnorm(2)
)
```

3. Afficher la classe de `emissions`. Comprenez-vous maintenant pourquoi cet objet est un
peu diff√©rent d'un dataframe de base ?
4. Utiliser les fonctions ad√©quates pour les 10 premi√®res valeurs, les 15 derni√®res et un √©chantillon al√©atoire de 10 valeurs gr√¢ce √† la [fonction ad√©quate du package `dplyr`](https://dplyr.tidyverse.org/reference/sample_n.html)

<details>
<summary>
En cas de blocage √† la question 1
</summary>
Lire la documentation de `read_csv` (tr√®s bien faite) ou chercher des exemples
en ligne pour d√©couvrir cette fonction.
‚ö†Ô∏è Ne pas utiliser `read.csv` (fonction de base) qui n'est pas performante. 
</details>
:::

[^nomdf]: Par manque d'imagination, on est souvent tent√© d'appeler notre
_dataframe_ principal `df` ou `data`. C'est souvent une mauvaise id√©e puisque
ce nom n'est pas tr√®s informatif quand on relit le code quelques semaines
plus tard. L'autodocumentation, approche qui consiste √† avoir un code
qui se comprend de lui-m√™me, est une bonne pratique et il est donc recommand√©
de donner un nom simple mais efficace pour conna√Ætre la nature du _dataset_ en question.

## Import de donn√©es de l'Insee

En ce qui concerne nos informations communales, on va utiliser l'une des plus
sources de l'Insee les plus utilis√©es : les donn√©es [`Filosofi`](https://www.insee.fr/fr/metadonnees/source/serie/s1172). 
Afin de faciliter la r√©cup√©ration de celles-ci, nous allons
utiliser le _package_ communautaire `doremifasol` :

```{r}
#| output: false
#| echo: true
library(doremifasol)
library(tibble)
filosofi <- as_tibble(
  telechargerDonnees("FILOSOFI_COM", date = 2016)
)
head(filosofi)
```

```{r}
#| echo: false
head(filosofi)
```

::: {.callout-note}
La fonction `as_tibble` nous sert √† transformer le _dataframe_ de base (`doremifasol` 
ne fait pas d'_a priori_ sur l'√©cosyst√®me de manipulation adopt√©) en 
_dataframe_ adapt√© √† une exploitation via le `tidyverse`. 
:::


:::{.callout-tip}
## Exercice 2

Comme c'est `readr` ou `doremifasol` qui ont
g√©r√© automatiquement l'import des donn√©es, on va faire un petit
contr√¥le qualit√©:

1. Afficher le nom des colonnes de nos _dataframes_ `emissions` et `filosofi`. 
Quelles sont les colonnes communes ? Utiliser la fonction `intersect` et comprendre
la nature du probl√®me.
2. Observer la structure de nos jeux de donn√©es (les types des colonnes). Les types fix√©s par d√©faut sont-ils ad√©quats ?

```{r}
#| output: false
str(filosofi)
str(emissions)
intersect(colnames(filosofi), colnames(emissions))
```


Ensuite, on v√©rifie les dimensions des `DataFrames` et la structure de certaines variables cl√©s.
En l'occurrence, les variables fondamentales pour lier nos donn√©es sont les variables communales.
Ici, on a deux variables g√©ographiques: un code commune et un nom de commune. 
On va donc v√©rifier qu'elles sont bien adapt√©es √† l'analyse statistique.

3. V√©rifier les dimensions des _dataframes_ ;
4. V√©rifier le nombre de valeurs uniques des variables g√©ographiques dans chaque base. Les r√©sultats apparaissent-ils coh√©rents ?
5. Identifier dans `filosofi` les noms de communes qui correspondent √† plusieurs codes communes et s√©lectionner leurs codes. En d'autres termes, identifier les `CODGEO` tels qu'il existe des doublons de `LIBGEO` et les stocker dans un dataframe `duplicates`

On se focalise temporairement sur les observations o√π le libell√© comporte plus de deux codes communes diff√©rents

6. Regarder dans `filosofi` ces observations. Pour mieux y voir, r√©ordonner la base obtenue par order alphab√©tique
7. D√©terminer la taille moyenne (variable nombre de personnes: `NBPERSMENFISC16`) et quelques statistiques descriptives de ces donn√©es.
Comparer aux m√™mes statistiques sur les donn√©es o√π libell√©s et codes communes co√Øncident
8. V√©rifier les grandes villes (plus de 100 000 personnes),
la proportion de villes pour lesquelles un m√™me nom est associ√© √† diff√©rents codes commune.
9. V√©rifier dans `filosofi` les villes dont le libell√© est √©gal √† Montreuil.
V√©rifier √©galement celles qui contiennent le terme 'Saint-Denis'

```{r}
#| output: false

library(dplyr)

# Question 4
emissions %>%
  select('INSEE commune', 'Commune') %>%
  summarize(Unique_Count = n_distinct(Commune))

filosofi %>%
  select('CODGEO', 'LIBGEO') %>%
  summarize(Unique_Count = n_distinct(LIBGEO))

# Question 5
duplicates <- filosofi %>%
  group_by(LIBGEO) %>%
  summarize(Count = n()) %>%
  select(LIBGEO, Count) %>%
  #arrange(desc(Count)) %>%
  filter(Count > 1)

# Question 6
filosofi %>%
  filter(LIBGEO %in% duplicates$LIBGEO) %>%
  arrange(LIBGEO)

# Question 7
filosofi %>%
  filter(LIBGEO %in% duplicates$LIBGEO) %>%
  summarize(Stats = mean(NBPERSMENFISC16, na.rm = TRUE))

# Calculate summary statistics for 'NBPERSMENFISC16' for rows where 'LIBGEO' is not in 'x$LIBGEO'
filosofi %>%
  filter(!(LIBGEO %in% duplicates$LIBGEO)) %>%
  summarize(Stats = mean(NBPERSMENFISC16, na.rm = TRUE))
```


```{r}
#| output: false
# Question 8
filosofi_big <- filosofi %>%
  filter(NBPERSMENFISC16 > 100000) %>%
  mutate(probleme = LIBGEO %in% duplicates$LIBGEO)

# Proportion de villes √† probl√®me
mean_probleme <- filosofi_big %>%
  summarize(mean(probleme))

# Filter rows where 'probleme' is TRUE
df_probleme <- filosofi_big %>%
  filter(probleme)
```

<details>
<summary>
Ce que vous devriez trouver dans les questions 8 et 9
</summary>

Pour la question 8, vous devriez obtenir ceci:


```{r}
head(df_probleme)
```

Alors que pour la question 9, vos deux _dataframes_ ressembleront √†


```{r}
# Question 9
filosofi %>%
  filter(LIBGEO == 'Montreuil')

# Question 10
filosofi %>%
  filter(grepl('Saint-Denis', LIBGEO)) %>%
  head(10)
```
</details>

:::

Ce petit exercice permet de se rassurer car les libell√©s dupliqu√©s
sont en fait des noms de commune identiques mais qui ne sont pas dans le m√™me d√©partement.
Il ne s'agit donc pas d'observations dupliqu√©es.
On se fiera ainsi aux codes communes, qui eux sont uniques.


::: {.callout-tip}
## Exercice 3

On va commencer l'exploration de donn√©es. Cela implique un peu de
nettoyage de donn√©es en amont. 

1. Renommer la variable `INSEE commune` en `code_insee`[^espace]. 
2. Les deux premiers chiffres des codes communes sont le num√©ro de d√©partement.
Cr√©er une variable de d√©partement `dep` dans `emissions` et dans `filosofi`
en utilisant la fonction `str_sub` du package `stringr`[^stringr].

Commen√ßons le calcul de nos premi√®res statistiques descriptives. 

3. Calculer les √©missions totales par secteur pour chaque d√©partement.
Mettre en _log_ ces r√©sultats dans un objet `emissions_log`.
La @fig-sample-log illustre la structure de ces √©missions sur 5 d√©partements
al√©atoires. 

4. Repartir du jeu de donn√©es `emissions`.
Calculer les √©missions totales par d√©partement et sortir la liste
des 10 principaux √©metteurs de CO2 et des 5 d√©partements les moins √©metteurs.
Sans faire de *merge*,
regarder les caract√©ristiques de ces d√©partements (population et niveau de vie)

[^stringr]: Les fonctionnalit√©s limit√©es du langage de base sur la manipulation
textuelle sont rapidement contraignantes. On passe ainsi rapidement √† `stringr`
m√™me si ce n'est pas l'objet principal du chapitre. 

```{r}
#| output: false
library(stringr)

emissions <- emissions %>%
  rename('code_insee' = `INSEE commune`)

emissions <- emissions %>%
  mutate(dep = str_sub(code_insee, start = 1, end = 2))
filosofi <- filosofi %>%
  mutate(dep = str_sub(CODGEO, start = 1, end = 2))
```

```{r}
#| label: question 3 exo 3
#| output: false
emissions_log <- emissions %>%
    group_by(dep) %>%
    summarise(across(where(is.numeric), sum, na.rm = TRUE)) %>%
    mutate(across(where(is.numeric), log))
```

```{r}
#| output: false

# Question 5

## Emissions totales par d√©partement
emissions_dep <- emissions %>%
  mutate(total = rowSums(pick(where(is.numeric)), na.rm = TRUE)) %>%
  group_by(dep) %>%
  summarise(total = sum(total))
gros_emetteurs <- emissions_dep %>%
  arrange(desc(total)) %>%
  head(10)
petits_emetteurs <- emissions_dep %>%
  arrange(total) %>%
  head(5)

## Caract√©ristiques de ces d√©partements dans filosofi
gros_emetteurs_filosofi <- filosofi %>%
  filter(dep %in% gros_emetteurs$dep) %>%
  group_by(dep) %>%
  summarise(across(c('NBPERSMENFISC16','MED16'), \(x) mean(x, na.rm = TRUE)))

head(gros_emetteurs_filosofi)
```


```{r}
#| echo: true
#| fig-cap: Structure des √©missions de cinq d√©partements al√©atoires
#| label: fig-sample-log
library(tidyr)
library(ggplot2)

emissions_log_sample <- emissions_log %>%
  filter(dep %in% sample(unique(dep),5))

emissions_log_sample <- emissions_log_sample %>%
  pivot_longer(cols = -dep, names_to = "Category", values_to = "Value")

ggplot(emissions_log_sample, aes(x = dep, y = Value, fill = Category)) +
    geom_bar(stat = "identity") +
    labs(x = "Department", y = "Value") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + scale_fill_viridis_d()
```


<details>
<summary>
Exemple d'utilisation de `str_sub`
</summary>
```r
library(stringr)
df %>% mutate(x = str_sub(y, start = 3, end = 5))
```

</details>

:::

[^espace]: L'espace dans le nom de la variable est emb√™tant. Pour pouvoir
utiliser le nom de cet variable dans `rename`, il va falloir utiliser
des backticks, c'est-√†-dire ` INSEE commune `.


# Restructurer des donn√©es

On pr√©sente g√©n√©ralement deux types de donn√©es : 
    
* format __wide__: les donn√©es comportent des observations r√©p√©t√©es, pour un m√™me individu (ou groupe), dans des colonnes diff√©rentes 
* format __long__: les donn√©es comportent des observations r√©p√©t√©es, pour un m√™me individu, dans des lignes diff√©rentes avec une colonne permettant de distinguer les niveaux d'observations

Un exemple de la distinction entre les deux peut √™tre pris √† l'ouvrage de r√©f√©rence d'Hadley Wickham, *R for Data Science*:

![](https://d33wubrfki0l68.cloudfront.net/3aea19108d39606bbe49981acda07696c0c7fcd8/2de65/images/tidy-9.png)

On est souvent amen√© avec {{< fa brands r-project >}} √† restructurer les donn√©es
pour les allonger (_wide to long_) et les √©largir (_long to wide_).
C'est le package _tidyr_ (qui appartient au _tidyverse_) qui permet
de faire ce type de transformations. 
L'aide m√©moire suivante aidera √† se rappeler les fonctions √† appliquer si besoin:

![](https://scienceparkstudygroup.github.io/r-lesson-based-on-ohi-data-training/img/rstudio-cheatsheet-spread-gather-sep-unite.png){width="80%" fig-align="center"}

Le fait de passer d'un format *wide* au format *long* (ou vice-versa)
peut √™tre extr√™mement pratique car certaines fonctions sont plus ad√©quates sur une forme de donn√©es ou sur l'autre.
En r√®gle g√©n√©rale, les formats *long* sont souvent pr√©f√©rables. C'est notamment
la forme de donn√©es privil√©gi√©e pour pr√©parer des graphiques avec `ggplot`, 
que nous verrons dans le prochain chapitre. 


:::{.callout-tip}
## Exercice 4
1. Restructurer les donn√©es au format *long* pour avoir des donn√©es d'√©missions par secteur en gardant comme niveau d'analyse la commune (attention aux autres variables identifiantes).
2. Faire la somme par secteur et repr√©senter graphiquement un _barplot_[^barplot] 
3. Garder, pour chaque d√©partement, le secteur le plus polluant

[^barplot]: vous pouvez
utiliser directement le morceau de code d'aide si vous n'√™tes pas familiers de `ggplot`

```{r}
library(tidyr)

# Question 1
df_long <- emissions %>%
  pivot_longer(cols = -c(code_insee, Commune, dep),
               names_to = "secteur",
               values_to = "emissions")

# Question 2
df_long_summary <- df_long %>%
  group_by(secteur) %>% summarise(emissions = sum(emissions, na.rm = TRUE))

# Question 3

```

<details>
<summary>Graphique √† r√©aliser pour la question 2</summary>

```{r}
#| echo: true
ggplot(df_long_summary) +
  geom_bar(
    aes(y = secteur, x = emissions),
    stat ='identity'
  )
```

</details>

```{r}
df_long_dep <- df_long %>%
  group_by(secteur, dep) %>%
  summarise(emissions = sum(emissions, na.rm = TRUE)) %>%
  arrange(desc(dep), desc(emissions)) %>%
  group_by(dep) %>%
  slice_head(n = 1)

head(df_long_dep)
```

:::



