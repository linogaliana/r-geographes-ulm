---
title: "Importer et manipuler des donn√©es avec {{< fa brands r-project >}}"
echo: false
number-sections: true
---

::: {.badge}
<a href="https://datalab.sspcloud.fr/launcher/ide/rstudio?autoLaunch=true&init.personalInit=¬´https%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fr-geographie%2Fmain%2Fsspcloud%2Finit.sh¬ª&networking.user.enabled=true&onyxia.friendlyName=¬´rstudio-cours-ENS¬ª" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/Tester%20via%20SSP%20cloud%20-%20SSPCloud?logo=R&labelColor=black&color=%231965b8" alt="Onyxia"></a><br>
:::

Dans ce deuxi√®me TP,
nous allons apprendre √† importer et
manipuler des donn√©es avec
{{< fa brands r-project >}}. 

Si vous √™tes int√©ress√©s par `Python` {{< fa brands python >}},
une version tr√®s proche de ce TP est disponible dans [mon cours de l'ENSAE](https://pythonds.linogaliana.fr/content/manipulation/02b_pandas_TP.html).


::: {.callout-note}

Certains exemples de code pr√©sentent des annotations sur le c√¥t√©,
passez votre souris dessus pour les afficher, comme ci-dessous

```{r}
#| echo: true
#| output: false
"une annotation explicative m'accompagne √† droite" #<1>
```
1. Je m'affiche quand on passe la souris sur moi üê≠ !

:::

Dans ce chapitre, nous allons principalement utiliser les packages suivants
du `tidyverse`: 

- `readr` pour l'import de donn√©es ;
- `dplyr` pour la manipulation de donn√©es.

::: {.callout-note}

Le `tidyverse` n'est pas le seul √©cosyst√®me complet pour analyser des donn√©es.

N√©anmoins, pour une introduction √† {{< fa brands r-project >}}, c'est 
certainement le plus raisonnable √† adopter. 

Les √©cosyst√®mes
concurrents ou compl√©mentaires (`data.table`, `arrow`, `duckdb`) n√©cessitent
d√©j√† une bonne compr√©hension du `tidyverse` et de ses limites. 

:::

Dans ce tutoriel, nous allons utiliser deux sources de donn√©es :

* Les √©missions de gaz √† effet de serre estim√©es au niveau communal par l'`ADEME`. Le jeu de donn√©es est
disponible sur [data.gouv](https://www.data.gouv.fr/fr/datasets/inventaire-de-gaz-a-effet-de-serre-territorialise/#_)
et requ√™table directement dans {{< fa brands r-project >}} avec
[cet url](https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert) (ce sera l'objet du premier exercice)[^notedownload].
* Id√©alement, on utiliserait directement les donn√©es
[disponibles sur le site de l'Insee](https://www.insee.fr/fr/statistiques/3560121) mais celles-ci n√©cessitent un peu de travail
de nettoyage qui n'entre pas dans le cadre de ce TP. 
Pour faciliter l'import de donn√©es Insee, il est recommand√© d'utiliser les _packages_
[`doremifasol`](https://github.com/InseeFrLab/DoReMIFaSol) et [`insee`](https://github.com/pyr-opendatafr/R-Insee-Data) qui simplifient l'acc√®s aux donn√©es
de l'Insee disponibles sur le site web [insee.fr](https://www.insee.fr/fr/accueil)
ou via des API. 

[^notedownload]: 

  `readr` offre la possibilit√© d'importer des donn√©es directement depuis un url. C'est l'option 
  prise dans ce tutoriel. Si vous pr√©f√®rez, pour des 
  raisons d'acc√®s au r√©seau ou de performance, importer depuis un poste local,
  vous pouvez t√©l√©charger les donn√©es et changer
  les commandes d'import avec le chemin ad√©quat plut√¥t que l'url. 


# Etapes pr√©liminaires: installer les _packages_

{{< fa brands r-project >}} est un langage _open source_. N'importe qui peut
donc proposer du code {{< fa brands r-project >}} pour accro√Ætre les 
fonctionnalit√©s du langage. Un ensemble coh√©rent de fonctionnalit√©s s'appelle
une __librairie__ ou un __package__. 

Comme l'√©quipe qui g√®re le langage {{< fa brands r-project >}} n'a pas vocation
√† int√©grer toutes les librairies dans le langage de base (celui-ci se doit
de rester, comme son nom l'indique, basique), il existe des espaces
communautaires o√π les gens peuvent mettre √† disposition leurs _packages_. Dans
l'√©cosyst√®me {{< fa brands r-project >}}, les deux principaux[^bioconductor] sont:

- Le `CRAN` (_Comprehensive R Archive Network_): le d√©p√¥t officiel et historique
de librairies {{< fa brands r-project >}}.
Pour installer un _package_ stock√© dans cet espace, on utilise `install.package` ;
- `Github` {{< fa brands github >}}: le r√©seau social du code _open source_. 
Pour installer un _package_ stock√© dans cet espace, on utilise `remotes::install_github`[^remotes]

[^bioconductor]: Il existe √©galement `bioconductor` mais celui-ci √©tant surtout orient√© biostatistiques (une des communaut√©s acad√©miques ayant adopt√© {{< fa brands r-project >}} le plus t√¥t), nous ne l'utilisons pas vraiment

[^remotes]:
    `remotes::install_github` signifie d'utiliser la fonction `install_github` du _package_ `remotes`. Autrement dit, il faut un _package_ pour installer d'autres _packages_ ü§Ø.
    C'est parce que `Github` n'existait pas lors de la cr√©ation de {{< fa brands r-project >}} (ann√©es 1990) et que cette fonctionnalit√© n'a pas √©t√© ajout√© depuis. 

::: {.callout-note}

En g√©n√©ral, les _packages_ avec une certaine
maturit√© sont sur le CRAN. `Github` a un aspect plus fourre-tout o√π on trouve
des mines d'or √† c√¥t√© de choses de qualit√© plus variable. 

Certains _packages_ que nous verrons ne sont pas sur le CRAN car la proc√©dure
de validation pour pouvoir y d√©poser son _package_ est assez lourde et
fatiguante pour des d√©veloppeurs b√©n√©voles, g√©n√©ralement non r√©mun√©r√© 
pour ce travail et qui effectuent souvent cela la nuit. 

:::

Nous allons supposer que les principales librairies du `tidyverse` sont
d√©j√† install√©es. Sinon, vous pouvez les installer en suivant la documentation
en ligne. 

Pour installer un package disponible sur le CRAN, par exemple
le package [`insee`](https://cran.r-project.org/web/packages/insee/index.html),
vous pouvez faire:

```{r}
#| eval: false
#| echo: true
install.packages("insee")
```

Pour installer un package disponible sur `Github` {{< fa brands github >}},
par exemple [`doremifasol`](https://github.com/InseeFrLab/DoReMIFaSol)
qui est disponible sur le d√©p√¥t du compte `InseeFrLab`, on fait:


```{r}
#| eval: false
#| echo: true
remotes::install_github('inseefrlab/DoReMIFaSol')
```

# Importer les donn√©es

## Import d'un csv de l'Ademe

Pour commencer, nous allons importer les donn√©es de l'Ademe √† l'aide du
_package_ [`readr`](https://readr.tidyverse.org/)[^readcsv]. 

::: {.callout-tip}
## Exercice 1: lire un csv avec `readr` et observer les donn√©es

Voici l'URL sur lequel les donn√©es sont disponibles

```{r}
#| echo: true
url <- "https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert"
```


1. Utiliser le _package_  `readr` pour importer ces donn√©es. Nommer cet objet `emissions`[^nomdf]
2. Afficher les premi√®res lignes avec `head` et observer la diff√©rence d'affichage avec, par exemple,
ce `dataframe`:

```{r}
#| echo: true
library(readr)
emissions <- read_csv(url)
```

```{r}
#| echo: true
data.frame(
  "com" = c(1,2),
  "val" = rnorm(2)
)
```

3. Afficher la classe de `emissions`. Comprenez-vous maintenant pourquoi cet objet est un
peu diff√©rent d'un dataframe de base ?
4. Utiliser les fonctions ad√©quates pour les 10 premi√®res valeurs, les 15 derni√®res et un √©chantillon al√©atoire de 10 valeurs gr√¢ce √† la [fonction ad√©quate du package `dplyr`](https://dplyr.tidyverse.org/reference/sample_n.html)

<details>
<summary>
En cas de blocage √† la question 1
</summary>
Lire la documentation de `read_csv` (tr√®s bien faite) ou chercher des exemples
en ligne pour d√©couvrir cette fonction.
‚ö†Ô∏è Ne pas utiliser `read.csv` (fonction de base) qui n'est pas performante. 
</details>
:::

[^nomdf]: Par manque d'imagination, on est souvent tent√© d'appeler notre
_dataframe_ principal `df` ou `data`. C'est souvent une mauvaise id√©e puisque
ce nom n'est pas tr√®s informatif quand on relit le code quelques semaines
plus tard. L'autodocumentation, approche qui consiste √† avoir un code
qui se comprend de lui-m√™me, est une bonne pratique et il est donc recommand√©
de donner un nom simple mais efficace pour conna√Ætre la nature du _dataset_ en question.

## Import de donn√©es de l'Insee

En ce qui concerne nos informations communales, on va utiliser l'une des plus
sources de l'Insee les plus utilis√©es : les donn√©es [`Filosofi`](https://www.insee.fr/fr/metadonnees/source/serie/s1172). 
Afin de faciliter la r√©cup√©ration de celles-ci, nous allons
utiliser le _package_ communautaire `doremifasol` :

```{r}
#| output: false
#| echo: true
library(doremifasol)
library(tibble)
filosofi <- as_tibble(
  telechargerDonnees("FILOSOFI_COM", date = 2016)
)
head(filosofi)
```

```{r}
#| echo: false
head(filosofi)
```

::: {.callout-note}
La fonction `as_tibble` nous sert √† transformer le _dataframe_ de base (`doremifasol` 
ne fait pas d'_a priori_ sur l'√©cosyst√®me de manipulation adopt√©) en 
_dataframe_ adapt√© √† une exploitation via le `tidyverse`. 
:::


:::{.callout-tip}
## Exercice 2

Comme c'est `readr` ou `doremifasol` qui ont
g√©r√© automatiquement l'import des donn√©es, on va faire un petit
contr√¥le qualit√©:

1. Afficher le nom des colonnes de nos _dataframes_ `emissions` et `filosofi`. 
Quelles sont les colonnes communes ? Utiliser la fonction `intersect` et comprendre
la nature du probl√®me.
2. Observer la structure de nos jeux de donn√©es (les types des colonnes). Les types fix√©s par d√©faut sont-ils ad√©quats ?

```{r}
#| output: false
str(filosofi)
str(emissions)
intersect(colnames(filosofi), colnames(emissions))
```


Ensuite, on v√©rifie les dimensions des `DataFrames` et la structure de certaines variables cl√©s.
En l'occurrence, les variables fondamentales pour lier nos donn√©es sont les variables communales.
Ici, on a deux variables g√©ographiques: un code commune et un nom de commune. 
On va donc v√©rifier qu'elles sont bien adapt√©es √† l'analyse statistique.

3. V√©rifier les dimensions des _dataframes_ ;
4. V√©rifier le nombre de valeurs uniques des variables g√©ographiques dans chaque base. Les r√©sultats apparaissent-ils coh√©rents ?
5. Identifier dans `filosofi` les noms de communes qui correspondent √† plusieurs codes communes et s√©lectionner leurs codes. En d'autres termes, identifier les `CODGEO` tels qu'il existe des doublons de `LIBGEO` et les stocker dans un dataframe `duplicates`

On se focalise temporairement sur les observations o√π le libell√© comporte plus de deux codes communes diff√©rents

6. Regarder dans `filosofi` ces observations. Pour mieux y voir, r√©ordonner la base obtenue par order alphab√©tique
7. D√©terminer la taille moyenne (variable nombre de personnes: `NBPERSMENFISC16`) et quelques statistiques descriptives de ces donn√©es.
Comparer aux m√™mes statistiques sur les donn√©es o√π libell√©s et codes communes co√Øncident
8. V√©rifier les grandes villes (plus de 100 000 personnes),
la proportion de villes pour lesquelles un m√™me nom est associ√© √† diff√©rents codes commune.
9. V√©rifier dans `filosofi` les villes dont le libell√© est √©gal √† Montreuil.
V√©rifier √©galement celles qui contiennent le terme 'Saint-Denis'

```{r}
#| output: false

library(dplyr)

# Question 4
emissions %>%
  select('INSEE commune', 'Commune') %>%
  summarize(Unique_Count = n_distinct(Commune))

filosofi %>%
  select('CODGEO', 'LIBGEO') %>%
  summarize(Unique_Count = n_distinct(LIBGEO))

# Question 5
duplicates <- filosofi %>%
  group_by(LIBGEO) %>%
  summarize(Count = n()) %>%
  select(LIBGEO, Count) %>%
  #arrange(desc(Count)) %>%
  filter(Count > 1)

# Question 6
filosofi %>%
  filter(LIBGEO %in% duplicates$LIBGEO) %>%
  arrange(LIBGEO)

# Question 7
filosofi %>%
  filter(LIBGEO %in% duplicates$LIBGEO) %>%
  summarize(Stats = mean(NBPERSMENFISC16, na.rm = TRUE))

# Calculate summary statistics for 'NBPERSMENFISC16' for rows where 'LIBGEO' is not in 'x$LIBGEO'
filosofi %>%
  filter(!(LIBGEO %in% duplicates$LIBGEO)) %>%
  summarize(Stats = mean(NBPERSMENFISC16, na.rm = TRUE))
```

Pour la question 8, vous devriez obtenir ceci:

```{r}
# Question 8
filosofi_big <- filosofi %>%
  filter(NBPERSMENFISC16 > 100000) %>%
  mutate(probleme = LIBGEO %in% duplicates$LIBGEO)

# Proportion de villes √† probl√®me
mean_probleme <- filosofi_big %>%
  summarize(mean(probleme))

# Filter rows where 'probleme' is TRUE
df_probleme <- filosofi_big %>%
  filter(probleme)
```

```{r}
head(df_probleme)
```


```{r}
# Question 9
filosofi %>%
  filter(LIBGEO == 'Montreuil')

# Question 10
filosofi %>%
  filter(grepl('Saint-Denis', LIBGEO)) %>%
  head(10)
```


:::

