[
  {
    "objectID": "exercises/r-wrangling.html",
    "href": "exercises/r-wrangling.html",
    "title": "Importer et manipuler des données avec ",
    "section": "",
    "text": "Dans ce deuxième TP, nous allons apprendre à importer et manipuler des données avec .\nSi vous êtes intéressés par Python , une version très proche de ce TP est disponible dans mon cours de l’ENSAE.\nDans ce chapitre, nous allons principalement utiliser les packages suivants du tidyverse:\nDans ce tutoriel, nous allons utiliser deux sources de données :"
  },
  {
    "objectID": "exercises/r-wrangling.html#import-dun-csv-de-lademe",
    "href": "exercises/r-wrangling.html#import-dun-csv-de-lademe",
    "title": "Importer et manipuler des données avec ",
    "section": "2.1 Import d’un csv de l’Ademe",
    "text": "2.1 Import d’un csv de l’Ademe\nPour commencer, nous allons importer les données de l’Ademe à l’aide du package readr[^readcsv].\n\n\n\n\n\n\nExercice 1: lire un csv avec readr et observer les données\n\n\n\nVoici l’URL sur lequel les données sont disponibles\n\nurl &lt;- \"https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert\"\n\n\nUtiliser le package readr pour importer ces données. Nommer cet objet emissions4\nAfficher les premières lignes avec head et observer la différence d’affichage avec, par exemple, ce dataframe:\n\n\nlibrary(readr)\nemissions &lt;- read_csv(url)\n\nRows: 35798 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): INSEE commune, Commune\ndbl (10): Agriculture, Autres transports, Autres transports international, C...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nAfficher la classe de emissions. Comprenez-vous maintenant pourquoi cet objet est un peu différent d’un dataframe de base ?\nUtiliser les fonctions adéquates pour les 10 premières valeurs, les 15 dernières et un échantillon aléatoire de 10 valeurs grâce à la fonction adéquate du package dplyr\n\n\n\nEn cas de blocage à la question 1\n\nLire la documentation de read_csv (très bien faite) ou chercher des exemples en ligne pour découvrir cette fonction. ⚠️ Ne pas utiliser read.csv (fonction de base) qui n’est pas performante."
  },
  {
    "objectID": "exercises/r-wrangling.html#premières-manipulations-de-données",
    "href": "exercises/r-wrangling.html#premières-manipulations-de-données",
    "title": "Importer et manipuler des données avec ",
    "section": "2.2 Premières manipulations de données",
    "text": "2.2 Premières manipulations de données\nComme c’est évoqué dans utilitR, les principales fonctions de dplyr (les verbes de la grammaire dplyr) sont les suivants:\n\nselect() : sélectionner des variables par leur nom ;\nrename() : renommer des variables ;\nfilter() : sélectionner des observations selon une ou plusieurs conditions ;\narrange() : trier la table selon une ou plusieurs variables ;\nmutate() : ajouter des variables qui sont fonction d’autres variables ;\nsummarise() : calculer une statistique à partir de données ;\ngroup_by() : faire des opérations par groupe.\n\n\nviewof dplyrVerbs = Inputs.select(['select','rename','filter','mutate'], {value: \"select\"})\n\n\n\n\n\n\n\nhtml`&lt;img src=\"img/${dplyrVerbs}.png\"&lt;/&gt;`\n\n\n\n\n\n\nLa cheatsheet suivante est très pratique puisqu’elle illustre ces différentes fonctions. Il est recommandé de régulièrement la consulter (cliquer sur l’image pour zoomer 🔎) :\n\n\n\n\n\n\n\n\n\n\n\nCheatsheets dplyr\n\n\n\n\n\n\n\n\n\nExercice 2: découverte des verbes de dplyr pour manipuler des données\n\n\n\nEn premier lieu, on propose de se familiariser avec les opérations sur les colonnes.\n\nCréer un dataframe emissions_copy ne conservant que les colonnes INSEE commune, Commune, Autres transports et Autres transports international\nComme les noms de variables sont peu pratiques, les renommer de la manière suivante:\n\nINSEE commune \\(\\to\\) code_insee\nAutres transports \\(\\to\\) transports\nAutres transports international \\(\\to\\) transports_international\n\nOn propose, pour simplifier, de remplacer les valeurs manquantes (NA) par la valeur 05. Utiliser la fonction replace_na du package tidyr, en conjonction avec mutate, pour transformer les valeurs manquantes en 0.\nCréer dans la même séquence de code les variables suivantes:\n\ndep: le département. Celui-ci peut être créé grâce aux deux premiers caractères de code_insee avec la fonction str_sub du package stringr6\ntransports_total: les émissions du secteur transports (somme des deux variables)\n\nOrdonner les données de manière décroissante puis ordonner les données de manière décroissante par département (du 01 au 95)."
  },
  {
    "objectID": "exercises/r-wrangling.html#import-de-données-de-linsee",
    "href": "exercises/r-wrangling.html#import-de-données-de-linsee",
    "title": "Importer et manipuler des données avec ",
    "section": "2.3 Import de données de l’Insee",
    "text": "2.3 Import de données de l’Insee\nEn ce qui concerne nos informations communales, on va utiliser l’une des plus sources de l’Insee les plus utilisées : les données Filosofi. Afin de faciliter la récupération de celles-ci, nous allons utiliser le package communautaire doremifasol :\n\nlibrary(doremifasol)\nlibrary(tibble)\nfilosofi &lt;- as_tibble(\n  telechargerDonnees(\"FILOSOFI_COM\", date = 2016)\n)\nhead(filosofi)\n\n\n\n# A tibble: 6 × 29\n  CODGEO LIBGEO      NBMENFISC16 NBPERSMENFISC16  MED16 PIMP16 TP6016 TP60AGE116\n  &lt;chr&gt;  &lt;chr&gt;             &lt;dbl&gt;           &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 01001  L'Abergeme…         313            796. 22679      NA     NA         NA\n2 01002  L'Abergeme…         101            248  24382.     NA     NA         NA\n3 01004  Ambérieu-e…        6363          14228  19721      49     17         19\n4 01005  Ambérieux-…         633           1662. 23378      NA     NA         NA\n5 01006  Ambléon              NA             NA     NA      NA     NA         NA\n6 01007  Ambronay           1087           2684  22146.     57     NA         NA\n# ℹ 21 more variables: TP60AGE216 &lt;dbl&gt;, TP60AGE316 &lt;dbl&gt;, TP60AGE416 &lt;dbl&gt;,\n#   TP60AGE516 &lt;dbl&gt;, TP60AGE616 &lt;dbl&gt;, TP60TOL116 &lt;dbl&gt;, TP60TOL216 &lt;dbl&gt;,\n#   PACT16 &lt;dbl&gt;, PTSA16 &lt;dbl&gt;, PCHO16 &lt;dbl&gt;, PBEN16 &lt;dbl&gt;, PPEN16 &lt;dbl&gt;,\n#   PPAT16 &lt;dbl&gt;, PPSOC16 &lt;dbl&gt;, PPFAM16 &lt;dbl&gt;, PPMINI16 &lt;dbl&gt;, PPLOGT16 &lt;dbl&gt;,\n#   PIMPOT16 &lt;dbl&gt;, D116 &lt;dbl&gt;, D916 &lt;dbl&gt;, RD16 &lt;dbl&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nLa fonction as_tibble nous sert à transformer le dataframe de base (doremifasol ne fait pas d’a priori sur l’écosystème de manipulation adopté) en dataframe adapté à une exploitation via le tidyverse."
  },
  {
    "objectID": "exercises/r-wrangling.html#footnotes",
    "href": "exercises/r-wrangling.html#footnotes",
    "title": "Importer et manipuler des données avec ",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nreadr offre la possibilité d’importer des données directement depuis un url. C’est l’option prise dans ce tutoriel. Si vous préfèrez, pour des raisons d’accès au réseau ou de performance, importer depuis un poste local, vous pouvez télécharger les données et changer les commandes d’import avec le chemin adéquat plutôt que l’url.↩︎\nIl existe également bioconductor mais celui-ci étant surtout orienté biostatistiques (une des communautés académiques ayant adopté  le plus tôt), nous ne l’utilisons pas vraiment↩︎\nremotes::install_github signifie d’utiliser la fonction install_github du package remotes. Autrement dit, il faut un package pour installer d’autres packages 🤯. C’est parce que Github n’existait pas lors de la création de  (années 1990) et que cette fonctionnalité n’a pas été ajouté depuis.↩︎\nPar manque d’imagination, on est souvent tenté d’appeler notre dataframe principal df ou data. C’est souvent une mauvaise idée puisque ce nom n’est pas très informatif quand on relit le code quelques semaines plus tard. L’autodocumentation, approche qui consiste à avoir un code qui se comprend de lui-même, est une bonne pratique et il est donc recommandé de donner un nom simple mais efficace pour connaître la nature du dataset en question.↩︎\nCette hypothèse est certainement fausse. Elle est exclusivement là pour illustrer la création de variables via mutate.↩︎\nPour être vraiment précis, il faudrait modifier les valeurs obtenues pour les départements Corse avec la fonction case_when du package dplyr. Ceci est laissé en exercice supplémentaire.↩︎\nL’espace dans le nom de la variable est embêtant. Pour pouvoir utiliser le nom de cet variable dans rename, il va falloir utiliser des backticks, c’est-à-dire INSEE commune.↩︎\nLes fonctionnalités limitées du langage de base sur la manipulation textuelle sont rapidement contraignantes. On passe ainsi rapidement à stringr même si ce n’est pas l’objet principal du chapitre.↩︎\nvous pouvez utiliser directement le morceau de code d’aide si vous n’êtes pas familiers de ggplot↩︎"
  },
  {
    "objectID": "exercises/ggplot.html",
    "href": "exercises/ggplot.html",
    "title": "Produire des représentations graphiques avec  et ggplot2",
    "section": "",
    "text": "Dans ce troisième TP, nous allons apprendre à créer des représentations graphiques synthétiques avec  qui est très bien outillé dans le domaine grâce à la librairie ggplot2. Cette dernière implémente une grammaire des graphiques flexible, cohérente et simple d’usage.\nSi vous êtes intéressés par Python , une version très proche de ce TP est disponible dans mon cours de l’ENSAE.\nLa pratique de la visualisation se fera, dans ce cours, en répliquant des graphiques qu’on peut trouver sur la page de l’open data de la ville de Paris ici.\nCe TP vise à initier:\nDans ce chapitre, nous allons utiliser les librairies suivantes:\nlibrary(scales)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(forcats)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(plotly)\nNous verrons par la suite la manière de construire des cartes facilement avec des formats équivalents."
  },
  {
    "objectID": "exercises/ggplot.html#données",
    "href": "exercises/ggplot.html#données",
    "title": "Produire des représentations graphiques avec  et ggplot2",
    "section": "1 Données",
    "text": "1 Données\nUn sous-ensemble des données de Paris Open Data a été mis à disposition pour faciliter l’import. Il s’agit d’une extraction, qui commence à dater, des données disponibles sur le site où seules les colonnes qui servent à cet exercice ont été conservées.\nNous proposons de télécharger ces données et les enregistrer dans un fichier sur le disque dur local avant de l’importer1. Cependant, nous n’allons pas faire cela manuellement mais nous allons plutôt utiliser . Effectuer ce type d’action de manière manuelle serait une mauvaise pratique du point de vue de la reproductibilité.\n\nurl &lt;- \"https://minio.lab.sspcloud.fr/projet-formation/diffusion/python-datascientist/bike.csv\"\n1download.file(url, \"bike.gz\")\n\n\n1\n\nL’extension .gz est importante pour la suite car readr en a besoin pour comprendre que le fichier est compressé."
  },
  {
    "objectID": "exercises/ggplot.html#premières-productions-graphiques",
    "href": "exercises/ggplot.html#premières-productions-graphiques",
    "title": "Produire des représentations graphiques avec  et ggplot2",
    "section": "2 Premières productions graphiques",
    "text": "2 Premières productions graphiques\nChercher à produire une visualisation parfaite du premier coup est illusoire. Il est beaucoup plus réaliste d’améliorer graduellement une représentation graphique afin, petit à petit, de mettre en avant les effets de structure dans un jeu de données.\nNous allons donc commencer par nous représenter la distribution des passages aux principales stations de mesure. Pour cela nous allons produire rapidement un barplot puis l’améliorer graduellement.\nDans cette partie, nous allons ainsi reproduire les deux premiers graphiques de la page d’analyse des données: Les 10 compteurs avec la moyenne horaire la plus élevée et Les 10 compteurs ayant comptabilisés le plus de vélos. Les valeurs chiffrées des graphiques seront différentes de celles de la page en ligne, c’est normal, nous travaillons sur des données plus anciennes.\n\n\n\n\n\n\nExercice 1 : Importer les données et produire un premier graphique rapidement\n\n\n\nLes données comportent plusieurs dimensions pouvant faire l’objet d’une analyse statistique. Il est donc nécessaire dans un premier temps de synthétiser celles-ci par des agrégations afin d’avoir un graphique lisible.\n\nImporter les données de compteurs de vélos depuis le fichier bike.gz ;\nGarder les dix bornes à la moyenne la plus élevée ;\n\n\n\nLes 10 principales stations à l’issue de la question 2\n\n\n\n# A tibble: 6 × 2\n  `Nom du compteur`                    `Comptage horaire`\n  &lt;chr&gt;                                             &lt;dbl&gt;\n1 Totem 73 boulevard de Sébastopol S-N               197.\n2 Totem 73 boulevard de Sébastopol N-S               148.\n3 89 boulevard de Magenta NO-SE                      144.\n4 Totem 64 Rue de Rivoli O-E                         140.\n5 102 boulevard de Magenta SE-NO                     137.\n6 72 boulevard Voltaire NO-SE                        124.\n\n\n\nOn va maintenant pouvoir se concentrer sur la production de la représentation\n\nEn premier lieu, sans se préoccuper des éléments de style ni de la beauté du graphique, créer la structure du barplot (diagramme en batons) de la page d’analyse des données:\n\n\n\nFigure obtenue, sans s’occuper du style\n\n\n\n\n\n\n\nLa suite de l’exercice consiste à améliorer graduellement cette représentation pour converger vers la reproduction de la version en open data. Il ne s’agit pas encore de se concentrer sur l’esthétique de la figure mais de la rendre intelligible, à gros trait.\n\nEn premier lieu, réordonner les barres sur l’axe des ordonnées grâce à la fonction reorder. Cela rendra le message de la figure plus intelligible.\n\n\n\nFigure avec les barres réordonnées\n\n\n\n\n\n\n\nOn réordonne Nom du compteur en fonction de Comptage horaire\n\n\n\nModifier votre couche esthétique afin d’appliquer une couleur rouge à l’ensemble des barres\n\n\n\nFigure avec les barres rouges\n\n\n\n\n\n\n\n\n\nOn commence à avoir quelque chose qui commence à transmettre un message synthétique sur la nature des données. On peut néanmoins remarquer plusieurs éléments problématiques (par exemple les labels) mais aussi des éléments ne correspondant pas (les titres des axes, etc.) ou manquants (le nom du graphique…)\n\n\n\n\n\n\nExercice 2 : Un peu de style !\n\n\n\nLa figure comporte maintenant un message mais il est encore peu lisible.\n\nLe minimum pour que quelqu’un ne connaissant pas les données soit capable de comprendre la représentation graphique est de labelliser les axes. Créer les mêmes labels d’axes que la figure originale.\n\n\n\nFigure avec les axes nommés\n\n\n\n\n\n\n\nIl existe de nombreuses manières de procéder avec ggplot pour labelliser les axes. Mais la plus simple est la fonction labs\n\n\n\nLe fond gris permet est certes une marque distinctive que le graphique a été produit avec ggplot2 mais ce n’est pas très soigné. Utiliser un thème plus minimaliste afin d’avoir un fond blanc.\n\n\n\nFigure avec un fond blanc\n\n\n\n\n\n\n\n\nMaintenant, concentrons nous sur les éléments plus esthétiques. Comme c’est une fonctionnalité un peu plus avancée, nous proposons directement le code pour mettre à jour votre figure avec les éléments de style suivant:\n\ntheme(\n  axis.text.x = element_text(angle = 45, hjust = 1, color = \"red\"),\n  axis.title.x = element_text(color = \"red\"),\n  plot.title = element_text(hjust = 0.5),\n  plot.margin = margin(1, 4, 1, 1, \"cm\")\n)\n\n\nFigure obtenue à l’issue de ces questions\n\n\n\n\n\n\n\nEnfin ajoutons de la complexité au graphique avec les chiffres sur les barres. En vous aidant de ce post, ajouter les comptages horaires moyens comme sur la figure de l’open data parisien2\n\n\n\n\nOn comprend ainsi que le boulevard de Sébastopol est le plus emprunté, ce qui ne vous suprendra pas si vous faites du vélo à Paris. Néanmoins, si vous n’êtes pas familiers avec la géographie parisienne, cela sera peu informatif pour vous, vous allez avoir besoin d’une représentation graphique supplémentaire: une carte ! Nous verrons ceci lors d’un prochain chapitre.\n\n\n\n\n\nLes 10 compteurs avec la moyenne horaire la plus élevée\n\n\n\n\n\n\n\n\n\n\nExercice 3: produire une nouvelle figure\n\n\n\nFaire la même chose pour la figure 2 (“Les 10 compteurs ayant comptabilisés le plus de vélos”), afin d’obtenir une figure similaire.\n\n\nFigure 2 à l’issue de cet exercice\n\n\n\n\n\n\n\n\n\nLes diagrammes en batons (barplot) sont extrêmement communs mais qu’ils transmettent. Sur le plan sémiologique, les lollipop charts sont préférables: ils transmettent la même information mais avec moins de bruit (la largeur des barres du barplot noie un peu l’information).\nVoici, par exemple, la deuxième figure de la page, rendue non plus sous forme de barplot mais sous forme de lollipop chart:\n\n\n\n\n\n\n\nComparaison du barplot et du lollipop chart\n\n\n\n\n\n\n\nBarplot\n\n\n\n\n\n\n\nLollipop\n\n\n\n\n\n\nChoisissez votre représentation préférée\n\n\n\n\n\n\n\n\n\n\nExercice 3 bis (optionnel): produire un lollipop chart\n\n\n\nReprendre l’exercice 2 mais à la place d’un barplot, produire un lollipop chart."
  },
  {
    "objectID": "exercises/ggplot.html#première-agrégation-temporelle",
    "href": "exercises/ggplot.html#première-agrégation-temporelle",
    "title": "Produire des représentations graphiques avec  et ggplot2",
    "section": "3 Première agrégation temporelle",
    "text": "3 Première agrégation temporelle\nOn va maintenant se concentrer sur la dimension spatiale de notre jeu de données à travers deux approches:\n\nUn diagramme en barre synthétisant l’information de notre jeu de données de manière mensuelle ;\nDes séries instructives sur la dynamique temporelle. Cela sera l’objet de la prochaine partie ;\n\nPour commencer, reproduisons la troisième figure qui est, encore une fois, un barplot. La première question implique une première rencontre avec une donnée temporelle à travers une opération assez classique en séries temporelles: changer le format d’une date pour pouvoir faire une agrégation à un pas de temps plus large.\n\n\n\n\n\n\nExercice 4: barplot des comptages mensuels\n\n\n\n\nUtiliser la fonction format pour créer une variable month dont le format respecte, par exemple, le schéma 2019-08 ;\nFaire la moyenne des comptages horaires pour chaque mois\n\n\n\nComptages horaires obtenus à l’issue de cette question\n\n\n\n# A tibble: 14 × 2\n   month   value\n   &lt;chr&gt;   &lt;dbl&gt;\n 1 2019-08  33.6\n 2 2019-09  55.8\n 3 2019-10  49.9\n 4 2019-11  36.0\n 5 2019-12  67.9\n 6 2020-01  66.1\n 7 2020-02  43.2\n 8 2020-03  29.4\n 9 2020-04  12.5\n10 2020-05  54.6\n11 2020-06  85.0\n12 2020-07  80.7\n13 2020-08  53.2\n14 2020-09  98.3\n\n\n\nAppliquer les conseils précédents pour construire et améliorer graduellement un graphique afin d’obtenir une figure similaire à la 3e production sur la page de l’open data parisien.\n\n\nExemple de figure reproduisant l’open data parisien\n\n\n\n\n\n\n\n\nQuestion optionnelle: représenter la même information sous forme de lollipop\n\n\n\n\n\n\n\n\nSi vous préférez représenter cela sous forme de lollipop3:"
  },
  {
    "objectID": "exercises/ggplot.html#première-série-temporelle",
    "href": "exercises/ggplot.html#première-série-temporelle",
    "title": "Produire des représentations graphiques avec  et ggplot2",
    "section": "4 Première série temporelle",
    "text": "4 Première série temporelle\nIl est plus commun de représenter sous forme de série les données ayant une dimension temporelle.\n\n\n\n\n\n\nExercice 5: Représenter une série temporelle\n\n\n\n\nCréer une variable day qui transforme l’horodatage en format journalier du type 2021-05-01.\n\n\nReprésenter sous forme de série temporelle cette information, sans vous préoccuper du style de la figure.\n\n\n\nFigure minimaliste\n\n\n\n\n\n\n\n\nColorer la zone sous la ligne avec la fonction appropriée\n\n\n\nFigure avec la coloration sous la ligne\n\n\n\n\n\n\n\n\nFinaliser le graphique pour reproduire la figure de la page d’open data\n\n\n\nFigure finalisée\n\n\n\n\n\n\n\nVoici quelques aides pour cet exercice\n\n\n💡 Aide pour la question 1\n\nRegardez la fonction day du package lubridate\n\n\n\n💡 Aide pour la question 3\n\nCe thread sur stackoverflow peut vous aider.\n\n\n\nLe jeu de données pour la figure 4\n\n\n\n# A tibble: 6 × 2\n  day        value\n  &lt;date&gt;     &lt;dbl&gt;\n1 2019-08-01  46.7\n2 2019-08-02  40.0\n3 2019-08-03  30.7\n4 2019-08-04  28.9\n5 2019-08-05  36.0\n6 2019-08-06  29.9\n\n\n\n\n\nA l’issue de cet exercice, on obtient ainsi une figure prenant la forme suivante:"
  },
  {
    "objectID": "exercises/ggplot.html#introduction-aux-graphiques-html-avec-plotly",
    "href": "exercises/ggplot.html#introduction-aux-graphiques-html-avec-plotly",
    "title": "Produire des représentations graphiques avec  et ggplot2",
    "section": "5 Introduction aux graphiques HTML avec Plotly",
    "text": "5 Introduction aux graphiques HTML avec Plotly\nL’inconvénient des figures avec ggplot est que celles-ci ne permettent pas d’interaction avec le lecteur. Toute l’information doit donc être contenue dans la figure ce qui peut la rendre difficile à lire. Si la figure est bien faite, avec différents niveaux d’information, cela peut bien fonctionner.\nIl est néanmoins plus simple, grâce aux technologies web, de proposer des visualisations à plusieurs niveaux. Un premier niveau d’information, celui du coup d’oeil, peut suffire à assimiler les principaux messages de la visualisation. Ensuite, un comportement plus volontaire de recherche d’information secondaire peut permettre d’en savoir plus. Les visualisations réactives, qui sont maintenant la norme dans le monde de la dataviz, permettent ce type d’approche: le lecteur d’une visualisation peut passer sa souris à la recherche d’information complémentaire (par exemple les valeurs exactes) ou cliquer pour faire apparaître des informations complémentaires sur la visualisation ou autour.\nCes visualisations reposent sur le même triptyque que l’ensemble de l’écosystème web: HTML, CSS et JavaScript. Les utilisateurs de  ne vont jamais manipuler directement ces langages, qui demandent une certaine expertise, mais vont utiliser des librairies au niveau de  qui génèreront automatiquement tout le code HTML, CSS et JavaScript permettant de créer la figure.\n\n\n\n\n\n\nExercice 6: série temporelle interactive\n\n\n\n\nCréer une figure Plotly basique pour représenter sous forme de série temporelle la figure 4, sans se préoccuper du style\n\n\n\nSérie temporelle produite sans élément de style\n\n\n\n\n\n\n\n\n\nA partir de l’exemple dans la documentation, ajouter une aire sous la figure\n\n\n\nAjout de la couche sous la ligne\n\n\n\n\n\n\n\n\n\nJouer sur les éléments de style pour reproduire la figure 4. Pour profiter de la réactivité du graphique, soigner l’information obtenue en passant la souris sur la figure grâce aux arguments hovertemplate et hoverinfo\n\n\n\nFigure obtenue\n\n\n\n\n\n\n\n\n\n\nLa version réactive de la figure est ainsi\n\n\n\n\n\n\nCette représentation montre bien le caractère spécial de l’année 2020. Pour rappeller au lecteur distrait la nature particulière de la période, marquée par un premier confinement qu’on voit bien dans les données, on peut, avec l’aide de la documentation, ajouter deux barres verticales pour marquer les dates de début et de fin de cette période:\n\nvline &lt;- function(x = 0, color = \"royalblue\") {\n  list(\n    type = \"line\",\n    y0 = 0,\n    y1 = 1,\n    yref = \"paper\",\n    x0 = x,\n    x1 = x,\n    line = list(color = color, dash=\"dot\")\n  )\n}\n\nfig4 %&gt;% layout(shapes = list(vline(\"2020-03-17\"), vline(\"2020-05-11\")))\n\n\n\n\n\nComme dernier exercice, voici comment reproduire cette figure avec Plotly:\n:::\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 7: un barplot avec Plotly\n\n\n\n\nPour avoir immédiatement des barres bien ordonnées, utiliser la fonction fct_reorder du package forcats pour réoordonner les valeurs du dataframe issu de l’exercice 1\nUtiliser Plotly pour créer votre figure.\n(Optionnel, plus avancé) Faire un lollipop chart avec Plotly"
  },
  {
    "objectID": "exercises/ggplot.html#footnotes",
    "href": "exercises/ggplot.html#footnotes",
    "title": "Produire des représentations graphiques avec  et ggplot2",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nD’habitude, nous recommandons d’utiliser directement l’URL de téléchargement ce qui évite de créer un fichier intermédiaire sur le disque dur. Néanmoins, ici, l’import direct avec readr ne fonctionnera pas car le fichier est mal interprété par la librairie. Celle-ci ne comprend pas que le fichier est compressé car il lui manque l’extension .gz (un format compressé) à la fin.↩︎\nCe n’est pas forcément une bonne pratique de dataviz de faire cela. En effet, cela signifie que l’échelle et la diversité des données dans celle-ci ne sont pas directement intelligibles.↩︎\nJ’ai retiré la couleur sur l’axe des ordonnées qui, je trouve, apporte peu à la figure voire dégrade la compréhension du message.↩︎"
  },
  {
    "objectID": "exercises/cartography.html",
    "href": "exercises/cartography.html",
    "title": "Produire des cartes avec ",
    "section": "",
    "text": "Dans ce TP, nous allons apprendre à créer des cartes avec . A mesure que  devient incontournable auprès des personnes manipulant des données spatiales, les solutions pour produire des cartes de qualité deviennent de plus en plus nombreuses.  a de moins en moins à envier aux logiciels spécialisés comme QGIS.\nSi vous êtes intéressés par Python , une version très proche de ce TP est disponible dans mon cours de l’ENSAE.\nLa pratique de la cartographie se fera, dans la continuité du chapitre sur les graphiques, en répliquant des cartes qu’on peut trouver sur la page de l’open-data de la ville de Paris ici.\nCe TP vise à initier:\nDans ce chapitre, nous allons utiliser les packages suivants:\nlibrary(dplyr)\nlibrary(sf)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(ggmap)\nlibrary(cartiflette)"
  },
  {
    "objectID": "exercises/cartography.html#données",
    "href": "exercises/cartography.html#données",
    "title": "Produire des cartes avec ",
    "section": "1 Données",
    "text": "1 Données\nAu cours de ce chapitre, nous allons utiliser principalement trois jeux de données :\n\nLes comptages de passage de vélos dans les stations de mesure parisiennnes ;\nLa localisation précise des stations\nLes limites officielles administratives des arrondissements et communes de l’agglomération parisienne. Ce fonds de carte est produit par l’IGN et sa récupération est facilitée par le package cartiflette.\n\n\n1.1 Comptages\nUn sous-ensemble des données de Paris Open Data a été mis à disposition pour faciliter l’import.\nIl s’agit d’une extraction, qui commence à dater, des données disponibles sur le site où seules les colonnes qui servent à cet exercice ont été conservées.\nNous proposons de télécharger ces données et les enregistrer dans un fichier sur le disque dur local avant de l’importer1. Cependant, nous n’allons pas faire cela manuellement mais nous allons plutôt utiliser . Effectuer ce type d’action de manière manuelle serait une mauvaise pratique du point de vue de la reproductibilité.\n\nurl &lt;- \"https://minio.lab.sspcloud.fr/projet-formation/diffusion/python-datascientist/bike.csv\"\n1download.file(url, \"bike.gz\")\n2comptages &lt;- readr::read_csv(\"bike.gz\")\n\n\n1\n\nL’extension .gz est importante pour la suite car readr en a besoin pour comprendre que le fichier est compressé.\n\n2\n\nLecture des données avec read_csv du package readr\n\n\n\n\n\n\n1.2 Localisation des compteurs\n\ncompteurs = st_read(\"https://parisdata.opendatasoft.com/api/explore/v2.1/catalog/datasets/comptage-velo-compteurs/exports/geojson?lang=fr&timezone=Europe%2FBerlin\")\n\nIl y a quelques valeurs aberrantes dans ce jeu de données qui doivent être laissées de côté. Elles sont identifiables par le fait que la variable nom_compteurs ne comporte pas les mentions Bike IN ou Bike OUT. Comme c’est un petit peu avancé pour une introduction, nous donnons directement la solution de ce travail de nettoyage:\n\ncompteurs &lt;- compteurs %&gt;% filter(!str_detect(\"(Bike IN|Bike OUT)\", nom_compteur))\n\n\n\n1.3 Fonds de carte contextuels\nOn va utiliser à nouveau cartiflette pour récupérer les arrondissements parisiens et les communes limitrophes.\n\narrondissements &lt;- download_vectorfile_url_all(\n  crs = 4326,\n  values = \"75\",\n  borders=\"COMMUNE_ARRONDISSEMENT\",\n  vectorfile_format=\"geojson\",\n  filter_by=\"DEPARTEMENT\",\n  source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n  year=2022) %&gt;%\n  st_transform(2154)"
  },
  {
    "objectID": "exercises/cartography.html#une-première-carte-avec-ggplot",
    "href": "exercises/cartography.html#une-première-carte-avec-ggplot",
    "title": "Produire des cartes avec ",
    "section": "2 Une première carte avec ggplot",
    "text": "2 Une première carte avec ggplot\nLors des chapitres précédents nous avons appris la manière dont des graphiques peuvent être construits en accumulant des couches.\nIl est possible d’ajouter des couches sur une image, à condition que les coordonnées coïncident. Pour faire cela de manière fiable, nous allons utiliser le package ggmap2.\nL’objectif du prochain exercice est de construire la carte suivante, de manière progressive:\n\n\nℹ Map tiles by Stamen Design, under CC BY 3.0. Data by OpenStreetMap, under CC BY SA.\n\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 1: construire la carte des compteurs avec ggmap et ggplot\n\n\n\nPour récupérer la carte, nous allons avoir besoin de construire un certain nombre d’objets en amont. En premier lieu, il est nécessaire de créer un vecteur stockant les extrêmes de notre carte. Dans le jargon des SIG, cela s’appelle la bounding box. Voici comment faire ceci:\n\n1bbox_paris &lt;- arrondissements %&gt;% st_transform(4326) %&gt;% st_bbox()\n2bbox_paris &lt;- setNames(bbox_paris, c(\"left\", \"bottom\", \"right\", \"top\"))\nbbox_paris\n\n\n1\n\nOn a besoin de coordonnées en WGS84, il faut donc reprojeter les données avant d’appliquer st_bbox\n\n2\n\nggmap attend un vecteur dont les noms sont \"left\", \"bottom\", \"right\", \"top\", setNames permet de renommer les éléments de bbox_paris\n\n\n\n\n\nbbox_paris\n\n     left    bottom     right       top \n 2.224217 48.815562  2.469851 48.902148 \n\n\n\nUtiliser get_map pour récupérer le fonds de carte. Nommer l’objet map_paris_watercolor. La carte proposée utilise le fonds watercolor, dont la source est stamen. Utiliser ensuite ggmap(fonds_stamen) pour vérifier le fonds de carte récupéré.\nAjouter une couche d’arrondissements à cette image avec geom_sf. Il va être nécessaire d’utiliser les arguments suivants:\n\n\ndata: comme nous initialisons la figure avec ggmap, il faut dire à ggplot que nous partons du jeu de données arrondissements pour cette couche\nfill et color pour contrôler, respectivement, la couleur de l’intérieur et des bordures des polygones.\ninherit.aes = FALSE: indispensable à cause du comportement de ggmap qui ne sait pas gérer les objets sf (cf. footnote antérieure)\n\n\nAjouter une couche pour représenter la position des stations avec geom_sf. Il va être nécessaire d’utiliser les arguments suivants:\n\n\ndata: comme nous initialisons la figure avec ggmap, il faut dire à ggplot que nous partons du jeu de données compteurs pour cette couche\ncolor=\"red\", size=5 et alpha=0.4 pour contrôler l’apparence de nos points\ninherit.aes = FALSE: indispensable à cause du comportement de ggmap qui ne sait pas gérer les objets sf (cf. footnote antérieure)\n\n\nFinaliser l’esthétique de la carte avec theme_void()\n\n\n\nAide pour la question 1\n\nLes arguments à utiliser sont location, maptype et source\n\n\n\n\n\nLe fonds de carte, sans motif par dessus, est le suivant:\n\n\n\nℹ Map tiles by Stamen Design, under CC BY 3.0. Data by OpenStreetMap, under CC BY SA.\n\n\n\n\n\n\n\n\nEn ajoutant les arrondissements par dessus (question 2):\n\n\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n\n\n\n\n\n\n\n\nAprès avoir ajouté les points (question 3)\n\n\n\n\n\n\n\n\n\nSi vous préférez un autre fonds de carte que Watercolor, par exemple Stamen Toner:\n\n\n\nℹ Map tiles by Stamen Design, under CC BY 3.0. Data by OpenStreetMap, under ODbL.\n\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one."
  },
  {
    "objectID": "exercises/cartography.html#heatmap",
    "href": "exercises/cartography.html#heatmap",
    "title": "Produire des cartes avec ",
    "section": "3 Heatmap",
    "text": "3 Heatmap"
  },
  {
    "objectID": "exercises/cartography.html#carte-de-fréquentation-des-stations",
    "href": "exercises/cartography.html#carte-de-fréquentation-des-stations",
    "title": "Produire des cartes avec ",
    "section": "4 Carte de fréquentation des stations",
    "text": "4 Carte de fréquentation des stations\n\n\n\n\n\n\nExercice\n\n\n\n\n\n\n\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union"
  },
  {
    "objectID": "exercises/cartography.html#footnotes",
    "href": "exercises/cartography.html#footnotes",
    "title": "Produire des cartes avec ",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nD’habitude, nous recommandons d’utiliser directement l’URL de téléchargement ce qui évite de créer un fichier intermédiaire sur le disque dur. Néanmoins, ici, l’import direct avec readr ne fonctionnera pas car le fichier est mal interprété par la librairie. Celle-ci ne comprend pas que le fichier est compressé car il lui manque l’extension .gz (un format compressé) à la fin.↩︎\nggmap est un package assez ancien qui n’a pas trop évolué récemment. Il continue notamment à utiliser des objets sp, l’ancêtre de sf qui existe déjà depuis plusieurs années. Il est donc possible que ce package soit archivé dans un futur plus ou moins lointain.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "",
    "text": "Introduction aux méthodes quantitatives avec \nLino Galiana\nCours du département de sciences sociales de l’ENS Ulm.\nUn cours pour se familiariser à  par la pratique avec l’open data.\n\n\n\n  \n     \n      \n          \n            \n          \n          \n            Introduction aux objets de base \n            \n              \nIntroduction aux objets basiques de \net à RStudio\n\n\n              \n                Lino Galiana\n                Sep 1, 2023\n              \n            \n            \n                \n                  Exercice ✏️\n                \n                \n                  Slides 🧑‍🏫\n                \n            \n          \n        \n      \n     \n  \n  \n     \n      \n          \n            \n          \n          \n            Manipuler des données avec le tidyverse\n            \n              \nIntroduction à l'écosystème du tidyverse\npour lire et manipuler des données structurées avec \n\n\n              \n                Lino Galiana\n                Sep 1, 2023\n              \n            \n            \n                \n                  Exercice ✏️\n                \n                \n                  Slides 🧑‍🏫\n                \n            \n          \n        \n      \n     \n  \n  \n     \n      \n          \n            \n          \n          \n            Produire des représentations graphiques avec ggplot2\n            \n              \nIntroduction à ggplot2,\npour produire des graphiques avec\n\n\n\n              \n                Lino Galiana\n                Sep 1, 2023\n              \n            \n            \n                \n                  Exercice ✏️\n                \n                \n                  Slides 🧑‍🏫\n                \n            \n          \n        \n      \n     \n  \n  \n     \n      \n          \n            \n          \n          \n            Manipuler des données spatiales avec sf\n            \n              \nIntroduction à sf,\nune extension du\ntidyverse\npour transformer \nen SIG capable de lire et manipuler des données géographiques.\n\n\n              \n                Lino Galiana\n                Sep 1, 2023\n              \n            \n            \n                \n                  Exercice ✏️\n                \n                \n                  Slides 🧑‍🏫\n                \n            \n          \n        \n      \n     \n  \n  \n     \n      \n          \n            \n          \n          \n            Produire des cartes avec \n            \n              \nIntroduction à la cartographie avec\n\n\n\n              \n                Lino Galiana\n                Sep 1, 2023\n              \n            \n            \n                \n                  Exercice ✏️\n                \n                \n                  Slides 🧑‍🏫\n                \n            \n          \n        \n      \n     \n  \n\n\nNo matching items"
  },
  {
    "objectID": "slides/ggplot.html#introduction",
    "href": "slides/ggplot.html#introduction",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\nNote\n\n\n\nExercices associés à ce chapitre ici\n\n\n\n\n\n\nRetour à la page principale"
  },
  {
    "objectID": "slides/ggplot.html#introduction-1",
    "href": "slides/ggplot.html#introduction-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Introduction",
    "text": "Introduction\n\nLa visualisation de données synthétise la structure des données\n\nGuide l’exploration ultérieure de données\nTransmets un message au lecteur\n\n\n\n\n2 types de visualisations :\n\nReprésentations figées: ggplot2\nReprésentations HTML: leaflet"
  },
  {
    "objectID": "slides/ggplot.html#jeu-de-données-des-exemples",
    "href": "slides/ggplot.html#jeu-de-données-des-exemples",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Jeu de données des exemples",
    "text": "Jeu de données des exemples\n\nlibrary(doremifasol)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)\n\ndf &lt;- telechargerDonnees(\"FILOSOFI_DISP_IRIS\", date = 2017) %&gt;%\n  as_tibble() %&gt;%\n  sample_frac(0.1)\n\n\n\n\n\n\n\nNote\n\n\nInspiration pour ces slides :\n\nDocumentation collaborative utilitR ;\nManuel ggplot ;\nCours de Joseph Larmarange"
  },
  {
    "objectID": "slides/ggplot.html#ggplot2",
    "href": "slides/ggplot.html#ggplot2",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "ggplot2",
    "text": "ggplot2\nInitialise une figure associée à un jeu de données\n\nggplot(df, aes(x = DISP_MED17, y = DISP_D917))"
  },
  {
    "objectID": "slides/ggplot.html#ggplot2-1",
    "href": "slides/ggplot.html#ggplot2-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "ggplot2",
    "text": "ggplot2\nAjoute des couches (+) avec les fonctions geom_*\n\nggplot(df) +\n  geom_point(aes(x = DISP_MED17, y = DISP_D917))"
  },
  {
    "objectID": "slides/ggplot.html#ggplot2-2",
    "href": "slides/ggplot.html#ggplot2-2",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "ggplot2",
    "text": "ggplot2\nParamétrise les couches avec aes\n\nggplot(df) +\n  geom_point(aes(x = DISP_MED17, y = DISP_D917, color = DISP_Q117), shape = 3)\n\n\n\n\n\n\n\n\nNote\n\n\nLe contrôle de l’esthétique d’une couche geom_ se fait :\n\naes: paramètres variables de la couche liés à une variable ;\nhors aes: paramètres qui s’appliquent uniformément sur la couche"
  },
  {
    "objectID": "slides/ggplot.html#ggplot2-3",
    "href": "slides/ggplot.html#ggplot2-3",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "ggplot2",
    "text": "ggplot2\nAjoute des couches (+) avec les fonctions geom_*\n\nggplot(df, aes(x = DISP_MED17, y = DISP_D917)) +\n  geom_point(aes(color = DISP_Q117), shape = 3) +\n  geom_smooth(color = \"red\", alpha = 0.7, se = FALSE)"
  },
  {
    "objectID": "slides/ggplot.html#ggplot2-4",
    "href": "slides/ggplot.html#ggplot2-4",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "ggplot2",
    "text": "ggplot2\nModifier les échelles avec les fonctions scale_\n\nggplot(df, aes(x = DISP_MED17, y = DISP_D917)) +\n  geom_point(aes(color = DISP_Q117), shape = 3) +\n  geom_smooth(color = \"red\", alpha = 0.7, se = FALSE) +\n  scale_x_continuous(labels = unit_format(unit = \"k\", scale=1e-3)) +\n  scale_y_continuous(trans='log', labels = unit_format(unit = \"k\", scale=1e-3)) +\n  scale_color_viridis_c()"
  },
  {
    "objectID": "slides/ggplot.html#ggplot2-5",
    "href": "slides/ggplot.html#ggplot2-5",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "ggplot2",
    "text": "ggplot2\nModifier les échelles avec les fonctions scale_\n\ndf &lt;- df %&gt;% mutate(quartile = factor(ntile(DISP_Q117, 4)))\nggplot(df, aes(x = DISP_MED17, y = DISP_D917)) +\n  geom_point(aes(color = quartile), shape = 3) +\n  geom_smooth(color = \"red\", alpha = 0.7, se = FALSE) +\n  scale_x_continuous(labels = unit_format(unit = \"k\", scale=1e-3)) +\n  scale_y_continuous(trans='log', labels = unit_format(unit = \"k\", scale=1e-3)) +\n  scale_color_viridis_d(option = \"turbo\")"
  },
  {
    "objectID": "slides/ggplot.html#ggplot2-6",
    "href": "slides/ggplot.html#ggplot2-6",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "ggplot2",
    "text": "ggplot2\nModifier l’esthétique, à la fin seulement\n\np &lt;- ggplot(df, aes(x = DISP_MED17, y = DISP_D917)) +\n  geom_point(aes(color = quartile), shape = 3) +\n  geom_smooth(color = \"red\", alpha = 0.7, se = FALSE) +\n  scale_x_continuous(labels = unit_format(unit = \"k\", scale=1e-3)) +\n  scale_y_continuous(trans='log', labels = unit_format(unit = \"k\", scale=1e-3)) +\n  scale_color_viridis_d(option = \"turbo\")\n\np + theme_bw() +\n  labs(x = \"Revenu médian\", y = \"9e décile\", color = \"Quartile\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\nIntroduction aux méthodes quantitatives avec , École Normale Supérieure (retour page principale)"
  },
  {
    "objectID": "slides/introduction.html#chapitre-introductif",
    "href": "slides/introduction.html#chapitre-introductif",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Chapitre introductif",
    "text": "Chapitre introductif\n\n\n\n\n\n\nNote\n\n\n\nExercices associés à ce chapitre ici\n\n\n\n\n\n\nRetour à la page principale"
  },
  {
    "objectID": "slides/introduction.html#qui-suis-je-fa-brands-firefox-sizetiny-fa-brands-github-sizetiny-fa-brands-twitter-sizetiny-fa-brands-linkedin-sizetiny-fa-brands-python-sizetiny",
    "href": "slides/introduction.html#qui-suis-je-fa-brands-firefox-sizetiny-fa-brands-github-sizetiny-fa-brands-twitter-sizetiny-fa-brands-linkedin-sizetiny-fa-brands-python-sizetiny",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Qui suis-je ?      ",
    "text": "Qui suis-je ?      \n\nData scientist au lab de l’Insee :\n\nAdministrateur Insee1 ;\nCoordonnateur d’un réseau de data scientists\n\n\n\n\nImplication dans l’innovation statistique, l’open source et la diffusion grand public2:\n\n: utilitR, doremifasol\n: cartiflette, pynsee\n\n\n\nRenseignez-vous sur le concours ENS ! Il y a de belles missions !Pas tout seul ! Avec une communauté de gens sympa de l’administration et de la recherche ! Beaucoup de projets novateurs 😍 sur compte  InseeFrLab"
  },
  {
    "objectID": "slides/introduction.html#qui-suis-je",
    "href": "slides/introduction.html#qui-suis-je",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Qui suis-je ?",
    "text": "Qui suis-je ?\n\nTravaux à l’intersection entre informatique, économie, sociologie & géographie:\n\nSégrégation avec données de téléphonie mobile\nInégalités alimentaires à partir de données massives de supermarchés\n\n\n\nExemple tiré de l’Insee Analyse sur la mixité sociale"
  },
  {
    "objectID": "slides/introduction.html#qui-suis-je-1",
    "href": "slides/introduction.html#qui-suis-je-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Qui suis-je ?",
    "text": "Qui suis-je ?\nD’autres cours introductifs que je donne peuvent vous intéresser:\n\nPython pour la data science ;\nBonnes pratiques en R et Git ;\nDonnées émergentes ;\n\nEt surtout consultez le portail complet de formation du datalab de l’Insee"
  },
  {
    "objectID": "slides/introduction.html#objectifs-pédagogiques",
    "href": "slides/introduction.html#objectifs-pédagogiques",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Objectifs pédagogiques",
    "text": "Objectifs pédagogiques\n\nDécouverte de l’écosystème de l’open data 🇫🇷\n\n\n\nIntroduction pratique au langage :\n\nDonnées classiques\nDonnées géographiques\n\n\n\n\n\nIntroduction à la publication reproductible avec Quarto\n\n\n\n\nOuverture à la cartographie web avec Observable"
  },
  {
    "objectID": "slides/introduction.html#modalités-pratiques",
    "href": "slides/introduction.html#modalités-pratiques",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Modalités pratiques",
    "text": "Modalités pratiques\n\nDes slides et surtout des TP guidés ;\nInfrastructure informatique (SSPCloud) fournie par l’Insee pour éviter:\n\nles galères d’installation\nles galères de configuration\n\nModalités d’initialisation à venir ;\n\nOn va utiliser le SSPCloud 😍🐉☁️🇫🇷 !\n(présentation tout à l’heure)"
  },
  {
    "objectID": "slides/introduction.html#ressources-complémentaires",
    "href": "slides/introduction.html#ressources-complémentaires",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Ressources complémentaires",
    "text": "Ressources complémentaires\n\nIntroduction à R et au tidyverse ;\n\n\n\nDocumentation collaborative utilitR 👶 ;\n\n\n\n\nPortail de formation du SSPCloud ;\n\n\n\n\nFunathon organisé par l’Insee ;\n\n\n\n\nR for Data Science (la bible !) ;\n\n\n\n\nData science with R (Sciences Po) ;\n\n\n\n\nRzine, du CIST\n\n\n\n\nGeocomputation with R, de Lovelace, Nowosad et Muenchow\n\n\n\n\nData Visualization : A practical introduction, de Kieran Healy"
  },
  {
    "objectID": "slides/introduction.html#prolifération-des-données",
    "href": "slides/introduction.html#prolifération-des-données",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Prolifération des données",
    "text": "Prolifération des données\n\nNumérisation et innovations technologiques ont réduit le coût de production de la donnée ;\n\nVolume de données produites en explosion\n\n\n\n\nL’utilisation des statistiques n’est pas nouvelle (cf. Desrosières)…\n\n\n\n\n… mais une place accrue dans le débat public et l’action publique (Supiot, Martin)"
  },
  {
    "objectID": "slides/introduction.html#diversification-des-données-14",
    "href": "slides/introduction.html#diversification-des-données-14",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Diversification des données (1/4)",
    "text": "Diversification des données (1/4)\nDonnées tabulaires classiques\n\nviewof info_mutations = Inputs.radio(\n  [\"Tableau\", \"Graphique\"], {value: \"Tableau\"}\n)\n\n\n\n\n\n\n\ninfo_mutations == \"Tableau\" ? html`&lt;div&gt;${table_mutations1}&lt;div&gt;` : html`&lt;div&gt;${plot_mutations}&lt;div&gt;`\n\n\n\n\n\n\n\nurl = \"https://files.data.gouv.fr/geo-dvf/latest/csv/2020/communes/92/92049.csv\"\nproxy = \"https://corsproxy.io/?\"\ndvf = d3.csv(proxy + url)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntable_mutations1 = Inputs.table(dvf, {\"columns\": ['date_mutation', 'valeur_fonciere', 'adresse_nom_voie']})\nplot_mutations = Plot.plot({\n  y: {grid: true, label: \"Nombre de transactions\"},\n  x: {\n    ticks: 12,\n    transform: (d) =&gt; Math.pow(10, d),\n    type: \"log\",\n    tickFormat: \"~s\",\n    label: \"Prix (échelle log) →\"\n  },\n  marks: [\n    Plot.rectY(\n      dvf.filter(d =&gt; d.valeur_fonciere &gt; 10000),\n      Plot.binX({y: \"count\"},\n      {\n        x: d =&gt; Math.log10(d.valeur_fonciere),\n        tip: true\n      })\n    ),\n    Plot.ruleY([0])\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot = require(\"https://cdn.jsdelivr.net/npm/@observablehq/plot@0.6.10/dist/plot.umd.min.js\")"
  },
  {
    "objectID": "slides/introduction.html#diversification-des-données-14-1",
    "href": "slides/introduction.html#diversification-des-données-14-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Diversification des données (1/4)",
    "text": "Diversification des données (1/4)\nDonnées tabulaires classiques\n\nDonnées structurées sous forme de tableau\n\n\nSource: Hadley Wickham, R for data science\n très bien outillé pour ces données (si volumétrie adaptée)"
  },
  {
    "objectID": "slides/introduction.html#diversification-des-données-24",
    "href": "slides/introduction.html#diversification-des-données-24",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Diversification des données (2/4)",
    "text": "Diversification des données (2/4)\n\nDonnées géolocalisées\n\n\nviewof info_power_plants = Inputs.radio(\n  [\"Tableau\", \"Carte\"], {value: \"Tableau\"}\n)\n\n\n\n\n\n\n\ninfo_power_plants == \"Tableau\" ? html`&lt;div&gt;${table_power_plants}&lt;div&gt;` : html`&lt;div&gt;${plot_power_plants}&lt;div&gt;`\n\n\n\n\n\n\n\nimport {us_power_plants, states} from \"@observablehq/build-your-first-map-with-observable-plot\"\n\ntable_power_plants = Inputs.table(\n  us_power_plants\n)\n\n\nplot_power_plants = Plot.plot({\n  projection: \"albers-usa\",\n  marks: [\n    Plot.geo(states, { fill: \"white\", stroke: \"#e2e2e2\"  }),\n    Plot.dot(us_power_plants, {\n      x: \"longitude\",\n      y: \"latitude\",\n      r: \"Total_MW\",\n      fill: \"PrimSource\",\n      opacity: 0.7,\n      tip: true\n    }),\n    Plot.dot(us_power_plants, { // Can you figure out what this additional Plot.dot layer adds?\n      x: \"longitude\",\n      y: \"latitude\",\n      r: \"Total_MW\",\n      fill: \"PrimSource\",\n      stroke: \"black\",\n      filter: d =&gt; d.Total_MW &gt; 3500,\n    }),\n    Plot.text(us_power_plants, { // Add text to the map using data from us_power_plants\n      x: \"longitude\", // Place text horizontally at plant longitude\n      y: \"latitude\", // Place text vertically at plant latitude\n      text: \"Plant_Name\", // The text that appears is the value from the Plant_Name column,\n      filter: (d) =&gt; d.Total_MW &gt; 3500, // Only add text for plants with capacity exceeding 3500 MW\n      fontSize: 12, // Increased font size\n      fontWeight: 600, // Increased font weight\n      stroke: \"white\", // Adds white outer stroke to text (for readability)\n      fill: \"black\", // Text fill color\n      textAnchor: \"start\", // Left align text with the x- and y-coordinates\n      dx: 15 // Shifts text to the right (starting from left alignment with coordinate)\n    })\n  ],\n  r: { range: [1, 15] },\n  color: { legend: true },\n  height: 500,\n  width: 800,\n  margin: 50\n})"
  },
  {
    "objectID": "slides/introduction.html#diversification-des-données-24-1",
    "href": "slides/introduction.html#diversification-des-données-24-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Diversification des données (2/4)",
    "text": "Diversification des données (2/4)\n\nDonnées géolocalisées\n\n\nDonnées tabulaires avec une dimension spatiale supplémentaire\n\nDimension géographique prend des formes multiples:\nPoints, lignes, polygones…\n\n\n\n\n très bien outillé pour ces données (si volumétrie adaptée)"
  },
  {
    "objectID": "slides/introduction.html#diversification-des-données-34",
    "href": "slides/introduction.html#diversification-des-données-34",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Diversification des données (3/4)",
    "text": "Diversification des données (3/4)\n\nDonnées textuelles et non structurées\n\n\nTechniques statistiques anciennes (Levenshtein 1957, perceptron) ;\n\n\n\nApplications limitées jusqu’aux années 2010 ;\n\n\n\n\nDéveloppement très rapide de la recherche :\n\nCollecte accrue : réseaux sociaux, enquêtes…\nBaisse coûts stockage & augmentation ressources traitement ;\nNouvelles techniques statistiques: webscraping, LLM…\n\n\n\n\n\nUtilisation intensive dans l’administration, la recherche et le secteur privé\n\nPlus d’infos dans mon cours sur les données émergentes"
  },
  {
    "objectID": "slides/introduction.html#diversification-des-données-44",
    "href": "slides/introduction.html#diversification-des-données-44",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Diversification des données (4/4)",
    "text": "Diversification des données (4/4)\nImages, sons et vidéos\n\nPlus d’infos dans mon cours sur les données émergentes"
  },
  {
    "objectID": "slides/introduction.html#apparition-de-nouveaux-acteurs",
    "href": "slides/introduction.html#apparition-de-nouveaux-acteurs",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Apparition de nouveaux acteurs",
    "text": "Apparition de nouveaux acteurs\n\nActeurs classiques:\n\nInstituts statistiques (INSEE et SSM1) ;\nAdministrations centrales (DGFiP, DINUM…) ou opérateurs (IGN…)\nPlus de détails à venir\n\n\n\n\nCollectivités locales (exemple: Open data Paris)\n\n\n\n\nProjets contributifs: OpenStreetMap, Wikidata, OpenFoodFacts…\n\n\n\n\nActeurs privés:\n\nCollectent des données sur leurs utilisateurs/clients (extrapolation possible?)\nPeuvent mettre à disposition ces données à d’autres acteurs (chercheurs par exemple)\nCadre réglementaire: RGPD\n\n\n\nLe service statistique public est constitué de l’Insee et des 16 services statistiques ministériels (SSM)"
  },
  {
    "objectID": "slides/introduction.html#accès-de-plus-en-plus-direct-à-la-donnée",
    "href": "slides/introduction.html#accès-de-plus-en-plus-direct-à-la-donnée",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Accès de plus en plus direct à la donnée",
    "text": "Accès de plus en plus direct à la donnée\n\nEre de l’open data et open source :\n\nMouvement accéléré depuis l’élection Obama 2008\nCréation Etalab en 2011 ;\nLoi pour une république numérique 2016\n\n\n\n\nChangements technologiques et culturels :\n\nFormats ouverts et standardisés ;\nSuccès des langages open source (notamment Python  et R )\nAcculturation aux API"
  },
  {
    "objectID": "slides/introduction.html#data-is-everywhere",
    "href": "slides/introduction.html#data-is-everywhere",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Data is everywhere",
    "text": "Data is everywhere"
  },
  {
    "objectID": "slides/introduction.html#linsee",
    "href": "slides/introduction.html#linsee",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "L’Insee",
    "text": "L’Insee\n\nCollecte, produit, analyse et diffuse l’information statistique :\n\nProducteur de statistiques (enquêtes, données administratives) ;\nProducteur d’études pour le débat public (rare chez les instituts statistiques)\n\n\n\n\nPublie énormément d’informations:\n\nRecensement, taux de chômage, inflation, PIB, fichier des prénoms…\nCode officiel géographique (COG) et zonages d’études\n\n\n\n\n\nRôle de coordination du service statistique public:\n\nInstituts statistiques ministériels: DREES (Santé), DARES (Travail)…\n\n\n\n\n\nDiffusion données sur insee.fr\n\nUtilisateurs de : accès facilité via des packages"
  },
  {
    "objectID": "slides/introduction.html#lign",
    "href": "slides/introduction.html#lign",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "L’IGN",
    "text": "L’IGN\n\nProduit et diffuse la géométrie du territoire national et l’occupation du sol:\n\nProducteur de cartes 🥾 (top25…)\nLIDAR\n\n\n\n\nProducteur des fonds de carte utiles pour nous:\n\nBDTopo, BD Forêt,\nAdminExpress\n\n\n\n\n\nDiffusion données depuis geoservices de l’IGN (en attendant la geoplateforme)\n\nUtilisateurs de : accès facilité à certaines sources via cartiflette"
  },
  {
    "objectID": "slides/introduction.html#data.gouv",
    "href": "slides/introduction.html#data.gouv",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "data.gouv",
    "text": "data.gouv\n\nPlateforme de l’open data en France\n\nCrée par Etalab (DINUM) en 2011\n\n\n\n\nRecense des jeux de données produits par les acteurs publics:\n\nAdministrations centrales\nCollectivités locales\n\n\n\n\n\nMise à disposition directe de certains jeux de données\n\n\n\n\nRecense des réutilisations"
  },
  {
    "objectID": "slides/introduction.html#github-fa-brands-github-là-où-on-trouve-du-code",
    "href": "slides/introduction.html#github-fa-brands-github-là-où-on-trouve-du-code",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Github : là où on trouve du code",
    "text": "Github : là où on trouve du code\n\nPlateforme de mise à disposition de code\n\n\n\nBeaucoup plus que seulement du code:\n\nDocumentation de projets\nSites web\n\n\n\n\n\nLieu de l’open source et de la recherche transparente"
  },
  {
    "objectID": "slides/introduction.html#observable-the-new-place-to-be",
    "href": "slides/introduction.html#observable-the-new-place-to-be",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Observable: the new place to be",
    "text": "Observable: the new place to be\n\nPlateforme de dataviz web\n\nCréée par Mike Bostock (dieu dans la dataviz)\n\n\n\n\nEmergence récente mais forte dynamique\n\nTrès complémentaire à R\n\n\n\n\n\nInvestie par des cartographes qui font de super visualisations :\n\nNicolas Lambert\nEric Mauvière\nThomas Ansart"
  },
  {
    "objectID": "slides/introduction.html#des-métiers-multiples-dans-ladministration",
    "href": "slides/introduction.html#des-métiers-multiples-dans-ladministration",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Des métiers multiples dans l’administration",
    "text": "Des métiers multiples dans l’administration\n\n\n\n\n\n\n\nmais aussi data engineer, data architect, data analyst…\ncf. Rapport INSEE-DINUM “Évaluation des besoins de l’État en compétences et expertises en matière de donnée”\n\n\n\n\nhttps://www.numerique.gouv.fr/uploads/RAPPORT-besoins-competences-donnee.pdf"
  },
  {
    "objectID": "slides/introduction.html#le-tournant-numérique-des-sciences-sociales",
    "href": "slides/introduction.html#le-tournant-numérique-des-sciences-sociales",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le tournant numérique des sciences sociales",
    "text": "Le tournant numérique des sciences sociales\n\nAccès facilité à des données spatialisées ;\nAcculturation aux SIG et langages statistiques ;\nDéveloppement de technologies web interactives (observable)\n\n\n\n\nRéférences\n\n\nRoth Camille. 2019. “Digital, Digitized, and Numerical Humanities.” Digital Scholarship in the Humanities\nAsh J, Kitchin R, Leszczynski A. 2018. “Digital turn, digital geographies ?” Progress in Human Geography\nEinav, L., & Levin, J. (2014). Economics in the age of big data. Science, 346(6210), 1243089."
  },
  {
    "objectID": "slides/introduction.html#le-tournant-numérique-des-sciences-sociales-1",
    "href": "slides/introduction.html#le-tournant-numérique-des-sciences-sociales-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le tournant numérique des sciences sociales",
    "text": "Le tournant numérique des sciences sociales\n\nWe live life in the network. We check our e-mails regularly, make mobile phone calls from almost any location, swipe transit cards to use public transportation,and make purchases with credit cards. Our movements in public places may be captured by video cameras, and our medical records stored as digital files. We may post blog entries accessible to anyone, or maintain friendships through online social networks. Each of these transactions leaves digital traces that can be compiled into comprehensive pictures of both individual and group behavior, with the potential to transform our understanding of our lives, organizations, and societies.\nLazer et al. ,Computational Social Science, Science (2009)"
  },
  {
    "objectID": "slides/introduction.html#la-géographie-quantitative",
    "href": "slides/introduction.html#la-géographie-quantitative",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "La géographie quantitative",
    "text": "La géographie quantitative\n\nUne des premières cartes statistiques (1798)"
  },
  {
    "objectID": "slides/introduction.html#la-géographie-quantitative-1",
    "href": "slides/introduction.html#la-géographie-quantitative-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "La géographie quantitative",
    "text": "La géographie quantitative\n\nJohn Snow cartographie le choléra à Londres"
  },
  {
    "objectID": "slides/introduction.html#années-1950-1960-révolution-quantitative",
    "href": "slides/introduction.html#années-1950-1960-révolution-quantitative",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Années 1950-1960 : révolution quantitative",
    "text": "Années 1950-1960 : révolution quantitative\n\nEverything is related to everything else, but near things are more related than distant things.\nW. Tobler, 1970, Economic Geography\n\n\nUne science nomothétique : recherche des lois générales de l’organisation de l’espace\n\n\n\nUne science explicative : modélisation\n\nModèle de Christaller\n\n\n\n\n\nUne science appliquée : essor de la regional science, de l’économétrie spatiale\n\nLoi de Zipf…)\n\n\n\n\n\nUne science de l’information (déjà):\n\nSémiologie (carto)graphique de Bertin, 1967"
  },
  {
    "objectID": "slides/introduction.html#années-2010-tournant-digital-de-la-géographie-quantitative",
    "href": "slides/introduction.html#années-2010-tournant-digital-de-la-géographie-quantitative",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Années 2010 : tournant “digital” de la géographie quantitative",
    "text": "Années 2010 : tournant “digital” de la géographie quantitative\n\nQuantification de masse de phénomènes spatiaux sociaux:\n\nDéplacements, lieux fréquentés…\n\n\n\n\nIntersection avec d’autres sciences : data science, CSS\n\nExemple: le RIATE\n\n\n\n\n\nArribas-Bel, D, 2018. “Geography and Computers: Past, Present, and Future” Geography Compass."
  },
  {
    "objectID": "slides/introduction.html#principe-dun-langage-open-source",
    "href": "slides/introduction.html#principe-dun-langage-open-source",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Principe d’un langage open source",
    "text": "Principe d’un langage open source\n\n\n\n\n\n\nPrincipe général\n\n\n\n\n\n\n\nIllustration avec R"
  },
  {
    "objectID": "slides/introduction.html#quest-ce-que-r",
    "href": "slides/introduction.html#quest-ce-que-r",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Qu’est-ce que R ?",
    "text": "Qu’est-ce que R ?\n\nLogiciel statistique open source:\n\nLangage de base\nPackages étendent les fonctionnalités\n\n\n\n\nAdoption importante dans le monde académique et l’administration\n\n\n\n\nBeaucoup de ressources d’aide en ligne\n\n\n\n\n\n\n\nNote\n\n\n\nNaissance dans les années 1990 ;\nSuccès depuis les années 2010 (succès parallèle à Python)"
  },
  {
    "objectID": "slides/introduction.html#un-logiciel-couteau-suisse",
    "href": "slides/introduction.html#un-logiciel-couteau-suisse",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Un logiciel couteau-suisse",
    "text": "Un logiciel couteau-suisse\n\nManipulation de données de tout type ;\n\n\n\nVisualisation de données (dataviz), cartographie & SIG ;\n\n\n\n\nModélisation (machine learning, analyse de réseaux…) ;\n\n\n\n\nRédaction de mémoires, de site web, de slides (comme celles-ci 🤓)…"
  },
  {
    "objectID": "slides/introduction.html#un-logiciel-couteau-suisse-1",
    "href": "slides/introduction.html#un-logiciel-couteau-suisse-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Un logiciel couteau-suisse",
    "text": "Un logiciel couteau-suisse\nOn peut tout faire en R:\n\nExtrait de R for data science (la bible)"
  },
  {
    "objectID": "slides/introduction.html#transparence-et-reproductibilité",
    "href": "slides/introduction.html#transparence-et-reproductibilité",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Transparence et reproductibilité",
    "text": "Transparence et reproductibilité\n\nTraçabilité des statistiques et réalisations graphiques\n\n\n\nPartage de code R permet une transparence méthodologique:\n\nDe plus en plus de journaux exigent les codes !\nEncore des progrès à faire dans le domaine\n\n\n\n\n\nL’utilisation de R Markdown rend plus efficace 🐢🔜🐇:\n\nSuppression des fichiers intermédiaires (texte, excel, images…)\nGain de temps sur la mise en page (des millions d’heures économisées au bas mot)\n\n\n\n\n\n\n\n\nNote\n\n\nVoir cours dédié sur le sujet des bonnes pratiques (Insee très impliquée sur le sujet!)"
  },
  {
    "objectID": "slides/introduction.html#une-communauté-dutilisateurs",
    "href": "slides/introduction.html#une-communauté-dutilisateurs",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Une communauté d’utilisateurs",
    "text": "Une communauté d’utilisateurs\n\nUn logiciel opensource :\n\nGratuit, collaboratif\n\n\n\n\nBeaucoup de packages:\n\nsur le CRAN (The Comprehensive R Archive Network)\nsur Github\n\n\n\n\n\nUne communauté d’idéalistes de la science ouverte\n\n\n\n\nUn pont vers les autres disciplines : sociologie, économie, biologie, sciences politiques etc."
  },
  {
    "objectID": "slides/introduction.html#le-ssp-cloud-cest-quoi",
    "href": "slides/introduction.html#le-ssp-cloud-cest-quoi",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le SSP Cloud, c’est quoi ?",
    "text": "Le SSP Cloud, c’est quoi ?"
  },
  {
    "objectID": "slides/introduction.html#le-ssp-cloud-cest-quoi-1",
    "href": "slides/introduction.html#le-ssp-cloud-cest-quoi-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le SSP Cloud, c’est quoi ?",
    "text": "Le SSP Cloud, c’est quoi ?\n\nDes serveurs hébergés à l’Insee avec de nombreux logiciels statistiques (dont R) dessus\nEnvironnement ouvert aux agents de l’Etat et à des formations en data science pour découvrir et expérimenter\nSeulement avec des données en open data\n\n\n\n\n\n\n\nNote\n\n\nPlus de détails dans la documentation du SSP Cloud ou dans utilitR"
  },
  {
    "objectID": "slides/introduction.html#pourquoi-utiliser-le-ssp-cloud",
    "href": "slides/introduction.html#pourquoi-utiliser-le-ssp-cloud",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Pourquoi utiliser le SSP Cloud ?",
    "text": "Pourquoi utiliser le SSP Cloud ?\n\nPénible d’installer R, RStudio et une ribambelle de packages\nMise à disposition d’un environnement standardisé:\n\nTP parfaitement reproductibles\n\nUn TP peut être lancé en un clic-bouton:\n\nExemple bouton TO DO"
  },
  {
    "objectID": "slides/introduction.html#créer-un-compte",
    "href": "slides/introduction.html#créer-un-compte",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Créer un compte",
    "text": "Créer un compte\n\nUtiliser votre adresse @ens.fr pour créer un compte sur https://datalab.sspcloud.fr/\nVotre nom d’utilisateur ne doit contenir ni caractères accentués, ni caractère spécial, ni signe de ponctuation:\n\n\nVous pouvez adopter le format prenomnom en faisant attention aux règles précédentes. Par exemple, si vous vous appelez Jérôme-Gérard L’Hâltère, votre nom d’utilisateur pourra être jeromegerardlhaltere."
  },
  {
    "objectID": "slides/introduction.html#lancer-un-service-rstudio",
    "href": "slides/introduction.html#lancer-un-service-rstudio",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Lancer un service RStudio",
    "text": "Lancer un service RStudio\nAide-mémoire\n\nCliquer à gauche sur Catalogue de service"
  },
  {
    "objectID": "slides/introduction.html#lancer-un-service-rstudio-1",
    "href": "slides/introduction.html#lancer-un-service-rstudio-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Lancer un service RStudio",
    "text": "Lancer un service RStudio\nAide-mémoire\n\nLaisser les options par défaut de RStudio"
  },
  {
    "objectID": "slides/introduction.html#lancer-un-service-rstudio-2",
    "href": "slides/introduction.html#lancer-un-service-rstudio-2",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Lancer un service RStudio",
    "text": "Lancer un service RStudio\nAide-mémoire\n\nRécupérer le mot de passe des services RStudio"
  },
  {
    "objectID": "slides/introduction.html#lancer-un-service-rstudio-3",
    "href": "slides/introduction.html#lancer-un-service-rstudio-3",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Lancer un service RStudio",
    "text": "Lancer un service RStudio\nAide-mémoire\n\nAutre manière de récupérer le mot de passe des services RStudio"
  },
  {
    "objectID": "slides/introduction.html#lancer-un-service-rstudio-4",
    "href": "slides/introduction.html#lancer-un-service-rstudio-4",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Lancer un service RStudio",
    "text": "Lancer un service RStudio\nAide-mémoire\n\nS’authentifier sur le service"
  },
  {
    "objectID": "slides/introduction.html#linterface-rstudio",
    "href": "slides/introduction.html#linterface-rstudio",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "L’interface RStudio",
    "text": "L’interface RStudio\n\nIllustration empruntée à ce livre"
  },
  {
    "objectID": "slides/wrangling.html#chapitre-introductif",
    "href": "slides/wrangling.html#chapitre-introductif",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Chapitre introductif",
    "text": "Chapitre introductif\n\n\n\n\n\n\nNote\n\n\n\nExercices associés à ce chapitre ici\n\n\n\n\n\n\nRetour à la page principale"
  },
  {
    "objectID": "slides/wrangling.html#introduction",
    "href": "slides/wrangling.html#introduction",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Introduction",
    "text": "Introduction\n\n centré autour du dataframe\n\n\n\nMais manipulations parfois un peu lourdes :\n\ndf$var: un peu lourd\ndf[,]: un peu trop calqué sur les matrices\n\n\n\n\n\nDonnées textuelles: une base perfectible\n\nDes outputs alambiqués\nDes fonctionnalités manquantes par rapport à Python"
  },
  {
    "objectID": "slides/wrangling.html#la-réponse-le-tidyverse",
    "href": "slides/wrangling.html#la-réponse-le-tidyverse",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "La réponse: le tidyverse !",
    "text": "La réponse: le tidyverse !\n\nL’écosystème du tidyverse"
  },
  {
    "objectID": "slides/wrangling.html#la-réponse-le-tidyverse-1",
    "href": "slides/wrangling.html#la-réponse-le-tidyverse-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "La réponse: le tidyverse !",
    "text": "La réponse: le tidyverse !\nUn ensemble de packages développés par RStudio qui facilite :\n\nLa lecture (readr) et la manipulation de bases de données (dplyr)\nL’exploitation de données textuelles (stringr), temporelles (lubridate) ou catégorielles (forcats)\nLa création de graphiques (ggplot2)\nLa programmation à partir de dataframes (purrr)\nEt bien d’autres choses…"
  },
  {
    "objectID": "slides/wrangling.html#le-concept-de-données-tidy",
    "href": "slides/wrangling.html#le-concept-de-données-tidy",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le concept de données tidy",
    "text": "Le concept de données tidy\n\nChaque variable possède sa propre colonne ;\nChaque observation possède sa propre ligne ;\nUne valeur, matérialisant une observation d’une variable, se trouve sur une unique cellule.\n\n\n\n\n\n\n\nNote\n\n\nConcept popularisé par Hadley Wickham."
  },
  {
    "objectID": "slides/wrangling.html#readr",
    "href": "slides/wrangling.html#readr",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "readr",
    "text": "readr\n\n\nLe package pour lire des fichiers plats (.csv, .txt…)\nPermet d’obtenir un tibble, le dataframe augmenté du tidyverse"
  },
  {
    "objectID": "slides/wrangling.html#dplyr",
    "href": "slides/wrangling.html#dplyr",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "dplyr",
    "text": "dplyr\n\n\nLe package central de l’écosystème de manipulation de données ;\nManipulation de données et statistiques descriptives ;"
  },
  {
    "objectID": "slides/wrangling.html#dplyr-1",
    "href": "slides/wrangling.html#dplyr-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "dplyr",
    "text": "dplyr\nPrincipaux verbes\nOn travaille sur un tibble (dataframe augmenté)\n\nselect() : sélectionner des variables par leur nom ;\nrename() : renommer des variables ;\nfilter() : sélectionner des observations selon une ou plusieurs conditions ;\narrange() : trier la table selon une ou plusieurs variables ;\nmutate() : ajouter des variables qui sont fonction d’autres variables ;\nsummarise() : calculer une statistique à partir de données ;\ngroup_by() : faire des opérations par groupe.- `"
  },
  {
    "objectID": "slides/wrangling.html#dplyr-2",
    "href": "slides/wrangling.html#dplyr-2",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "dplyr",
    "text": "dplyr\nManipulation de données\nOn enchaine des séquences avec les pipe (%&gt;%)\n\nlibrary(doremifasol)\nlibrary(dplyr)\n\nbase_publique_equipements &lt;- telechargerDonnees(\"BPE_ENS\")\nbase_publique_equipements %&gt;%\n1  as_tibble() %&gt;%\n2  filter(TYPEQU == \"B316\") %&gt;%\n3  mutate(x = paste0(AN, \"_\", NB_EQUIP))\n\n\n1\n\nOn convertit le dataframe standard en tibble\n\n2\n\nOn ne garde que les stations services (valeurs B316 de TYPEQU)\n\n3\n\nOn crée une nouvelle colonne en faisant référence à celles existantes (sans guillemets!)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nPlus de détails dans utilitR"
  },
  {
    "objectID": "slides/wrangling.html#dplyr-3",
    "href": "slides/wrangling.html#dplyr-3",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "dplyr",
    "text": "dplyr\nStatistiques agrégées\n\nLogique du split-apply-combine avec groupby\n\n\n\nIllustration du split-apply-combine\n\n\n\n\nlibrary(doremifasol)\nlibrary(dplyr)\n\nbase_publique_equipements &lt;- telechargerDonnees(\"BPE_ENS\")\nbase_publique_equipements %&gt;%\n1  as_tibble() %&gt;%\n2  filter(TYPEQU == \"B316\") %&gt;%\n3  group_by(DEP) %&gt;%\n4  summarise(nombre_station_serv = sum(NB_EQUIP, na.rm = TRUE))\n\n\n1\n\nOn convertit le dataframe standard en tibble\n\n2\n\nOn ne garde que les stations services (valeurs B316 de TYPEQU)\n\n3\n\nOn définit DEP comme une variable de stratification pour définir des groupes\n\n4\n\nOn résume les données en faisant la somme des stations services dans chaque groupe"
  },
  {
    "objectID": "slides/wrangling.html#ggplot",
    "href": "slides/wrangling.html#ggplot",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "ggplot",
    "text": "ggplot\n\n\nLe package indispensable pour faire des graphiques ❤️ ;\nApproche cohérente et flexible basée sur la grammaire des graphiques\n\nObjet d’un chapitre dédié"
  },
  {
    "objectID": "slides/wrangling.html#stringr-forcats-et-lubridate",
    "href": "slides/wrangling.html#stringr-forcats-et-lubridate",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "stringr, forcats et lubridate",
    "text": "stringr, forcats et lubridate\n\n  \n\n\nPlein de fonctions facilitant la manipulation:\n\nDonnées textuelles: stringr\nDonnées catégorielles: forcats\nDonnées temporelles: lubridate"
  },
  {
    "objectID": "slides/wrangling.html#généralités",
    "href": "slides/wrangling.html#généralités",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Généralités",
    "text": "Généralités\n\nDonnées peuvent être stockées dans de nombreux formats différents\n\nStandards différents\nManières d’importer différentes\n\n\n\n\nFonctionnalités de  limitées:\n\nPackages spécialisés pour certains formats\nObjectif: applatir l’information dans un dataframe\n\n\n\n\n\n\n\n\nNote\n\n\nOn verra les formats géographiques, et leurs enjeux, ultérieurement"
  },
  {
    "objectID": "slides/wrangling.html#le-csv",
    "href": "slides/wrangling.html#le-csv",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le CSV",
    "text": "Le CSV\n\nFormat de fichier plat avec des colonnes délimitées:\n\nStandard: , en délimitateur, . en décimale ;\nVariante européenne 😮‍💨: ; en délimitateur, , en décimale\n\nFormat universel, simple d’utilisation (quelques limites)\n\n\nviewof info_csv = Inputs.radio(\n  [\"Fichier brut\", \"Ficher après import\"], {value: \"Fichier brut\"}\n)\n\n\n\n\n\n\n\ninfo_csv == \"Fichier brut\" ? html`&lt;div&gt;${md_csv}&lt;div&gt;` : html`&lt;div&gt;${df_csv}&lt;div&gt;`\n\n\n\n\n\n\n\ndf_csv = Inputs.table(\n  d3.csvParse(raw_csv)\n)\nmd_csv = md`\n\\`\\`\\`\n${raw_csv}\n\\`\\`\\`\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nraw_csv = `DEP,REG,CHEFLIEU,TNCC,NCC,NCCENR,LIBELLE\n01,84,01053,5,AIN,Ain,Ain\n02,32,02408,5,AISNE,Aisne,Aisne\n03,84,03190,5,ALLIER,Allier,Allier\n04,93,04070,4,ALPES DE HAUTE PROVENCE,Alpes-de-Haute-Provence,Alpes-de-Haute-Provence\n05,93,05061,4,HAUTES ALPES,Hautes-Alpes,Hautes-Alpes\n06,93,06088,4,ALPES MARITIMES,Alpes-Maritimes,Alpes-Maritimes\n`"
  },
  {
    "objectID": "slides/wrangling.html#le-csv-1",
    "href": "slides/wrangling.html#le-csv-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le CSV",
    "text": "Le CSV\n\nLecture avec la fonction read_csv du package readr!\n\n\n1library(readr)\n2read_csv(\"dossier_donnees/nom_fichier.csv\")\n\n\n1\n\nOn importe la librairie readr pour avoir accès à la fonction read_csv\n\n2\n\nOn utilise read_csv pour lire les données stockées dans le chemin relatif dossier_donnees/nom_fichier.csv\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nCSV avec délimitateur ;: fonction read_csv2.\nFormats plats plus exotiques (.txt par exemple): read_delim\n\nPlus de détails dans la documentation utilitR"
  },
  {
    "objectID": "slides/wrangling.html#le-json",
    "href": "slides/wrangling.html#le-json",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le JSON",
    "text": "Le JSON\n\nLe format du web, notamment des API\n\nAPI: on verra ça plus tard\n\n\n\nviewof info_json = Inputs.radio(\n  [\"Fichier brut\", \"Ficher après import\"], {value: \"Fichier brut\"}\n)\n\n\n\n\n\n\n\ninfo_json == \"Fichier brut\" ? html`&lt;div&gt;${md_json}&lt;div&gt;` : html`&lt;div&gt;${df_json}&lt;div&gt;`\n\n\n\n\n\n\n\njson_string = `[\n  {\"DEP\": \"01\", \"REG\": \"84\", \"CHEFLIEU\": \"01053\", \"TNCC\": \"5\", \"NCC\": \"AIN\", \"NCCENR\": \"Ain\", \"LIBELLE\": \"Ain\"},\n  {\"DEP\": \"02\", \"REG\": \"32\", \"CHEFLIEU\": \"02408\", \"TNCC\": \"5\", \"NCC\": \"AISNE\", \"NCCENR\": \"Aisne\", \"LIBELLE\": \"Aisne\"},\n  {\"DEP\": \"03\", \"REG\": \"84\", \"CHEFLIEU\": \"03190\", \"TNCC\": \"5\", \"NCC\": \"ALLIER\", \"NCCENR\": \"Allier\", \"LIBELLE\": \"Allier\"},\n  {\"DEP\": \"04\", \"REG\": \"93\", \"CHEFLIEU\": \"04070\", \"TNCC\": \"4\", \"NCC\": \"ALPES DE HAUTE PROVENCE\", \"NCCENR\": \"Alpes-de-Haute-Provence\", \"LIBELLE\": \"Alpes-de-Haute-Provence\"},\n  {\"DEP\": \"05\", \"REG\": \"93\", \"CHEFLIEU\": \"05061\", \"TNCC\": \"4\", \"NCC\": \"HAUTES ALPES\", \"NCCENR\": \"Hautes-Alpes\", \"LIBELLE\": \"Hautes-Alpes\"},\n  {\"DEP\": \"06\", \"REG\": \"93\", \"CHEFLIEU\": \"06088\", \"TNCC\": \"4\", \"NCC\": \"ALPES MARITIMES\", \"NCCENR\": \"Alpes-Maritimes\", \"LIBELLE\": \"Alpes-Maritimes\"}\n]`\nraw_json = [\n  {\"DEP\": \"01\", \"REG\": \"84\", \"CHEFLIEU\": \"01053\", \"TNCC\": \"5\", \"NCC\": \"AIN\", \"NCCENR\": \"Ain\", \"LIBELLE\": \"Ain\"},\n  {\"DEP\": \"02\", \"REG\": \"32\", \"CHEFLIEU\": \"02408\", \"TNCC\": \"5\", \"NCC\": \"AISNE\", \"NCCENR\": \"Aisne\", \"LIBELLE\": \"Aisne\"},\n  {\"DEP\": \"03\", \"REG\": \"84\", \"CHEFLIEU\": \"03190\", \"TNCC\": \"5\", \"NCC\": \"ALLIER\", \"NCCENR\": \"Allier\", \"LIBELLE\": \"Allier\"},\n  {\"DEP\": \"04\", \"REG\": \"93\", \"CHEFLIEU\": \"04070\", \"TNCC\": \"4\", \"NCC\": \"ALPES DE HAUTE PROVENCE\", \"NCCENR\": \"Alpes-de-Haute-Provence\", \"LIBELLE\": \"Alpes-de-Haute-Provence\"},\n  {\"DEP\": \"05\", \"REG\": \"93\", \"CHEFLIEU\": \"05061\", \"TNCC\": \"4\", \"NCC\": \"HAUTES ALPES\", \"NCCENR\": \"Hautes-Alpes\", \"LIBELLE\": \"Hautes-Alpes\"},\n  {\"DEP\": \"06\", \"REG\": \"93\", \"CHEFLIEU\": \"06088\", \"TNCC\": \"4\", \"NCC\": \"ALPES MARITIMES\", \"NCCENR\": \"Alpes-Maritimes\", \"LIBELLE\": \"Alpes-Maritimes\"}\n]\nmd_json = md`\n\\`\\`\\`\n${json_string}\n\\`\\`\\`\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndf_json = Inputs.table(raw_json)"
  },
  {
    "objectID": "slides/wrangling.html#le-json-1",
    "href": "slides/wrangling.html#le-json-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le JSON",
    "text": "Le JSON\n\nImporté comme une liste hiérarchisée\nObjectif: transformer cette information dans un dataframe tidy\n\nPas toujours évident !\n\n\n\n1library(jsonlite)\n2df &lt;- fromJSON(file=\"dossier_donnees/nom_fichier.json\")\n\n\n1\n\nOn importe la librairie jsonlite pour avoir accès à la fonction fromJSON\n\n2\n\nOn utilise fromJSON pour lire les données stockées dans le chemin relatif dossier_donnees/nom_fichier.csv"
  },
  {
    "objectID": "slides/wrangling.html#les-formats-excel",
    "href": "slides/wrangling.html#les-formats-excel",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Les formats Excel",
    "text": "Les formats Excel"
  },
  {
    "objectID": "slides/wrangling.html#les-formats-excel-1",
    "href": "slides/wrangling.html#les-formats-excel-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Les formats Excel",
    "text": "Les formats Excel\n\nFormat propriétaire\nMélange mise en forme et données brute\n\nPas approprié pour l’analyse de données\nDangereux pour la reproductibilité et la transparence\n\nPlus de détails sur utilitR"
  },
  {
    "objectID": "slides/wrangling.html#le-pipe-magrittr-1",
    "href": "slides/wrangling.html#le-pipe-magrittr-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le pipe magrittr (%>%)",
    "text": "Le pipe magrittr (%&gt;%)\nUne manière de chaîner les opérations\n\n\nFonctions emboitéesAvec le pipe\n\n\nlibrary(dplyr)\nlibrary(doremifasol)\n\ndf &lt;- filter(\n  as_tibble(telechargerDonnees(\"BPE_ENS\")),\n  TYPEQU == \"B316\"\n)\n\nsummarise(\n  group_by(df, DEP),\n  nombre_station_serv = sum(NB_EQUIP, na.rm = TRUE)\n)\n\n\nlibrary(dplyr)\nlibrary(doremifasol)\n\ntelechargerDonnees(\"BPE_ENS\") %&gt;%\n  as_tibble() %&gt;%\n  filter(TYPEQU == \"B316\") %&gt;% \n  group_by(DEP) %&gt;% \n  summarise(nombre_station_serv = sum(NB_EQUIP, na.rm = TRUE)) \n\n\n\n\n\nIntroduction aux méthodes quantitatives avec , École Normale Supérieure (retour page principale)"
  },
  {
    "objectID": "slides/geospatial.html#chapitre-introductif",
    "href": "slides/geospatial.html#chapitre-introductif",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Chapitre introductif",
    "text": "Chapitre introductif\n\n\n\n\n\n\nNote\n\n\n\nExercices associés à ce chapitre ici\n\n\n\n\n\n\nRetour à la page principale"
  },
  {
    "objectID": "slides/geospatial.html#introduction",
    "href": "slides/geospatial.html#introduction",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Introduction",
    "text": "Introduction\n\ndplyr facilite l’analyse de données avec \n\n\n\nMais les données géographiques sont plus complexes:\n\nDonnées classiques associées à des objets géométriques\nBesoin de faire des opérations géométriques (fusion, dissolution…)\n\n\n\n\n\nSIG offrent une approche cohérente pour ce type d’opération\n\n peut se comporter comme un SIG !"
  },
  {
    "objectID": "slides/geospatial.html#la-réponse-le-package-sf",
    "href": "slides/geospatial.html#la-réponse-le-package-sf",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "La réponse: le package sf !",
    "text": "La réponse: le package sf !\n\n\n\nsf, une association de tables de données classiques à des géométries\n\n\n\n\n\nL’écosystème du tidyverse"
  },
  {
    "objectID": "slides/geospatial.html#la-réponse-le-package-sf-1",
    "href": "slides/geospatial.html#la-réponse-le-package-sf-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "La réponse: le package sf !",
    "text": "La réponse: le package sf !\n\nExtension de dplyr pour les données spatiales\n\nVerbes dplyr fonctionnent de la même manière\nOpérations géométriques grâce à GDAL en arrière plan\n\n\nUn tibble amélioré:\n{fig-align = “center”}"
  },
  {
    "objectID": "slides/geospatial.html#anatomie-dun-objet-sf",
    "href": "slides/geospatial.html#anatomie-dun-objet-sf",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Anatomie d’un objet sf",
    "text": "Anatomie d’un objet sf\nLes attributs\n\nValeurs associées à chaque niveau géographique\n\nDonnée tabulaire classique\ndplyr fonctionne normalement\n\n\n\nimport {download_vectorfile} from \"@linogaliana/cartiflette-js\"\nbertin = require(\"bertin@latest\")\n\ndf = download_vectorfile({\n      \"value\": \"92\",\n      \"crs\": 4326,\n      \"borders\": \"COMMUNE\",\n      \"vectorfile_format\": \"geojson\",\n      \"filter_by\": \"DEPARTEMENT\",\n      \"source\": \"EXPRESS-COG-CARTO-TERRITOIRE\",\n      \"year\": 2022\n  })\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInputs.table(\n  bertin.properties.table(df),\n  {columns: [\"NOM\",\"POPULATION\"]}\n)"
  },
  {
    "objectID": "slides/geospatial.html#anatomie-dun-objet-sf-1",
    "href": "slides/geospatial.html#anatomie-dun-objet-sf-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Anatomie d’un objet sf",
    "text": "Anatomie d’un objet sf\nLes géométries\n\nValeurs numériques interprétées pour représenter la dimension géographique\n\nPlusieurs types d’objets: points, polygones, lignes…\nOpérations sur géométries grâce à sf\n\n\n\n\n\n\n\n\nIllustration de st_union\n\n\n\n\n\n\n\nIllustration de st_union"
  },
  {
    "objectID": "slides/geospatial.html#projection",
    "href": "slides/geospatial.html#projection",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Anatomie d’un objet sf",
    "text": "Anatomie d’un objet sf\nLe système de référence de l’objet\n\n\n\n\nPosition sur terre \\(\\to\\) position dans le plan \nMultitude de projections (cf. suite)\nGestion cohérente grâce à sf\n\nUtilise les codes EPSG (4326, 2154…)\nDéfinition souvent automatique\nReprojections facilitées avec st_transform\n\n\n\n\n\nst_crs(communes_borders)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]"
  },
  {
    "objectID": "slides/geospatial.html#principe",
    "href": "slides/geospatial.html#principe",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Principe",
    "text": "Principe\n\n\n\nReprésentation dans un plan (2D) d’une surface arrondie en 3D\nThéorème remarquable de Gauss: la surface de la Terre ne peut être cartographiée sans distortion.\nMultitude de projections possibles\n\n\n\n\n\n\n\nExemple: projection de Mercator\n\n\nPréserve les angles mais ne conserve pas les surfaces et leurs proportions relatives (cf. site thetruesize.com).\n\n\n\n\n\nhtml`&lt;div&gt;${container_projection}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\ncontainer_projection = html`&lt;div class=\"container\"&gt;\n  &lt;div class=\"row\"&gt;\n    &lt;div class=\"projection\"&gt;\n      &lt;div class=\"projection-label\"&gt;Choisir une projection&lt;/div&gt;\n      ${viewof projection}\n    &lt;/div&gt;\n  &lt;/div&gt;\n  &lt;div class=\"row\"&gt;\n    &lt;div class=\"projectedMap\"&gt;\n      ${projectedMap}\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\nviewof projection = projectionInput({\n  name: \"\",\n  value: \"Mercator\"\n})\n\n\n\n\n\n\n\nimport {projectionInput} from \"@fil/d3-projections\"\nimport {map} from \"@linogaliana/base-map\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprojectedMap = map(projection,\n                   {\n                     //svg: true,\n                     value: projection.options,\n                     width: width_projected_map,\n                     //height: 300,\n                     //rotate: [0, -90],\n                     //inertia: true,\n                     show_equator: true,\n                     background: \"#f1f0eb\"\n                     \n                     //show_structure: true\n                   })\n\n\n\n\n\n\n\nwidth_projected_map = screen.width/4"
  },
  {
    "objectID": "slides/geospatial.html#web-mercator-wgs-84-4326",
    "href": "slides/geospatial.html#web-mercator-wgs-84-4326",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "(Web) Mercator / WGS 84 (4326)",
    "text": "(Web) Mercator / WGS 84 (4326)\n\n\n\nProjection la plus usuelle:\n\nSystème GPS (position précise depuis des satellites grâce conservation des angles)\nFonds de carte web Google, OpenStreetMap…\n\nMais déforme les distances et superficies\n\n\n\n\n\n\n\nAstuce pour la France\n\n\n\nLongitude (\\(x\\)) tourne autour de 0° (de -5.2 à +9.6 pour être plus précis)\nLa latitude (\\(y\\)) autour de 45 (entre +41.3 à +51.1)\n\nPlus de détails\n\n\n\n\n\nsize = 400\nhtml`&lt;iframe width=\"${size}\" height=\"${size*1.15 + 50}\" frameborder=\"0\"   overflow-x = \"hidden\" overflow-Y=\"hidden\"\n  src=\"https://observablehq.com/embed/@neocartocnrs/impact-of-projections-on-areas?cells=map%2Cviewof+mycountry\"&gt;&lt;/iframe&gt;`"
  },
  {
    "objectID": "slides/geospatial.html#lambert-93-2154",
    "href": "slides/geospatial.html#lambert-93-2154",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Lambert 93 (2154)",
    "text": "Lambert 93 (2154)\n\nProjection officielle pour la métropole\n\nProjection conique\nD’autres Lambert pour les DROM\n\n\n\n\nOrthonormée, centrée sur la métropole\n\nOn peut faire des calculs de distance sur des coordonnées\nDistance en mètres = distance euclidienne (\\(\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}\\))\n\n\n\n\n\n\n\n\nAstuce pour la France\n\n\n\nCoordonnées \\(x\\): entre 100 000 et 1 300 000\nLa latitude (\\(y\\)): entre 6 000 000 et 7 200 000\n\nPlus de détails"
  },
  {
    "objectID": "slides/geospatial.html#la-projection-de-spilhaus",
    "href": "slides/geospatial.html#la-projection-de-spilhaus",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "La projection de Spilhaus",
    "text": "La projection de Spilhaus\nLe monde vu par les poissons 🐟🐡🐠\n\nhtml`&lt;div class=\"centered\"&gt;${spilhaus}&lt;/div&gt;`\n\n\n\n\n\n\n\nspilhaus = {\n  const width = 600;\n  const height = width;\n\n  const context = DOM.context2d(width, height);\n  const projection = d3.geoStereographic()\n    .rotate([95, 45])\n    .translate([width / 2, height / 2])\n    .scale(width / 10.1)\n    .center([30, -5])\n    .clipAngle(166);\n  const path = d3.geoPath(projection, context);\n\n  const land = topojson.feature(world, world.objects.land);\n\n  context.lineJoin = \"round\";\n  context.lineCap = \"round\";\n  context.fillStyle = \"#f2f1ed\";\n  context.fillRect(0, 0, width, height);\n\n  context.beginPath();\n  path({type: \"Sphere\"});\n  path(land);\n  context.lineWidth = 0.5;\n  context.stroke();\n  context.clip(\"evenodd\");\n\n  context.save();\n  context.beginPath();\n  path(land);\n  context.filter = \"blur(12px)\";\n  context.fillStyle = \"#006994\";\n  context.fill(\"evenodd\");\n  context.restore();\n  \n  context.beginPath();\n  path(d3.geoGraticule10());\n  context.globalAlpha = 0.2;\n  context.strokeStyle = \"#000\";\n  context.stroke();\n\n  return context.canvas;\n}\n\n\n\n\n\n\n\n//import {map as spilhausmap} with {height, width} from \"@d3/spilhaus-shoreline-map\"\nimport { world } from \"@d3/spilhaus-shoreline-map\"\n\n\n\n\n\n\n\n\nIntroduction aux méthodes quantitatives avec , École Normale Supérieure (retour page principale)"
  },
  {
    "objectID": "exercises/geospatial-wrangling.html",
    "href": "exercises/geospatial-wrangling.html",
    "title": "Manipuler des données spatiales avec sf",
    "section": "",
    "text": "Dans ce TP, nous allons apprendre à importer et manipuler des données spatiales avec .\nCe logiciel propose des fonctionnalités très intéressantes pour ce type de données complexes qui le rendent capable de se comporter comme un SIG. Grâce à la librairie sf, une extension de dplyr aux données spatiales, les données géographiques pourront être manipulées comme n’importe quel type de données avec . La complexité induite par la dimension spatiale ne sera pas ressentie.\nSi vous êtes intéressés par Python , une version très proche de ce TP est disponible dans mon cours de l’ENSAE.\nDans ce chapitre, nous allons utiliser les packages suivants:\nlibrary(units)\nlibrary(dplyr)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(mapsf)\nlibrary(leaflet)\nlibrary(cartiflette)\nCe chapitre illustre à partir d’exemples pratiques certains principes centraux de l’analyse de données:"
  },
  {
    "objectID": "exercises/geospatial-wrangling.html#découverte-des-objets-géographiques",
    "href": "exercises/geospatial-wrangling.html#découverte-des-objets-géographiques",
    "title": "Manipuler des données spatiales avec sf",
    "section": "1 Découverte des objets géographiques",
    "text": "1 Découverte des objets géographiques\nDans cette partie, nous utiliserons les fonds de carte de l’IGN dont la mise à disposition est facilitée par le projet cartiflette1.\n\n\n\n\n\n\nExercice 1: découverte des objets géographiques\n\n\n\nEn premier lieu, on récupère des données géographiques grâce au package cartiflette.\n\nUtiliser le code ci-dessous pour télécharger les données communales (produit Admin Express de l’IGN) des départements de la petite couronne (75, 92, 93 et 94) de manière simplifiée grâce au package cartiflette:\n\n\n# 1. Chargement des données de cartiflette\ncommunes_borders &lt;- download_vectorfile_url_all(\n    crs = 4326,\n    values = c(\"75\", \"92\", \"93\", \"94\"),\n    borders=\"COMMUNE\",\n    vectorfile_format=\"geojson\",\n    filter_by=\"DEPARTEMENT\",\n    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n    year=2022)\n\n\nRegarder les premières lignes des données. Identifier la différence avec un dataframe standard.\n\n\n\nPremières lignes des données\n\n\n\nSimple feature collection with 6 features and 12 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2.169349 ymin: 48.80894 xmax: 2.469851 ymax: 48.92685\nGeodetic CRS:  WGS 84\n                        ID              NOM            NOM_M INSEE_COM\n1 COMMUNE_0000000009736048            Paris            PARIS     75056\n2 COMMUNE_0000000009736037 Levallois-Perret LEVALLOIS-PERRET     92044\n3 COMMUNE_0000000009736055    Bois-Colombes    BOIS-COLOMBES     92009\n4 COMMUNE_0000000009736538         Malakoff         MALAKOFF     92046\n5 COMMUNE_0000000009736038           Clichy           CLICHY     92024\n6 COMMUNE_0000000009736052         Nanterre         NANTERRE     92050\n           STATUT POPULATION INSEE_CAN INSEE_ARR INSEE_DEP INSEE_REG\n1 Capitale d'état    2165423        NR         1        75        11\n2  Commune simple      66082        16         2        92        11\n3  Commune simple      28841        11         2        92        11\n4  Commune simple      30950        18         1        92        11\n5  Commune simple      63089        09         2        92        11\n6      Préfecture      96277        99         2        92        11\n           SIREN_EPCI                           source\n1           200054781 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n2 200054781/200057982 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n3 200054781/200057990 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n4 200054781/200057966 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n5 200054781/200057990 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n6 200054781/200057982 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n                        geometry\n1 POLYGON ((2.364204 48.8164,...\n2 POLYGON ((2.287395 48.90364...\n3 POLYGON ((2.266394 48.90629...\n4 POLYGON ((2.278183 48.81425...\n5 POLYGON ((2.303774 48.89415...\n6 POLYGON ((2.229099 48.90603...\n\n\n\n\nAfficher le crs de communes_borders. Ce dernier contrôle la transformation de l’espace tridimensionnel terrestre en une surface plane. Utiliser st_transform pour transformer les données en Lambert 93, le système officiel (code EPSG 2154).\n\n\nAfficher les communes des Hauts de Seine (département 92) et représenter rapidement la carte.\n\n\nNe conserver que Paris et réprésenter les frontières sur une carte : quel est le problème pour une analyse de Paris intramuros?\n\nOn remarque rapidement le problème. On ne dispose ainsi pas des limites des arrondissements parisiens, ce qui appauvrit grandement la carte de Paris.\n\nCette fois, utiliser l’argument borders=\"COMMUNE_ARRONDISSEMENT\" pour obtenir un fonds de carte consolidé des communes avec les arrondissements dans les grandes villes. Convertir en Lambert 93.\n\n\n\n\n\nSi vous désirez observer l’aspect de la carte du 92 (question 4), déroulez cette partie.\n\n\n\n\n\n\n\n\n\nCarte de Paris attendue à la question 5 et à la question 6\n\nA la question 5, Paris intra-muros est bien pauvre:\n\n\n\n\n\nA l’issue de la question 6, on a bien une carte de la petite couronne avec des arrondissements:"
  },
  {
    "objectID": "exercises/geospatial-wrangling.html#le-système-de-projection",
    "href": "exercises/geospatial-wrangling.html#le-système-de-projection",
    "title": "Manipuler des données spatiales avec sf",
    "section": "2 Le système de projection",
    "text": "2 Le système de projection\nUn concept central dans les logiciels de SIG est la notion de projection. L’exercice précédent imposait parfois certaines projections sans expliquer l’importance de ces choix. , comme tout SIG, permet une gestion cohérente des projections.\nL’exercice suivant vise à introduire aux principales fonctionnalités de  à ce propos. Il illustre les problèmes communs que peuvent rencontrer les géographes dans la gestion des systèmes de projection.\nObservez les variations significatives de proportions pour certains pays selon les projections choisies:\n\nhtml`&lt;div&gt;${container_projection}&lt;/div&gt;`\n\n\n\n\n\n\n\ncontainer_projection = html`&lt;div class=\"container\"&gt;\n  &lt;div class=\"row\"&gt;\n    &lt;div class=\"projection\"&gt;\n      &lt;div class=\"projection-label\"&gt;Choisir une projection&lt;/div&gt;\n      ${viewof projection}\n    &lt;/div&gt;\n  &lt;/div&gt;\n  &lt;div class=\"row\"&gt;\n    &lt;div class=\"projectedMap\"&gt;\n      ${projectedMap}\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\nviewof projection = projectionInput({\n  name: \"\",\n  value: \"Mercator\"\n})\n\n\n\n\n\n\n\nimport {projectionInput} from \"@fil/d3-projections\"\nimport {map} from \"@linogaliana/base-map\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprojectedMap = map(projection,\n                   {\n                     //svg: true,\n                     value: projection.options,\n                     width: width_projected_map,\n                     //height: 300,\n                     //rotate: [0, -90],\n                     //inertia: true,\n                     show_equator: true,\n                     background: \"#f1f0eb\"\n                     \n                     //show_structure: true\n                   })\n\n\n\n\n\n\n\nwidth_projected_map = screen.width/2\n\n\n\n\n\n\n\n\n\n\n\n\nExercice 2: Les projections, représentations et approximations\n\n\n\nVoici un code utilisant encore cartiflette pour récupérer les frontières françaises (découpées par région):\n\nfrance &lt;- download_vectorfile_url_all(\n      values = \"metropole\",\n      crs = 4326,\n      borders = \"REGION\",\n      vectorfile_format=\"geojson\",\n      filter_by=\"FRANCE_ENTIERE\",\n      source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n      year=2022)\n\n\nS’amuser à représenter les limites de la France avec plusieurs projections:\n\n\nMercator WGS84 (EPSG: 4326)\nProjection healpix (+proj=healpix +lon_0=0 +a=1)\nProjection prévue pour Tahiti (EPSG: 3304)\nProjection Albers prévue pour Etats-Unis (EPSG: 5070)\n\n\nUtiliser la fonction st_area sur calculer la superficie en \\(km^2\\) des régions françaises dans les deux systèmes de projection suivants: WGS84 (EPSG: 4326) et Lambert 93 (EPSG: 2154). Calculer la différence en \\(km^2\\) pour chaque région.\n\n\n\nAvec la question 1 illustrant quelques cas pathologiques, on comprend que les projections ont un effet déformant qui se voit bien lorsqu’on les représente côte à côte sous forme de cartes :\n\n\n\n\nComparaison des projections\n\n\nFigure 1: ?(caption)\n\n\nCependant le problème n’est pas que visuel, il est également numérique. Les calculs géométriques amènent à des différences assez notables selon le système de référence utilisé.\n\n\nVoir le tableau des approximations pour chaque région\n\n\n\nSimple feature collection with 13 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 99040 ymin: 6046546 xmax: 1242445 ymax: 7110479\nProjected CRS: RGF93 / Lambert-93\nFirst 10 features:\n                          NOM superficie_4326 superficie_2154         mismatch\n1                   Occitanie 73221.52 [km^2] 73405.65 [km^2] 184.13122 [km^2]\n2             Hauts-de-France 31843.17 [km^2] 32010.92 [km^2] 167.75210 [km^2]\n3                   Grand Est 57547.55 [km^2] 57704.28 [km^2] 156.72959 [km^2]\n4          Nouvelle-Aquitaine 84990.76 [km^2] 85093.94 [km^2] 103.18544 [km^2]\n5                   Normandie 30000.85 [km^2] 30103.70 [km^2] 102.84798 [km^2]\n6  Provence-Alpes-Côte d'Azur 31609.54 [km^2] 31676.26 [km^2]  66.71286 [km^2]\n7        Auvergne-Rhône-Alpes 70736.67 [km^2] 70797.01 [km^2]  60.34424 [km^2]\n8                    Bretagne 27393.22 [km^2] 27446.42 [km^2]  53.20734 [km^2]\n9     Bourgogne-Franche-Comté 47929.07 [km^2] 47980.51 [km^2]  51.44109 [km^2]\n10        Centre-Val de Loire 39419.19 [km^2] 39470.10 [km^2]  50.91416 [km^2]\n                         geometry\n1  MULTIPOLYGON (((449522.3 62...\n2  MULTIPOLYGON (((686066 6888...\n3  MULTIPOLYGON (((983336.7 67...\n4  MULTIPOLYGON (((374733.1 65...\n5  MULTIPOLYGON (((367887.8 68...\n6  MULTIPOLYGON (((961116.4 62...\n7  MULTIPOLYGON (((985059.5 65...\n8  MULTIPOLYGON (((174782.1 67...\n9  MULTIPOLYGON (((880572.7 67...\n10 MULTIPOLYGON (((604790.4 68...\n\n\n\nOn peut représenter ces approximations sur une carte2 pour se faire une idée des régions où l’erreur de mesure est la plus importante.\n\n\n\n\n\nFigure 2: Approximations liées au système de projection WGS 84\n\n\n\n\nCe type d’erreur de mesure est normal à l’échelle du territoire français. Les projections héritères du Mercator déforment les distances, surtout lorqu’on se rapproche de l’équateur ou des pôles.\n\n\n\n\n\n(a) Exemple de reprojection de pays depuis le site thetruesize.com\n\n\n\n\n\n(b) “Don’t trust the Mercator projection” sur Reddit\n\n\nFigure 3: La projection Mercator, une vision déformante\n\n\nPour aller plus loin, la carte interactive suivante, construite par Nicolas Lambert, issue de ce notebook Observable, illustre l’effet déformant de la projection Mercator, et de quelques unes autres, sur notre perception de la taille des pays.\n\n\nVoir la carte interactive\n\n\nhtml`&lt;div class=\"grid-container\"&gt;\n  &lt;div class=\"viewof-projection\"&gt;${viewof projectionBertin}&lt;/div&gt;\n  &lt;div class=\"viewof-mycountry\"&gt;${viewof mycountry}&lt;/div&gt;\n  &lt;div class=\"map-bertin\"&gt;${mapBertin}&lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\n\nimport {map as mapBertin, viewof projection as projectionBertin, viewof mycountry} from \"@neocartocnrs/impact-of-projections-on-areas\"\n\n\n\n\n\n\nIl n’est donc pas suprenant que nos déformations soient exacerbées aux extrèmes du territoire métropolitain. Si les approximations sont légères sur de petits territoires, les erreurs peuvent être non négligeables à l’échelle de la France.\nIl faut donc systématiquement repasser les données dans le système de projection Lambert 93 (le système officiel pour la métropole) avant d’effectuer des calculs géométriques."
  },
  {
    "objectID": "exercises/geospatial-wrangling.html#utiliser-des-données-géographiques-comme-des-couches-graphiques",
    "href": "exercises/geospatial-wrangling.html#utiliser-des-données-géographiques-comme-des-couches-graphiques",
    "title": "Manipuler des données spatiales avec sf",
    "section": "3 Utiliser des données géographiques comme des couches graphiques",
    "text": "3 Utiliser des données géographiques comme des couches graphiques\nSouvent, le découpage communal ne sert qu’en fond de cartes, pour donner des repères. En complément de celui-ci, on peut désirer exploiter un autre jeu de données.\nOn va partir des données de localisation des stations velib, disponibles sur le site d’open data de la ville de Paris et requêtables directement en utilisant un URL\n\nurl &lt;- \"https://opendata.paris.fr/explore/dataset/velib-emplacement-des-stations/download/?format=geojson&timezone=Europe/Berlin&lang=fr\"\n\nDans le prochain exercice, nous proposons de créer rapidement une carte comprenant trois couches:\n\nLes localisations de stations sous forme de points ;\nLes bordures des communes et arrondissements pour contextualiser ;\nLes bordures des départements en traits plus larges pour contextualiser également.\n\nNous irons plus loin dans le travail cartographique dans le prochain chapitre. Mais être en mesure de positionner rapidement ses données sur une carte est toujours utile dans un travail exploratoire.\nEn amont de l’exercice, utiliser la fonction suivante du package cartiflette pour récupérer le fonds de carte des départements de la petite couronne:\n\nidf &lt;- download_vectorfile_url_all(\n      values = \"11\",\n      crs = 4326,\n      borders = \"DEPARTEMENT\",\n      vectorfile_format=\"geojson\",\n      filter_by=\"REGION\",\n      source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n      year=2022)\npetite_couronne_departements &lt;- idf %&gt;%\n  filter(INSEE_DEP %in% c(\"75\",\"92\",\"93\",\"94\"))\n\n\n\n\n\n\n\nExercice 3: importer et explorer les données velib\n\n\n\nOn commence par récupérer les données nécessaires à la production de cette carte.\n\nEn utilisant l’URL précédent, importer les données velib sous le nom station\nVérifier la projection géographique de station (attribut crs). Si celle-ci est différente des données communales, reprojeter ces dernières dans le même système de projection que les stations de vélib\nNe conserver que les 50 principales stations (variable capacity)\n\nOn peut maintenant construire la carte de manière séquentielle avec ggplot\n\nEn premier lieu, grâce à geom_sf, représenter exclusivement les positions des stations et ajuster la taille en fonction de la variable capacity\nAjouter la couche des communes d’arrondissements et des communes\n\nComme ces limites administratives sont stockées dans un dataframe différent, il va falloir utiliser l’argument data\nUtiliser fill = \"transparent\" pour que l’intérieur du polygone ne masque pas nos points\n\nAjouter la couche des départements\nEn supposant que votre objet ggplot s’appelle carte, vous pouvez utiliser le code suivant pour améliorer rapidement l’esthétique\n\ncarte +\n  theme_void() +\n  theme(legend.position = \"bottom\") +\n  guides(color = \"none\", size = guide_legend(title.position=\"top\", title.hjust = 0.5)) +\n  labs(size = \"Capacité de la station\", title = \"Les 50 principales stations de vélib\")\n\n\n\n\nLes stations placées sur un plan, à l’issue de la question 4\n\n\n\n\n\n\n\n\n\nAjout d’une couche d’arrondissements (question 5)\n\n\n\n\n\n\n\n\n\nAjout de la couche des départements (question 6)\n\n\n\n\n\n\n\nLa carte finalisée (question 7), obtenue grâce à une demi-douzaine de lignes de code seulement, est ainsi:"
  },
  {
    "objectID": "exercises/geospatial-wrangling.html#jointures-spatiales",
    "href": "exercises/geospatial-wrangling.html#jointures-spatiales",
    "title": "Manipuler des données spatiales avec sf",
    "section": "4 Jointures spatiales",
    "text": "4 Jointures spatiales\nLes jointures attributaires fonctionnent comme avec un tibble classique. Pour conserver un objet spatial in fine, il faut faire attention à utiliser en premier (base de gauche) l’objet sf. En revanche, l’un des intérêts des objets sf est qu’on peut également faire une jointure sur la dimension spatiale grâce à plusieurs fonctions. Les jointures les plus communes sont:\n\n\n\n\n\n\n\nFonction\nOpération\n\n\n\n\nst_intersects()\nQuelles géométries de x intersectent celles de y ?\n\n\nst_contains()\nQuelles géométries de x contiennent celles de y ?\n\n\nst_disjoint()\nQuelles géométries de x sont disjointes à celles de y ?\n\n\nst_is_within_distance()\nQuelles géométries de x est à moins de m/km de celles de y ?\n\n\n\nLa documentation à laquelle se référer est ici. Une version pédagogique se trouve dans la documentation utilitR.\n\n\n\n\n\n\nExercice 4: Associer les stations aux communes et arrondissements auxquels elles appartiennent\n\n\n\nDans cet exercice, on va supposer que :\n\nles localisations des stations velib sont stockées dans un dataframe nommé stations\nles données administratives sont dans un dataframe nommé petite_couronne.\n\n\nFaire une jointure spatiale pour enrichir les données de stations en y ajoutant des informations de petite_couronne. Appeler cet objet stations_info\nCréer les objets stations_19e et arrondissement_19e pour stocker, respectivement, les stations appartenant au 19e et les limites de l’arrondissement\nReprésenter la carte des stations du 19e arrondissement avec le code suivant:\n\npetite_couronne %&gt;% filter(INSEE_DEP == 75) %&gt;%\n  ggplot() +\n    geom_sf(aes(fill = grepl(\"19e\", NOM)), alpha = 0.1) +\n    geom_sf(data = stations_19e, color = \"royalblue\") +\n    scale_fill_viridis_d() +\n    theme_void() +\n    theme(legend.position = \"none\")\n\nCompter le nombre de stations velib et le nombre de places velib par arrondissement ou commune. Représenter sur une carte chacune des informations\nReprésenter les mêmes informations mais en densité (diviser par la surface de l’arrondissement ou commune en km2)\n(optionnel) Choisir une des cartes de densité et la nettoyer (retirer les axes, mettre les titres…)\n\n\n\n\n\nLa carte obtenue sur la question 2\n\n\n\n\n\n\n\n\n\nUne version interactive produite avec leaflet, que nous découvrirons prochainement.\n\n\n\n\n\n\n\n\n\n\nLa carte obtenue à la question 3\n\n\n\n\n\n\n\nAvec la carte de la question 3, basée sur des aplats de couleurs (choropleth map), le lecteur est victime d’une illusion classique. Les arrondissements les plus visibles sur la carte sont les plus grands. D’ailleurs c’est assez logique qu’ils soient également mieux pourvus en velib. Même si l’offre de velib est probablement plus reliée à la densité de population et d’équipements, on peut penser que l’effet taille joue et qu’ainsi on est victime d’une illusion avec la carte précédente.\nSi on représente plutôt la capacité sous forme de densité, pour tenir compte de la taille différente des arrondissements, les conclusions sont inversées et correspondent mieux aux attentes d’un modèle centr-périphérie. Les arrondissements centraux sont mieux pourvus, cela se voit encore mieux avec des ronds proportionnels plutôt qu’une carte chorolèpthe.\n\n\n\n\n\n\n\n(a) Aplat de couleur\n\n\n\n\n\n\n\n(b) Ronds proportionnels\n\n\n\n\nFigure 4: Densité de velib dans l’agglomération parisienne"
  },
  {
    "objectID": "exercises/geospatial-wrangling.html#exercice-supplémentaire",
    "href": "exercises/geospatial-wrangling.html#exercice-supplémentaire",
    "title": "Manipuler des données spatiales avec sf",
    "section": "5 Exercice supplémentaire",
    "text": "5 Exercice supplémentaire\nLes exercices précédents ont permis de se familiariser au traitement de données spatiales. Néanmoins il arrive de devoir jongler plus avec la dimension géométrique par exemple pour changer d’échelle ou introduire des fusions/dissolutions de géométries.\nImaginons que chaque utilisateur de velib se déplace exclusivement vers la station la plus proche (à supposer qu’il n’y a jamais pénurie ou surcapacité). Quelle est la carte de la couverture des vélibs ? Pour répondre à ce type de question, on utilise fréquemment la la tesselation de Voronoï, une opération classique pour transformer des points en polygones. L’exercice suivant permet de se familiariser avec cette approche3.\n\n\n\n\n\n\nExercice 5: la tesselation de Voronoï\n\n\n\nA l’aide de cet article, créer progressivement votre tesselation de voronoi\n\nConstruire une enveloppe nommée petite_couronne_limites en utilisant la fonction st_union sur notre fonds de carte des communes de la petite couronne\nCréer la tesselation de voronoi en exécutant les étapes suivantes:\n\nNe conserver que les géométries avec st_geometry\nChanger le type d’objet sf sous-jacent avec st_union\nAppliquer la transformation avec st_voronoi\nTransformer ça en objet sf auquel on est plus coutumier avec st_collection_extract(type = \"POLYGON\") puis st_sf()\nAppliquer un masque pour couper les parties extérieures à la petite couronne avec st_intersection(petite_couronne_limites)\nJoindre à nouveau aux données initiales avec st_join(stations_info) pour retrouver les attributs précédents\n\n\n\nDu fait de la densité des stations dans Paris intramuros, une carte au niveau global serait illisible. Il est plus pratique d’avoir une carte web dans laquelle il est possible de naviguer. Utiliser le code suivant pour générer cette carte avec leaflet:\n\n\nvoronoi_velib &lt;- voronoi %&gt;% st_transform(4326) %&gt;%\n  leaflet() %&gt;%\n  addTiles() %&gt;%\n  addPolygons(\n    fillOpacity = 0.1,\n    popup = ~paste0(name, \": \", capacity, \" vélos disponibles\"),\n    stroke = TRUE, weight = 1)\n\n\n\nA vous d’observer la zone de chalandise de la station la plus proche de chez vous :"
  },
  {
    "objectID": "exercises/geospatial-wrangling.html#footnotes",
    "href": "exercises/geospatial-wrangling.html#footnotes",
    "title": "Manipuler des données spatiales avec sf",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLa librairie  est expérimentale mais les prochaines semaines devraient permettre de combler ce manque. Une documentation interactive illustrant le code nécessaire pour reproduire telle ou telle carte est disponible sur linogaliana.github.io/cartiflette-website.↩︎\nCette carte n’est pas trop soignée, c’est normal nous verrons comment faire de belles cartes ultérieurement.↩︎\nDans ce document de travail sur données de téléphonie mobile, on montre néanmoins que cette approche n’est pas sans biais sur des phénomènes où l’hypothèse de proximité spatiale est trop simplificatrice.↩︎"
  },
  {
    "objectID": "exercises/r-base.html",
    "href": "exercises/r-base.html",
    "title": "Découverte des objets de base de ",
    "section": "",
    "text": "Dans ce premier TP, nous allons rentrer tranquillement dans notre parcours de découverte de .\nCela se fera par les étapes suivantes:"
  },
  {
    "objectID": "exercises/r-base.html#numeric",
    "href": "exercises/r-base.html#numeric",
    "title": "Découverte des objets de base de ",
    "section": "2.1 Les vecteurs numériques (numeric)",
    "text": "2.1 Les vecteurs numériques (numeric)\n\n2.1.1 Les deux types de vecteurs numériques\n propose différents types d’objets numériques. Pour l’analyse de données, nous allons principalement nous intéresser principalement à deux types :\n\nles entiers (type int pour integer)\nles nombres réels (type double pour nombres à virgule flottante)\n\nEn pratique, les premiers sont un cas spécial des seconds. Contrairement à d’autres langages,  ne tente pas de contraindre de manière automatique les nombres sans virgules à être des entiers (integers). C’est pratique mais sur de gros volumes de données ça peut poser problème car les double sont plus lourds que les int.\nEn général, on utilise la fonction class pour afficher le type d’un objet  et si on veut être plus précis on peut utiliser typeof:\n\nclass(3)\ntypeof(3)\nclass(3.14)\ntypeof(3.14)\n\nLes fonctions as.numeric et as.integer peuvent être utilisées pour convertir d’un type à l’autre:\n\n# Conversion en int\nas.integer(3.79)\n\n[1] 3\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAttention à la conversion double \\(\\to\\) int, qui tronque la partie décimale.\n\n# double -&gt; int -&gt; double\nas.numeric(\n    as.integer(3.79)\n)\n\n[1] 3\n\n\n\n\nLes floats peuvent également être écrits en notation scientifique :\n\n2e3\n\n[1] 2000\n\nclass(2e3)\n\n[1] \"numeric\"\n\n\n\n\n2.1.2 Opérations arithmétiques de base\n\n\n\n\n\nComme tout langage informatique,  est avant tout une calculette. On est sauvé, on peut donc faire des additions:\n\n# Addition\n8 + 9\n\n[1] 17\n\n\n\n\n\n\n\n\nNote\n\n\n\n est bien fait, il adapte le type des variables pour les mettre en cohérence lorsqu’elles peuvent l’être:\n\n# Addition\n8.1 + as.integer(9)\n\n[1] 17.1\n\n\n\n\nOn a bien-sûr accès à d’autres opérations standards:\n\n# Soustraction\n5 - 2\n\n[1] 3\n\n# Multiplication\n2 * 6\n\n[1] 12\n\n# Division\n9 / 4\n\n[1] 2.25\n\n\nIl faut tout de même faire attention à la division par 0\n\n# Division par 0\n3 / 0\n\n[1] Inf\n\n-5 / 0\n\n[1] -Inf\n\n\n\n\n\n\n\n\nWarning\n\n\n\nCertains langages, comme Python, ne permettent pas la division par 0, ils renvoient une erreur plutôt qu’Inf. C’est un peu piégeux en R car cela peut arriver d’avoir des divisions par 0 sans qu’on s’en rende compte…\n\n\nComme toute calculette, on peut appliquer d’autres types d’opérations\n\n# Division euclidienne : quotient\n9 %/% 4\n\n[1] 2\n\n# Division euclidienne : reste\n9 %% 4\n\n[1] 1\n\n\n\n# Puissance\n2 ^ 5\n\n[1] 32\n\n# Racine carrée\nsqrt(5)\n\n[1] 2.236068\n\n# Log\nlog(2)\n\n[1] 0.6931472\n\n# Exponentielle\nexp(2)\n\n[1] 7.389056\n\n\nL’ordre des opérations suit la convention usuelle:\n\n2 + 5 * (10 - 4)\n\n[1] 32\n\n\n\n\n2.1.3 Vectorisation\nSi on ne pouvait utiliser  qu’en mode calculette peu raffinée, ça ne serait pas un langage très intéressant pour l’analyse de données. L’avantage principal de  est qu’on va pouvoir manipuler des vecteurs, c’est à dire des suites de nombres. On va considérer que les vecteurs sont des suites de nombres ordonnés en une seule colonne:\n\\[\n\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix}\n\\]\net on va appliquer des opérations sur chaque ligne de ces vecteurs. On parle de vectorisation des opérations pour désigner une opération qui s’appliquera de manière automatique à chaque élément de notre vecteur.\nPar exemple, la multiplication est vectorielle par défaut:\n\n5*c(1,20,2)\n\n[1]   5 100  10\n\n\nDe même l’addition, à condition de mettre des vecteurs de taille cohérente:\n\nc(1,20,2) + c(21,2,20)\n\n[1] 22 22 22\n\nc(1,20,2) - 3\n\n[1] -2 17 -1\n\n\n\n\n\n\n\n\nWarning\n\n\n\nSi la taille des vecteurs n’est pas cohérente,  recycle le vecteur le plus petit jusqu’à atteindre la bonne taille\n\nc(1,20,2) - c(1,20)\n\nWarning in c(1, 20, 2) - c(1, 20): longer object length is not a multiple of\nshorter object length\n\n\n[1] 0 0 1"
  },
  {
    "objectID": "exercises/r-base.html#characters",
    "href": "exercises/r-base.html#characters",
    "title": "Découverte des objets de base de ",
    "section": "2.2 Les chaînes de caractères (characters)",
    "text": "2.2 Les chaînes de caractères (characters)\nLes chaînes de caractères (ou strings) sont utilisées pour stocker de l’information textuelle. Plus précisément, elles peuvent stocker tout caractère de type Unicode, ce qui inclut les lettres des différentes langues, mais également la ponctuation, les chiffres, les smileys, etc.\n\n2.2.1 Créer un string\nPour créer une chaine de caractères (string), on peut utiliser de manière indifférente les guillemets ou les apostrophes.\n\n1'mot'\n2\"ça fonctionne aussi\"\n\n\n1\n\nPremière méthode: '\n\n2\n\nDeuxième méthode (préférable): \"\n\n\n\n\n[1] \"mot\"\n[1] \"ça fonctionne aussi\"\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAttention au mélange des deux !\n\nprint('l'apostrophe, quelle catastrophe')\n\nError: &lt;text&gt;:1:10: unexpected symbol\n1: print('l'apostrophe\n             ^\n\n\nLa deuxième apostrophe est comprise comme la fin du string, et  ne sait pas interpréter le reste de la séquence.\nIl faut donc varier en cas de besoin :\n\n11\"l'apostrophe, aucun problème\"\n\n\n1\n\nCette fois, l’apostrophe ' est bien enchassée au sein des guillemets qui délimitent notre string.\n\n\n\n\n[1] \"l'apostrophe, aucun problème\"\n\n\nCela fonctionne également en sens inverse: les guillements sont bien interprétés lorsqu’ils sont entre apostrophes.\n\n'les guillemets, \"aucun problème\"'\n\n[1] \"les guillemets, \\\"aucun problème\\\"\"\n\n\nComme l’illustre la sortie ci-dessus, il est possible de bien définir les caractères spéciaux de cette sorte en les échappant avec des antislashs \\:\n\n1\"les guillemets, \\\"aucun problème\\\"\"\n'l\\'apostrophe, aucun problème'\n\n\n1\n\n\\ permet à  de comprendre que l’apostrophe ou le guillemet fait partie de la chaine de caractère et non de sa délimitation.\n\n\n\n\n[1] \"les guillemets, \\\"aucun problème\\\"\"\n[1] \"l'apostrophe, aucun problème\"\n\n\n\n\n\n\n2.2.2 Quelques fonctions utiles\n propose par défaut un certain nombre de fonctions utiles pour extraire ou transformer des vecteurs textuels. On en découvrira des plus pratiques et plus générales lorsqu’on se focalisera sur les données textuelles et le package stringr.\nLa fonction nchar permet de compter le nombre de caractères d’un string, tous caractères inclus (lettres, chiffres, espaces, ponctuation…).\n\nnchar(\"J'ai 19 charactères\")\n\n[1] 19\n\n\nIl ne faut pas la confondre avec la fonction length. Celle-ci nous donne la longueur du vecteur. Par exemple,\n\nlength(\"J'ai 19 charactères\")\n\n[1] 1\n\n\nest de taille 1 puisqu’on a un seul élément dans notre vecteur. Si on prend un vecteur de plus grande dimension:\n\nlength(c(\"J'ai 19 charactères\", \"pas moi\"))\n\n[1] 2\n\n\nOn retrouve bien le nombre d’éléments de notre vecteur en sortie de length.\nnchar est une opération vectorielle, on peut donc compter la longueur de chaque ligne de notre jeu de données:\n\nnchar(c(\"J'ai 19 charactères\", \"pas moi\"))\n\n[1] 19  7\n\n\nL’un des intérêts des fonctions de base de traitement des données textuelles est la possibilité de remettre en forme nos chaînes de caractères de manière automatique. Par exemple, l’opération la plus simple est de changer la capitalisation de notre texte:\n\n1toupper(c(\"sequence 850\", \"Sequence 850\"))\n2tolower(c(\"SEQuEnce 850\", \"SEQUENCE 850\"))\n\n\n1\n\nMettre en majuscules tout le texte.\n\n2\n\nMettre en minuscules.\n\n\n\n\n[1] \"SEQUENCE 850\" \"SEQUENCE 850\"\n[1] \"sequence 850\" \"sequence 850\"\n\n\nMais on peut aussi nettoyer des chaines textuelles avec quelques fonctions de base :\n\nstrsplit(c(\"une séquence    à séparer\", \"uneautreàséparer\"), split = \" \")\n\n[[1]]\n[1] \"une\"      \"séquence\" \"\"         \"\"         \"\"         \"à\"        \"séparer\" \n\n[[2]]\n[1] \"uneautreàséparer\"\n\n\nA ce stade, la sortie obtenue, avec des [[]] peut vous paraître étrange car nous n’avons pas encore découvert le type list.\nCe type de données n’étant pas forcément pratique pour l’analyse statistique, pour laquelle on préfère des formats comme le vecteur, ce sera beaucoup plus pratique d’utiliser le package stringr pour faire un split.\nOn peut tout à fait découper notre string sur autre chose que les espaces!\n\nstrsplit(c(\"une séquence    à séparer\", \"uneautreàséparer\"), split = \"à\")\n\n[[1]]\n[1] \"une séquence    \" \" séparer\"        \n\n[[2]]\n[1] \"uneautre\" \"séparer\" \n\n\nOn peut concaténer des chaines de caractère ensemble, c’est très pratique. Malheureusement le + ne fonctionne pas en R pour les chaines de caractères (contrairement à Python). Pour effectuer cela on utilise paste ou paste0 (une version moins générale mais qui est pensée pour les concaténations simples):\n\npaste0(\n    \"La première fois qu'Aurélien vit Bérénice,\",\n    \" \",\n    \"il la trouva franchement laide. Elle lui déplut, enfin.\",\n    \" \",\n    \"Il n'aima pas comment elle était habillée.\"\n1)\n\npaste(\n    \"La première fois qu'Aurélien vit Bérénice,\",\n    \"il la trouva franchement laide. Elle lui déplut, enfin.\",\n    \"Il n'aima pas comment elle était habillée.\",\n    sep = \" \"\n2)\n\n\n1\n\nAvec paste0, on concatène en accolant les strings, sans espace.\n\n2\n\nAvec paste, on peut choisir la manière d’accoler les strings, ici en mettant des espaces.\n\n\n\n\n[1] \"La première fois qu'Aurélien vit Bérénice, il la trouva franchement laide. Elle lui déplut, enfin. Il n'aima pas comment elle était habillée.\"\n[1] \"La première fois qu'Aurélien vit Bérénice, il la trouva franchement laide. Elle lui déplut, enfin. Il n'aima pas comment elle était habillée.\"\n\n\nOn peut utiliser les strings comme templates. C’est particulièrement pratique pour automatiquement créer du texte à partir de valeurs issues de nos données. Pour cela on utilise sprintf:\n\nsprintf(\"La première fois qu'%s vit %s\", \"Aurélien\", \"Bérénice\")\n\n[1] \"La première fois qu'Aurélien vit Bérénice\"\n\nsprintf(\"%s et %s font %s\", 2, 2, 2+2)\n\n[1] \"2 et 2 font 4\"\n\n\n%s sert à définir l’endroit où sera collé le texte voulu."
  },
  {
    "objectID": "exercises/r-base.html#logicals",
    "href": "exercises/r-base.html#logicals",
    "title": "Découverte des objets de base de ",
    "section": "2.3 Vecteurs logiques (logicals)",
    "text": "2.3 Vecteurs logiques (logicals)\nEn , les vecteurs logiques sont utilisés pour stocker des valeurs booléennes, c’est-à-dire des valeurs vraies (TRUE) ou fausses (FALSE).\nLes vecteurs logiques sont couramment utilisés pour effectuer des opérations de logique, des filtres de données et des sélections conditionnelles. Nous y reviendrons par la suite, nous les utiliserons fréquemment mais de manière indirecte.\n\n15 &gt; 3\n22 == 2\n30 == (2 - 2)\n41 &lt; 0\n\n\n1\n\nTRUE, car 5 est supérieur à 3.\n\n2\n\nTRUE, car 2 est égal à 2.\n\n3\n\nTRUE, le chainage des opérations est respecté.\n\n4\n\nFALSE, car 1 n’est pas inférieur à 0.\n\n\n\n\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] FALSE\n\n\nOn peut généraliser les comparaisons pour obtenir des vecteurs:\n\nc(2, 4, 6, 8, 10, 1, 3) %% 2 == 0\n\n[1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE\n\n\nOn obtient TRUE pour les nombres pairs, FALSE pour les impairs.\nUtiliser des vecteurs logiques nous permettra, au quotidien, sélectionner des données. Par exemple si on a des données d’âge, on peut ne vouloir garder que les prénoms des adultes. Cela pourra être fait sur le modèle suivant:\n\nc('Pierre', 'Paul', 'François', 'et les autres')[\n    c(25, 3, 61, 17) &gt;= 18\n]\n\n[1] \"Pierre\"   \"François\"\n\n\nNéanmoins nous verrons dans les prochains chapitres comment intégrer ce principe dans une séquence plus générale d’opérations grâce au package dplyr."
  },
  {
    "objectID": "exercises/r-base.html#factors",
    "href": "exercises/r-base.html#factors",
    "title": "Découverte des objets de base de ",
    "section": "2.4 Les facteurs (factors)",
    "text": "2.4 Les facteurs (factors)\nLes facteurs (factors) sont utilisés pour représenter des variables catégorielles, c’est-à-dire des variables qui prennent un nombre fini et prédéterminé de niveaux ou de catégories.\nPour convertir un vecteur numérique ou textuel en vecteur, on utilise la fonction factor:\n\nfactor(\n    c(\"capitale\",\"préfecture\",\"sous-préfecture\",\"préfecture\")\n)\n\n[1] capitale        préfecture      sous-préfecture préfecture     \nLevels: capitale préfecture sous-préfecture\n\nfactor(c(1,10,3))\n\n[1] 1  10 3 \nLevels: 1 3 10\n\n\nLes niveaux d’un facteur sont les différentes catégories ou valeurs possibles que la variable peut prendre. On peut les lister avec la fonction levels\n\nlevels(\n    factor(\n        c(\"capitale\",\"préfecture\",\"sous-préfecture\",\"préfecture\")\n    )\n)\n\n[1] \"capitale\"        \"préfecture\"      \"sous-préfecture\"\n\n\nOn peut aussi ordonner ces niveaux si cela a un sens lors de la définition du facteur. Cela implique néanmoins de connaître, a priori nos différents niveaux et les renseigner à  dans l’ordre:\n\nfactor(\n    c(\"capitale\",\"préfecture\",\"sous-préfecture\",\"préfecture\"),\n    levels = c(\"capitale\",\"préfecture\",\"sous-préfecture\"),\n    ordered = TRUE\n)\n\n[1] capitale        préfecture      sous-préfecture préfecture     \nLevels: capitale &lt; préfecture &lt; sous-préfecture"
  },
  {
    "objectID": "exercises/r-base.html#les-matrices",
    "href": "exercises/r-base.html#les-matrices",
    "title": "Découverte des objets de base de ",
    "section": "7.1 Les matrices",
    "text": "7.1 Les matrices\nLes matrices peuvent être vues comme le prolongement en deux dimensions des vecteurs. Au lieu d’avoir des données sur une seule dimension, on empile des colonnes côte à côte.\n\\[\nX = \\begin{bmatrix}\nx_{11} & x_{12} \\\\\nx_{21} & x_{22} \\\\\n\\end{bmatrix}\n\\]\nNéanmoins, les matrices présentent une limite fondamentale: on ne peut stocker dans une matrice que des éléments de même type. Autrement dit, on aura exclusivement des matrices numériques, des matrices de caractères ou des matrices logiques. Il est impossible de construire une matrice dont certaines variables sont de type numérique (par exemple l’âge des personnes enquêtées) et d’autres de type caractère (par exemple leur secteur d’activité).\nLes matrices ne constituent donc pas un type d’objet susceptible de stocker l’information statistique habituellement mobilisée dans les enquêtes sociales. Le mix des types n’est pas pratique, c’est pour cette raison que les praticiens de l’analyse de données les utilisent peu3.\nOn propose donc un exercice sur les matrices mais on va rapidement passer à des types plus flexibles, plus utiles pour l’analyse de données où les variables sont de type diverses.\n\n\n\n\n\n\nExercice 7\n\n\n\nSoit une matrice:\n\nX &lt;- matrix(letters[1:20], nrow = 4, ncol = 5)\n\n\n\nSolution\nX[1,1]\n2X[1,]\n3X[,1]\n4X[2:3,c(1,3)]\n\n\n\n1\n\nSélectionner l’élement le plus à gauche de notre matrice (première ligne, première colonne)\n\n2\n\nSélectionner l’ensemble de la première ligne\n\n3\n\nSélectionner l’ensemble de la première colonne\n\n4\n\nSélectionner les éléments à l’intersection :\n\n\n\n\n\n\nIndice si vous êtes bloqués\n\nAvec un vecteur, on accédait aux positions d’un élément avec X[*]. Avec les matrices le principe est le même mais on ajoute une dimension X[*,*]"
  },
  {
    "objectID": "exercises/r-base.html#les-listes",
    "href": "exercises/r-base.html#les-listes",
    "title": "Découverte des objets de base de ",
    "section": "7.2 Les listes",
    "text": "7.2 Les listes\nLes listes constituent un type d’objet beaucoup plus riche qui permet précisément de rassembler des types d’objets très différents : une liste peut contenir tous les types d’objet (vecteurs numériques, caractères, logiques, matrices, etc.), y compris d’autres listes.\nCette très grande souplesse fait de la liste l’objet de prédilection pour stocker une information complexe et structurée, en particulier les résultats de procédures statistiques complexes (régression, classification, etc.). Pour des données plus structurées, comme le sont les jeux de données, nous allons voir ensuite que nous allons utiliser un type spécial de liste: le dataframe.\n\n\n\nProposition d’illustration du principe des listes avec R par Dall-E-2\n\n\n\n\n\n\n\n\nExercice 8\n\n\n\nVoici une liste illustrant le principe de stockage de données hétérogènes dans un même objet:\n\nma_liste &lt;- list(\n    1,\n    \"texte\",\n    matrix(letters[1:20], nrow = 4, ncol = 5),\n    c(2, 3, 4)\n)\n\n\nAfficher la liste et observer la différence avec l’affichage des objets précédents\nUtiliser la notation [[]] pour accéder au 2e élément de notre liste pour au 2e nombre au sein du dernier élément de notre matrice\nOn peut utiliser des noms pour les éléments de notre liste (c’est d’ailleurs une bonne pratique). Créer un élément nommé communes dans votre liste stockant les données suivantes c('01363', '02644', '03137', '11311')\nCréer un élément departements en extrayant les deux premiers chiffres de votre élément communes\n\n\n\nSolution\n#Question 1: afficher la liste\nma_liste\n# Question 2: Accéder au deuxième élément de la liste\nma_liste[[2]]\nma_liste[[4]][2]\n# Question 3: mettre à jour la liste avec un élément nommé et y accéder\nma_liste[['communes']] &lt;- c(\n  '01363', '02644', '03137', '11311'\n  )\nma_liste[['communes']]  \n# Question 4: effectuer une opération \nma_liste[['departements']] &lt;- substr(ma_liste[['communes']] , start = 1, stop = 2)\n\n\n\n\nLorsqu’on utilise des listes, on peut effectuer des opérations sur chaque élément de notre liste. On appelle cela boucler sur notre liste.\n\n\n\n\n\n\n\nExercice 9\n\n\n\nDans cet exercice, nous allons découvrir comment appliquer la même fonction aux éléments de notre liste grâce à lapply.\n\nAvant cela, combien d’éléments comporte le premier niveau de notre liste ?\nCombien d’éléments comportent chaque niveaux de notre liste ?\nCréer un vecteur numérique qui est égal à 1 si typeof de l’élément est “double” et 0 sinon\n\n\n\nSolution\n# Question 1\nlongueur_liste &lt;- length(ma_liste)\n# Question 2\nlapply(ma_liste, length)\nas.numeric(\n    lapply(ma_liste, function(l) typeof(l) == \"double\")\n)\n\n\n\n\nSi ?lapply ne vous aide pas\n\nExemple d’utilisation de lapply pour faire la somme dans chaque élément de notre liste\n\nma_liste_nombres &lt;- list(c(1,2), seq(1,10))\nlapply(ma_liste_nombres, sum)\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] 55"
  },
  {
    "objectID": "exercises/r-base.html#les-dataframes",
    "href": "exercises/r-base.html#les-dataframes",
    "title": "Découverte des objets de base de ",
    "section": "7.3 Les dataframes",
    "text": "7.3 Les dataframes\nC’est l’objet central de l’analyse de données avec . Ces objets permettent en effet de représenter sous la forme d’une table (i.e. d’un objet à deux dimensions) des données de nature tant quantitatives (variables numériques) que qualitatives (variables de type caractère ou facteur).\n\n\n\nIllustration du principe du dataframe (empruntée à H. Wickham)\n\n\nVoici par exemple un dataframe:\n\n# Création du data.frame df\ndf &lt;- data.frame(\n  var1 = 1:10,\n  var2 = letters[1:10],\n  var3 = rep(c(TRUE, FALSE), times = 5)\n)\n\nSa structure interne peut être vérifiée avec la fonction str:\n\nstr(df)\n\n'data.frame':   10 obs. of  3 variables:\n $ var1: int  1 2 3 4 5 6 7 8 9 10\n $ var2: chr  \"a\" \"b\" \"c\" \"d\" ...\n $ var3: logi  TRUE FALSE TRUE FALSE TRUE FALSE ...\n\n\nQuand on travaille avec R, l’une des fonctions qu’on utilise le plus est head. Elle permet d’afficher les \\(n\\) premières lignes de notre jeu de données:\n\nhead(df)\n\n  var1 var2  var3\n1    1    a  TRUE\n2    2    b FALSE\n3    3    c  TRUE\n4    4    d FALSE\n5    5    e  TRUE\n6    6    f FALSE\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIl est également possible d’utiliser le viewer de RStudio pour afficher des jeux de données.\nAttention cependant, ce viewer peut rencontrer des problèmes de performance et faire planter votre session R quand le jeu de données commence à être d’une taille conséquente.\nJe recommande plutôt de toucher utiliser head ou de sélectionner des lignes aléatoirement avec sample:\n\ndf[sample(nrow(df), 3), ]\n\n   var1 var2  var3\n10   10    j FALSE\n3     3    c  TRUE\n4     4    d FALSE\n\n\n\n\nDu point de vue de sa structure, un data.frame est en réalité une liste dont tous les éléments ont la même longueur : c’est ce qui permet de le représenter sous la forme d’un tableau à deux dimensions.\n\nis.list(df)\n\n[1] TRUE\n\nlapply(df, length)\n\n$var1\n[1] 10\n\n$var2\n[1] 10\n\n$var3\n[1] 10\n\n\nDe ce fait, les data.frame empruntent leurs caractéristiques tantôt aux listes, tantôt aux matrices comme le montre l’exercice suivant:\n\n\n\n\n\n\nExercice 10\n\n\n\n\nVérifier la dimension du dataframe df\nCompter le nombre de lignes et de colonnes de df\nVérifier la longueur (length) de df. Est-ce le comportement d’une matrice ou d’une liste ?\nExtraire l’élement à la 2e ligne, 3e colonne de df. Est-ce le comportement d’indexation d’une matrice ou d’une liste ?\nRécupérer la 3e ligne des variables var1 et var2.\n\n\n\nSolution\ndim(df)\nnrow(df)\nncol(df)\nlength(df) #comme une liste\ndf[3, c(\"var1\",\"var2\")]\n\n\n\n\nL’intérêt d’utiliser un data.frame est qu’on peut facilement mettre à jour nos données lors d’une analyse statistique. Les opérations les plus classiques, sur lesquelles nous reviendrons lors du prochain chapitre, sont\n\nCréer une nouvelle colonne à partir des colonnes pré-existantes ;\nSélectionner un sous-échantillon des données correspondant à certaines valeurs observées.\n\nIl existe plusieurs manières de faire référence à une colonne déjà existante d’un dataframe. La plus simple est d’utiliser la structure dataframe$colonne. Cela nous donnera un vecteur et on retombe sur ce format qu’on connaît déjà:\n\nclass(df$var1)\n\n[1] \"integer\"\n\n\n\n\n\n\n\n\nExercice 11\n\n\n\n\nCréer une colonne var4 de notre jeu de données égale au carré de var1\nCréer une colonne var5 de notre jeu de données concaténant les deux premières variables en généralisant le schéma 1=a.\nCréer un dataframe df_small1 pour les lignes où la condition logique var3 est vérifiée\nCréer un dataframe df_small2 pour les lignes où var1 est paire (voir plus haut l’exemple sur la division euclidienne pour le modèle)\n\n\n\nLe prochain chapitre va nous permettre d’aller beaucoup plus loin grâce à l’écosystème du tidyverse et notamment son package phare dplyr. Sans cet ensemble de packages facilitant grandement l’analyse statistique,  ne serait pas devenu l’un des deux langages phares de la statistique."
  },
  {
    "objectID": "exercises/r-base.html#footnotes",
    "href": "exercises/r-base.html#footnotes",
    "title": "Découverte des objets de base de ",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPour installer soi-même RStudio, les instructions sont ici. Néanmoins, dans le cadre de ce cours, vous n’aurez pas besoin de faire l’installation, nous allons utiliser une infrastructure préconfigurée. De cette manière, nous aurons accès au même environnement.↩︎\nCette remarque peut paraître triviale mais, en informatique, elle ne l’est pas. Beaucoup de langages (Python, C) ont une indexation qui commence à 0, comme c’est la convention en algèbre. Cela signifie que le premier élément a un indice 0, le deuxième indice 1 et le dernier un indice \\(n-1\\).↩︎\nL’objet matrice sera surtout utilisé par les les chercheurs en statistique mathématique ou les spécialistes d’algorithmique qui manipuleront des objets numériques bas niveau.↩︎"
  }
]