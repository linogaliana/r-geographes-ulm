[
  {
    "objectID": "exercises/r-wrangling.html",
    "href": "exercises/r-wrangling.html",
    "title": "Importer et manipuler des données avec ",
    "section": "",
    "text": "Dans ce deuxième TP, nous allons apprendre à importer et manipuler des données avec .\nSi vous êtes intéressés par Python , une version très proche de ce TP est disponible dans mon cours de l’ENSAE.\nDans ce chapitre, nous allons principalement utiliser les packages suivants du tidyverse:\nDans ce tutoriel, nous allons utiliser deux sources de données :"
  },
  {
    "objectID": "exercises/r-wrangling.html#import-dun-csv-de-lademe",
    "href": "exercises/r-wrangling.html#import-dun-csv-de-lademe",
    "title": "Importer et manipuler des données avec ",
    "section": "2.1 Import d’un csv de l’Ademe",
    "text": "2.1 Import d’un csv de l’Ademe\nPour commencer, nous allons importer les données de l’Ademe à l’aide du package readr[^readcsv].\n\n\n\n\n\n\nExercice 1: lire un csv avec readr et observer les données\n\n\n\nVoici l’URL sur lequel les données sont disponibles\n\nurl &lt;- \"https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert\"\n\n\nUtiliser le package readr pour importer ces données. Nommer cet objet emissions4\nAfficher les premières lignes avec head et observer la différence d’affichage avec, par exemple, ce dataframe:\n\n\nlibrary(readr)\nemissions &lt;- read_csv(url)\n\nRows: 35798 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): INSEE commune, Commune\ndbl (10): Agriculture, Autres transports, Autres transports international, C...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ndata.frame(\n  \"com\" = c(1,2),\n  \"val\" = rnorm(2)\n)\n\n  com       val\n1   1  1.113313\n2   2 -1.289941\n\n\n\nAfficher la classe de emissions. Comprenez-vous maintenant pourquoi cet objet est un peu différent d’un dataframe de base ?\nUtiliser les fonctions adéquates pour les 10 premières valeurs, les 15 dernières et un échantillon aléatoire de 10 valeurs grâce à la fonction adéquate du package dplyr\n\n\n\nEn cas de blocage à la question 1\n\nLire la documentation de read_csv (très bien faite) ou chercher des exemples en ligne pour découvrir cette fonction. ⚠️ Ne pas utiliser read.csv (fonction de base) qui n’est pas performante."
  },
  {
    "objectID": "exercises/r-wrangling.html#import-de-données-de-linsee",
    "href": "exercises/r-wrangling.html#import-de-données-de-linsee",
    "title": "Importer et manipuler des données avec ",
    "section": "2.2 Import de données de l’Insee",
    "text": "2.2 Import de données de l’Insee\nEn ce qui concerne nos informations communales, on va utiliser l’une des plus sources de l’Insee les plus utilisées : les données Filosofi. Afin de faciliter la récupération de celles-ci, nous allons utiliser le package communautaire doremifasol :\n\nlibrary(doremifasol)\nlibrary(tibble)\nfilosofi &lt;- as_tibble(\n  telechargerDonnees(\"FILOSOFI_COM\", date = 2016)\n)\nhead(filosofi)\n\n\n\n# A tibble: 6 × 29\n  CODGEO LIBGEO      NBMENFISC16 NBPERSMENFISC16  MED16 PIMP16 TP6016 TP60AGE116\n  &lt;chr&gt;  &lt;chr&gt;             &lt;dbl&gt;           &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 01001  L'Abergeme…         313            796. 22679      NA     NA         NA\n2 01002  L'Abergeme…         101            248  24382.     NA     NA         NA\n3 01004  Ambérieu-e…        6363          14228  19721      49     17         19\n4 01005  Ambérieux-…         633           1662. 23378      NA     NA         NA\n5 01006  Ambléon              NA             NA     NA      NA     NA         NA\n6 01007  Ambronay           1087           2684  22146.     57     NA         NA\n# ℹ 21 more variables: TP60AGE216 &lt;dbl&gt;, TP60AGE316 &lt;dbl&gt;, TP60AGE416 &lt;dbl&gt;,\n#   TP60AGE516 &lt;dbl&gt;, TP60AGE616 &lt;dbl&gt;, TP60TOL116 &lt;dbl&gt;, TP60TOL216 &lt;dbl&gt;,\n#   PACT16 &lt;dbl&gt;, PTSA16 &lt;dbl&gt;, PCHO16 &lt;dbl&gt;, PBEN16 &lt;dbl&gt;, PPEN16 &lt;dbl&gt;,\n#   PPAT16 &lt;dbl&gt;, PPSOC16 &lt;dbl&gt;, PPFAM16 &lt;dbl&gt;, PPMINI16 &lt;dbl&gt;, PPLOGT16 &lt;dbl&gt;,\n#   PIMPOT16 &lt;dbl&gt;, D116 &lt;dbl&gt;, D916 &lt;dbl&gt;, RD16 &lt;dbl&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nLa fonction as_tibble nous sert à transformer le dataframe de base (doremifasol ne fait pas d’a priori sur l’écosystème de manipulation adopté) en dataframe adapté à une exploitation via le tidyverse."
  },
  {
    "objectID": "exercises/r-wrangling.html#footnotes",
    "href": "exercises/r-wrangling.html#footnotes",
    "title": "Importer et manipuler des données avec ",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nreadr offre la possibilité d’importer des données directement depuis un url. C’est l’option prise dans ce tutoriel. Si vous préfèrez, pour des raisons d’accès au réseau ou de performance, importer depuis un poste local, vous pouvez télécharger les données et changer les commandes d’import avec le chemin adéquat plutôt que l’url.↩︎\nIl existe également bioconductor mais celui-ci étant surtout orienté biostatistiques (une des communautés académiques ayant adopté  le plus tôt), nous ne l’utilisons pas vraiment↩︎\nremotes::install_github signifie d’utiliser la fonction install_github du package remotes. Autrement dit, il faut un package pour installer d’autres packages 🤯. C’est parce que Github n’existait pas lors de la création de  (années 1990) et que cette fonctionnalité n’a pas été ajouté depuis.↩︎\nPar manque d’imagination, on est souvent tenté d’appeler notre dataframe principal df ou data. C’est souvent une mauvaise idée puisque ce nom n’est pas très informatif quand on relit le code quelques semaines plus tard. L’autodocumentation, approche qui consiste à avoir un code qui se comprend de lui-même, est une bonne pratique et il est donc recommandé de donner un nom simple mais efficace pour connaître la nature du dataset en question.↩︎\nL’espace dans le nom de la variable est embêtant. Pour pouvoir utiliser le nom de cet variable dans rename, il va falloir utiliser des backticks, c’est-à-dire INSEE commune.↩︎\nLes fonctionnalités limitées du langage de base sur la manipulation textuelle sont rapidement contraignantes. On passe ainsi rapidement à stringr même si ce n’est pas l’objet principal du chapitre.↩︎\nvous pouvez utiliser directement le morceau de code d’aide si vous n’êtes pas familiers de ggplot↩︎"
  },
  {
    "objectID": "exercises/ggplot.html",
    "href": "exercises/ggplot.html",
    "title": "Produire des représentations graphiques avec  et ggplot2",
    "section": "",
    "text": "Dans ce troisième TP, nous allons apprendre à créer des représentations graphiques synthétiques avec  qui est très bien outillé dans le domaine grâce à la librairie ggplot2. Cette dernière implémente une grammaire des graphiques flexible, cohérente et simple d’usage.\nSi vous êtes intéressés par Python , une version très proche de ce TP est disponible dans mon cours de l’ENSAE.\nLa pratique de la visualisation se fera, dans ce cours, en répliquant des graphiques qu’on peut trouver sur la page de l’open data de la ville de Paris ici.\nCe TP vise à initier:\nDans ce chapitre, nous allons utiliser les librairies suivantes:\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\nNous verrons par la suite la manière de construire des cartes facilement avec des formats équivalents."
  },
  {
    "objectID": "exercises/ggplot.html#données",
    "href": "exercises/ggplot.html#données",
    "title": "Produire des représentations graphiques avec  et ggplot2",
    "section": "1 Données",
    "text": "1 Données\nUn sous-ensemble des données de Paris Open Data a été mis à disposition pour faciliter l’import. Il s’agit d’une extraction, qui commence à dater, des données disponibles sur le site où seules les colonnes qui servent à cet exercice ont été conservées.\nNous proposons de télécharger ces données et les enregistrer dans un fichier sur le disque dur local avant de l’importer1. Cependant, nous n’allons pas faire cela manuellement mais nous allons plutôt utiliser . Effectuer ce type d’action de manière manuelle serait une mauvaise pratique du point de vue de la reproductibilité.\n\nurl &lt;- \"https://minio.lab.sspcloud.fr/projet-formation/diffusion/python-datascientist/bike.csv\"\n1download.file(url, \"bike.gz\")\n\n\n1\n\nL’extension .gz est importante pour la suite car readr en a besoin pour comprendre que le fichier est compressé."
  },
  {
    "objectID": "exercises/ggplot.html#premières-productions-graphiques",
    "href": "exercises/ggplot.html#premières-productions-graphiques",
    "title": "Produire des représentations graphiques avec  et ggplot2",
    "section": "2 Premières productions graphiques",
    "text": "2 Premières productions graphiques\nChercher à produire une visualisation parfaite du premier coup est illusoire. Il est beaucoup plus réaliste d’améliorer graduellement une représentation graphique afin, petit à petit, de mettre en avant les effets de structure dans un jeu de données.\nNous allons donc commencer par nous représenter la distribution des passages aux principales stations de mesure. Pour cela nous allons produire rapidement un barplot puis l’améliorer graduellement.\nDans cette partie, nous allons ainsi reproduire les deux premiers graphiques de la page d’analyse des données: Les 10 compteurs avec la moyenne horaire la plus élevée et Les 10 compteurs ayant comptabilisés le plus de vélos. Les valeurs chiffrées des graphiques seront différentes de celles de la page en ligne, c’est normal, nous travaillons sur des données plus anciennes.\n\n\n\n\n\n\nExercice 1 : Importer les données et produire un premier graphique rapidement\n\n\n\nLes données comportent plusieurs dimensions pouvant faire l’objet d’une analyse statistique. Il est donc nécessaire dans un premier temps de synthétiser celles-ci par des agrégations afin d’avoir un graphique lisible.\n\nImporter les données de compteurs de vélos depuis le fichier bike.gz ;\nGarder les dix bornes à la moyenne la plus élevée ;\n\nOn va maintenant pouvoir se concentrer sur la production de la représentation\n\nEn premier lieu, sans se préoccuper des éléments de style ni de la beauté du graphique, créer la structure du barplot (diagramme en batons) de la page d’analyse des données:\n\n\n\nFigure obtenue, sans s’occuper du style\n\n\n\n\n\n\n\nLa suite de l’exercice consiste à améliorer graduellement cette représentation pour converger vers la reproduction de la version en open data. Il ne s’agit pas encore de se concentrer sur l’esthétique de la figure mais de la rendre intelligible, à gros trait.\n\nEn premier lieu, réordonner les barres sur l’axe des ordonnées grâce à la fonction reorder. Cela rendra le message de la figure plus intelligible.\n\n\n\nFigure avec les barres réordonnées\n\n\n\n\n\n\n\nOn réordonne Nom du compteur en fonction de Comptage horaire\n\n\n\nLe minimum pour que quelqu’un ne connaissant pas les données soit capable de comprendre la représentation graphique est de labelliser les axes. Créer les mêmes labels d’axes que la figure originale.\n\n\n\nFigure avec les axes nommés\n\n\n\n\n\n\n\nIl existe de nombreuses manières de procéder avec ggplot pour labelliser les axes. Mais la plus simple est la fonction labs\n\n\n\nLe fond gris permet est certes une manière de reconnaître que le graphique a été produit avec ggplot2 mais ce n’est pas très soigné. Comme c’est une fonctionnalité un peu plus avancée, nous proposons directement le code pour mettre à jour votre figure avec les éléments de style suivant:\n\ntheme_minimal() +\ntheme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(hjust = 0.5),\n        plot.margin = margin(1, 4, 1, 1, \"cm\"))\n\n\nFigure obtenue à l’issue de ces questions\n\n\n\n\n\n\n\nFaire la même chose pour la figure 2, afin d’obtenir une figure similaire\n\n\nFigure 2 à l’issue de cet exercice\n\n\n\n\n\n\n\n\n\nLes 10 principales stations à l’issue de la question 2\n\n\n\n# A tibble: 6 × 2\n  `Nom du compteur`                    `Comptage horaire`\n  &lt;chr&gt;                                             &lt;dbl&gt;\n1 Totem 73 boulevard de Sébastopol S-N               197.\n2 Totem 73 boulevard de Sébastopol N-S               148.\n3 89 boulevard de Magenta NO-SE                      144.\n4 Totem 64 Rue de Rivoli O-E                         140.\n5 102 boulevard de Magenta SE-NO                     137.\n6 72 boulevard Voltaire NO-SE                        124.\n\n\n\n\n\nOn peut remarquer plusieurs éléments problématiques (par exemple les labels) mais aussi des éléments ne correspondant pas (les titres des axes, etc.) ou manquants (le nom du graphique…)\n\n\n\n\n\n\nTip\n\n\n\nExercice 2 : Un peu de style !"
  },
  {
    "objectID": "exercises/ggplot.html#footnotes",
    "href": "exercises/ggplot.html#footnotes",
    "title": "Produire des représentations graphiques avec  et ggplot2",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nD’habitude, nous recommandons d’utiliser directement l’URL de téléchargement ce qui évite de créer un fichier intermédiaire sur le disque dur. Néanmoins, ici, l’import direct avec readr ne fonctionnera pas car le fichier est mal interprété par la librairie. Celle-ci ne comprend pas que le fichier est compressé car il lui manque l’extension .gz (un format compressé) à la fin.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "",
    "text": "Introduction aux méthodes quantitatives avec \nLino Galiana\nCours du département de sciences sociales de l’ENS Ulm.\nUn cours pour se familiariser à  par la pratique avec l’open data.\n\n\n\n  \n     \n      \n          \n            \n          \n          \n            Introduction aux objets de base \n            \n              \nIntroduction aux objets basiques de \net à RStudio\n\n\n              \n                Lino Galiana\n                Sep 1, 2023\n              \n            \n            \n                \n                  Exercice ✏️\n                \n                \n                  Slides 🧑‍🏫\n                \n            \n          \n        \n      \n     \n  \n  \n     \n      \n          \n            \n          \n          \n            Manipuler des données avec le tidyverse\n            \n              \nIntroduction à l'écosystème du tidyverse\npour lire et manipuler des données structurées avec \n\n\n              \n                Lino Galiana\n                Sep 1, 2023\n              \n            \n            \n                \n                  Exercice ✏️\n                \n                \n                  Slides 🧑‍🏫\n                \n            \n          \n        \n      \n     \n  \n  \n     \n      \n          \n            \n          \n          \n            Produire des représentations graphiques avec ggplot2\n            \n              \nIntroduction à ggplot2,\npour produire des graphiques avec\n\n\n\n              \n                Lino Galiana\n                Sep 1, 2023\n              \n            \n            \n                \n                  Exercice ✏️\n                \n                \n                  Slides 🧑‍🏫\n                \n            \n          \n        \n      \n     \n  \n  \n     \n      \n          \n            \n          \n          \n            Manipuler des données spatiales avec sf\n            \n              \nIntroduction à sf,\nune extension du\ntidyverse\npour transformer \nen SIG capable de lire et manipuler des données géographiques.\n\n\n              \n                Lino Galiana\n                Sep 1, 2023\n              \n            \n            \n                \n                  Exercice ✏️\n                \n                \n                  Slides 🧑‍🏫\n                \n            \n          \n        \n      \n     \n  \n\n\nNo matching items"
  },
  {
    "objectID": "slides/introduction.html#chapitre-introductif",
    "href": "slides/introduction.html#chapitre-introductif",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Chapitre introductif",
    "text": "Chapitre introductif\n\n\n\n\n\n\nNote\n\n\n\nExercices associés à ce chapitre ici\n\n\n\n\n\n\nRetour à la page principale"
  },
  {
    "objectID": "slides/introduction.html#qui-suis-je-fa-brands-firefox-sizetiny-fa-brands-github-sizetiny-fa-brands-twitter-sizetiny-fa-brands-linkedin-sizetiny-fa-brands-python-sizetiny",
    "href": "slides/introduction.html#qui-suis-je-fa-brands-firefox-sizetiny-fa-brands-github-sizetiny-fa-brands-twitter-sizetiny-fa-brands-linkedin-sizetiny-fa-brands-python-sizetiny",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Qui suis-je ?      ",
    "text": "Qui suis-je ?      \n\nData scientist au lab de l’Insee :\n\nAdministrateur Insee1 ;\nCoordonnateur d’un réseau de data scientists\n\n\n\n\nImplication dans l’innovation statistique, l’open source et la diffusion grand public2:\n\n: utilitR, doremifasol\n: cartiflette, pynsee\n\n\n\nRenseignez-vous sur le concours ENS ! Il y a de belles missions !Pas tout seul ! Avec une communauté de gens sympa de l’administration et de la recherche ! Beaucoup de projets novateurs 😍 sur compte  InseeFrLab"
  },
  {
    "objectID": "slides/introduction.html#qui-suis-je",
    "href": "slides/introduction.html#qui-suis-je",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Qui suis-je ?",
    "text": "Qui suis-je ?\n\nTravaux à l’intersection entre informatique, économie, sociologie & géographie:\n\nSégrégation avec données de téléphonie mobile\nInégalités alimentaires à partir de données massives de supermarchés\n\n\n\nExemple tiré de l’Insee Analyse sur la mixité sociale"
  },
  {
    "objectID": "slides/introduction.html#qui-suis-je-1",
    "href": "slides/introduction.html#qui-suis-je-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Qui suis-je ?",
    "text": "Qui suis-je ?\nD’autres cours introductifs que je donne peuvent vous intéresser:\n\nPython pour la data science ;\nBonnes pratiques en R et Git ;\nDonnées émergentes ;\n\nEt surtout consultez le portail complet de formation du datalab de l’Insee"
  },
  {
    "objectID": "slides/introduction.html#objectifs-pédagogiques",
    "href": "slides/introduction.html#objectifs-pédagogiques",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Objectifs pédagogiques",
    "text": "Objectifs pédagogiques\n\nDécouverte de l’écosystème de l’open data 🇫🇷\n\n\n\nIntroduction pratique au langage :\n\nDonnées classiques\nDonnées géographiques\n\n\n\n\n\nIntroduction à la publication reproductible avec Quarto\n\n\n\n\nOuverture à la cartographie web avec Observable"
  },
  {
    "objectID": "slides/introduction.html#modalités-pratiques",
    "href": "slides/introduction.html#modalités-pratiques",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Modalités pratiques",
    "text": "Modalités pratiques\n\nDes slides et surtout des TP guidés ;\nInfrastructure informatique (SSPCloud) fournie par l’Insee pour éviter:\n\nles galères d’installation\nles galères de configuration\n\nModalités d’initialisation à venir ;\n\nOn va utiliser le SSPCloud 😍🐉☁️🇫🇷 !\n(présentation tout à l’heure)"
  },
  {
    "objectID": "slides/introduction.html#ressources-complémentaires",
    "href": "slides/introduction.html#ressources-complémentaires",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Ressources complémentaires",
    "text": "Ressources complémentaires\n\nIntroduction à R et au tidyverse ;\n\n\n\nDocumentation collaborative utilitR 👶 ;\n\n\n\n\nPortail de formation du SSPCloud ;\n\n\n\n\nFunathon organisé par l’Insee ;\n\n\n\n\nR for Data Science (la bible !) ;\n\n\n\n\nData science with R (Sciences Po) ;\n\n\n\n\nRzine, du CIST\n\n\n\n\nGeocomputation with R, de Lovelace, Nowosad et Muenchow\n\n\n\n\nData Visualization : A practical introduction, de Kieran Healy"
  },
  {
    "objectID": "slides/introduction.html#prolifération-des-données",
    "href": "slides/introduction.html#prolifération-des-données",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Prolifération des données",
    "text": "Prolifération des données\n\nNumérisation et innovations technologiques ont réduit le coût de production de la donnée ;\n\nVolume de données produites en explosion\n\n\n\n\nL’utilisation des statistiques n’est pas nouvelle (cf. Desrosières)…\n\n\n\n\n… mais une place accrue dans le débat public et l’action publique (Supiot, Martin)"
  },
  {
    "objectID": "slides/introduction.html#diversification-des-données-14",
    "href": "slides/introduction.html#diversification-des-données-14",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Diversification des données (1/4)",
    "text": "Diversification des données (1/4)\nDonnées tabulaires classiques\n\nviewof info_mutations = Inputs.radio(\n  [\"Tableau\", \"Graphique\"], {value: \"Tableau\"}\n)\n\n\n\n\n\n\n\ninfo_mutations == \"Tableau\" ? html`&lt;div&gt;${table_mutations1}&lt;div&gt;` : html`&lt;div&gt;${plot_mutations}&lt;div&gt;`\n\n\n\n\n\n\n\nurl = \"https://files.data.gouv.fr/geo-dvf/latest/csv/2020/communes/92/92049.csv\"\nproxy = \"https://corsproxy.io/?\"\ndvf = d3.csv(proxy + url)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntable_mutations1 = Inputs.table(dvf, {\"columns\": ['date_mutation', 'valeur_fonciere', 'adresse_nom_voie']})\nplot_mutations = Plot.plot({\n  y: {grid: true, label: \"Nombre de transactions\"},\n  x: {\n    ticks: 12,\n    transform: (d) =&gt; Math.pow(10, d),\n    type: \"log\",\n    tickFormat: \"~s\",\n    label: \"Prix (échelle log) →\"\n  },\n  marks: [\n    Plot.rectY(\n      dvf.filter(d =&gt; d.valeur_fonciere &gt; 10000),\n      Plot.binX({y: \"count\"},\n      {\n        x: d =&gt; Math.log10(d.valeur_fonciere),\n        tip: true\n      })\n    ),\n    Plot.ruleY([0])\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot = require(\"https://cdn.jsdelivr.net/npm/@observablehq/plot@0.6.10/dist/plot.umd.min.js\")"
  },
  {
    "objectID": "slides/introduction.html#diversification-des-données-14-1",
    "href": "slides/introduction.html#diversification-des-données-14-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Diversification des données (1/4)",
    "text": "Diversification des données (1/4)\nDonnées tabulaires classiques\n\nDonnées structurées sous forme de tableau\n\n\nSource: Hadley Wickham, R for data science\n très bien outillé pour ces données (si volumétrie adaptée)"
  },
  {
    "objectID": "slides/introduction.html#diversification-des-données-24",
    "href": "slides/introduction.html#diversification-des-données-24",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Diversification des données (2/4)",
    "text": "Diversification des données (2/4)\n\nDonnées géolocalisées\n\n\nviewof info_power_plants = Inputs.radio(\n  [\"Tableau\", \"Carte\"], {value: \"Tableau\"}\n)\n\n\n\n\n\n\n\ninfo_power_plants == \"Tableau\" ? html`&lt;div&gt;${table_power_plants}&lt;div&gt;` : html`&lt;div&gt;${plot_power_plants}&lt;div&gt;`\n\n\n\n\n\n\n\nimport {us_power_plants, states} from \"@observablehq/build-your-first-map-with-observable-plot\"\n\ntable_power_plants = Inputs.table(\n  us_power_plants\n)\n\n\nplot_power_plants = Plot.plot({\n  projection: \"albers-usa\",\n  marks: [\n    Plot.geo(states, { fill: \"white\", stroke: \"#e2e2e2\"  }),\n    Plot.dot(us_power_plants, {\n      x: \"longitude\",\n      y: \"latitude\",\n      r: \"Total_MW\",\n      fill: \"PrimSource\",\n      opacity: 0.7,\n      tip: true\n    }),\n    Plot.dot(us_power_plants, { // Can you figure out what this additional Plot.dot layer adds?\n      x: \"longitude\",\n      y: \"latitude\",\n      r: \"Total_MW\",\n      fill: \"PrimSource\",\n      stroke: \"black\",\n      filter: d =&gt; d.Total_MW &gt; 3500,\n    }),\n    Plot.text(us_power_plants, { // Add text to the map using data from us_power_plants\n      x: \"longitude\", // Place text horizontally at plant longitude\n      y: \"latitude\", // Place text vertically at plant latitude\n      text: \"Plant_Name\", // The text that appears is the value from the Plant_Name column,\n      filter: (d) =&gt; d.Total_MW &gt; 3500, // Only add text for plants with capacity exceeding 3500 MW\n      fontSize: 12, // Increased font size\n      fontWeight: 600, // Increased font weight\n      stroke: \"white\", // Adds white outer stroke to text (for readability)\n      fill: \"black\", // Text fill color\n      textAnchor: \"start\", // Left align text with the x- and y-coordinates\n      dx: 15 // Shifts text to the right (starting from left alignment with coordinate)\n    })\n  ],\n  r: { range: [1, 15] },\n  color: { legend: true },\n  height: 500,\n  width: 800,\n  margin: 50\n})"
  },
  {
    "objectID": "slides/introduction.html#diversification-des-données-24-1",
    "href": "slides/introduction.html#diversification-des-données-24-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Diversification des données (2/4)",
    "text": "Diversification des données (2/4)\n\nDonnées géolocalisées\n\n\nDonnées tabulaires avec une dimension spatiale supplémentaire\n\nDimension géographique prend des formes multiples:\nPoints, lignes, polygones…\n\n\n\n\n très bien outillé pour ces données (si volumétrie adaptée)"
  },
  {
    "objectID": "slides/introduction.html#diversification-des-données-34",
    "href": "slides/introduction.html#diversification-des-données-34",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Diversification des données (3/4)",
    "text": "Diversification des données (3/4)\n\nDonnées textuelles et non structurées\n\n\nTechniques statistiques anciennes (Levenshtein 1957, perceptron) ;\n\n\n\nApplications limitées jusqu’aux années 2010 ;\n\n\n\n\nDéveloppement très rapide de la recherche :\n\nCollecte accrue : réseaux sociaux, enquêtes…\nBaisse coûts stockage & augmentation ressources traitement ;\nNouvelles techniques statistiques: webscraping, LLM…\n\n\n\n\n\nUtilisation intensive dans l’administration, la recherche et le secteur privé\n\nPlus d’infos dans mon cours sur les données émergentes"
  },
  {
    "objectID": "slides/introduction.html#diversification-des-données-44",
    "href": "slides/introduction.html#diversification-des-données-44",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Diversification des données (4/4)",
    "text": "Diversification des données (4/4)\nImages, sons et vidéos\n\nPlus d’infos dans mon cours sur les données émergentes"
  },
  {
    "objectID": "slides/introduction.html#apparition-de-nouveaux-acteurs",
    "href": "slides/introduction.html#apparition-de-nouveaux-acteurs",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Apparition de nouveaux acteurs",
    "text": "Apparition de nouveaux acteurs\n\nActeurs classiques:\n\nInstituts statistiques (INSEE et SSM1) ;\nAdministrations centrales (DGFiP, DINUM…) ou opérateurs (IGN…)\nPlus de détails à venir\n\n\n\n\nCollectivités locales (exemple: Open data Paris)\n\n\n\n\nProjets contributifs: OpenStreetMap, Wikidata, OpenFoodFacts…\n\n\n\n\nActeurs privés:\n\nCollectent des données sur leurs utilisateurs/clients (extrapolation possible?)\nPeuvent mettre à disposition ces données à d’autres acteurs (chercheurs par exemple)\nCadre réglementaire: RGPD\n\n\n\nLe service statistique public est constitué de l’Insee et des 16 services statistiques ministériels (SSM)"
  },
  {
    "objectID": "slides/introduction.html#accès-de-plus-en-plus-direct-à-la-donnée",
    "href": "slides/introduction.html#accès-de-plus-en-plus-direct-à-la-donnée",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Accès de plus en plus direct à la donnée",
    "text": "Accès de plus en plus direct à la donnée\n\nEre de l’open data et open source :\n\nMouvement accéléré depuis l’élection Obama 2008\nCréation Etalab en 2011 ;\nLoi pour une république numérique 2016\n\n\n\n\nChangements technologiques et culturels :\n\nFormats ouverts et standardisés ;\nSuccès des langages open source (notamment Python  et R )\nAcculturation aux API"
  },
  {
    "objectID": "slides/introduction.html#data-is-everywhere",
    "href": "slides/introduction.html#data-is-everywhere",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Data is everywhere",
    "text": "Data is everywhere"
  },
  {
    "objectID": "slides/introduction.html#linsee",
    "href": "slides/introduction.html#linsee",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "L’Insee",
    "text": "L’Insee\n\nCollecte, produit, analyse et diffuse l’information statistique :\n\nProducteur de statistiques (enquêtes, données administratives) ;\nProducteur d’études pour le débat public (rare chez les instituts statistiques)\n\n\n\n\nPublie énormément d’informations:\n\nRecensement, taux de chômage, inflation, PIB, fichier des prénoms…\nCode officiel géographique (COG) et zonages d’études\n\n\n\n\n\nRôle de coordination du service statistique public:\n\nInstituts statistiques ministériels: DREES (Santé), DARES (Travail)…\n\n\n\n\n\nDiffusion données sur insee.fr\n\nUtilisateurs de : accès facilité via des packages"
  },
  {
    "objectID": "slides/introduction.html#lign",
    "href": "slides/introduction.html#lign",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "L’IGN",
    "text": "L’IGN\n\nProduit et diffuse la géométrie du territoire national et l’occupation du sol:\n\nProducteur de cartes 🥾 (top25…)\nLIDAR\n\n\n\n\nProducteur des fonds de carte utiles pour nous:\n\nBDTopo, BD Forêt,\nAdminExpress\n\n\n\n\n\nDiffusion données depuis geoservices de l’IGN (en attendant la geoplateforme)\n\nUtilisateurs de : accès facilité à certaines sources via cartiflette"
  },
  {
    "objectID": "slides/introduction.html#data.gouv",
    "href": "slides/introduction.html#data.gouv",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "data.gouv",
    "text": "data.gouv\n\nPlateforme de l’open data en France\n\nCrée par Etalab (DINUM) en 2011\n\n\n\n\nRecense des jeux de données produits par les acteurs publics:\n\nAdministrations centrales\nCollectivités locales\n\n\n\n\n\nMise à disposition directe de certains jeux de données\n\n\n\n\nRecense des réutilisations"
  },
  {
    "objectID": "slides/introduction.html#github-fa-brands-github-là-où-on-trouve-du-code",
    "href": "slides/introduction.html#github-fa-brands-github-là-où-on-trouve-du-code",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Github : là où on trouve du code",
    "text": "Github : là où on trouve du code\n\nPlateforme de mise à disposition de code\n\n\n\nBeaucoup plus que seulement du code:\n\nDocumentation de projets\nSites web\n\n\n\n\n\nLieu de l’open source et de la recherche transparente"
  },
  {
    "objectID": "slides/introduction.html#observable-the-new-place-to-be",
    "href": "slides/introduction.html#observable-the-new-place-to-be",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Observable: the new place to be",
    "text": "Observable: the new place to be\n\nPlateforme de dataviz web\n\nCréée par Mike Bostock (dieu dans la dataviz)\n\n\n\n\nEmergence récente mais forte dynamique\n\nTrès complémentaire à R\n\n\n\n\n\nInvestie par des cartographes qui font de super visualisations :\n\nNicolas Lambert\nEric Mauvière\nThomas Ansart"
  },
  {
    "objectID": "slides/introduction.html#des-métiers-multiples-dans-ladministration",
    "href": "slides/introduction.html#des-métiers-multiples-dans-ladministration",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Des métiers multiples dans l’administration",
    "text": "Des métiers multiples dans l’administration\n\n\n\n\n\n\n\nmais aussi data engineer, data architect, data analyst…\ncf. Rapport INSEE-DINUM “Évaluation des besoins de l’État en compétences et expertises en matière de donnée”\n\n\n\n\nhttps://www.numerique.gouv.fr/uploads/RAPPORT-besoins-competences-donnee.pdf"
  },
  {
    "objectID": "slides/introduction.html#le-tournant-numérique-des-sciences-sociales",
    "href": "slides/introduction.html#le-tournant-numérique-des-sciences-sociales",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le tournant numérique des sciences sociales",
    "text": "Le tournant numérique des sciences sociales\n\nAccès facilité à des données spatialisées ;\nAcculturation aux SIG et langages statistiques ;\nDéveloppement de technologies web interactives (observable)\n\n\n\n\nRéférences\n\n\nRoth Camille. 2019. “Digital, Digitized, and Numerical Humanities.” Digital Scholarship in the Humanities\nAsh J, Kitchin R, Leszczynski A. 2018. “Digital turn, digital geographies ?” Progress in Human Geography\nEinav, L., & Levin, J. (2014). Economics in the age of big data. Science, 346(6210), 1243089."
  },
  {
    "objectID": "slides/introduction.html#le-tournant-numérique-des-sciences-sociales-1",
    "href": "slides/introduction.html#le-tournant-numérique-des-sciences-sociales-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le tournant numérique des sciences sociales",
    "text": "Le tournant numérique des sciences sociales\n\nWe live life in the network. We check our e-mails regularly, make mobile phone calls from almost any location, swipe transit cards to use public transportation,and make purchases with credit cards. Our movements in public places may be captured by video cameras, and our medical records stored as digital files. We may post blog entries accessible to anyone, or maintain friendships through online social networks. Each of these transactions leaves digital traces that can be compiled into comprehensive pictures of both individual and group behavior, with the potential to transform our understanding of our lives, organizations, and societies.\nLazer et al. ,Computational Social Science, Science (2009)"
  },
  {
    "objectID": "slides/introduction.html#la-géographie-quantitative",
    "href": "slides/introduction.html#la-géographie-quantitative",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "La géographie quantitative",
    "text": "La géographie quantitative\n\nUne des premières cartes statistiques (1798)"
  },
  {
    "objectID": "slides/introduction.html#la-géographie-quantitative-1",
    "href": "slides/introduction.html#la-géographie-quantitative-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "La géographie quantitative",
    "text": "La géographie quantitative\n\nJohn Snow cartographie le choléra à Londres"
  },
  {
    "objectID": "slides/introduction.html#années-1950-1960-révolution-quantitative",
    "href": "slides/introduction.html#années-1950-1960-révolution-quantitative",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Années 1950-1960 : révolution quantitative",
    "text": "Années 1950-1960 : révolution quantitative\n\nEverything is related to everything else, but near things are more related than distant things.\nW. Tobler, 1970, Economic Geography\n\n\nUne science nomothétique : recherche des lois générales de l’organisation de l’espace\n\n\n\nUne science explicative : modélisation\n\nModèle de Christaller\n\n\n\n\n\nUne science appliquée : essor de la regional science, de l’économétrie spatiale\n\nLoi de Zipf…)\n\n\n\n\n\nUne science de l’information (déjà):\n\nSémiologie (carto)graphique de Bertin, 1967"
  },
  {
    "objectID": "slides/introduction.html#années-2010-tournant-digital-de-la-géographie-quantitative",
    "href": "slides/introduction.html#années-2010-tournant-digital-de-la-géographie-quantitative",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Années 2010 : tournant “digital” de la géographie quantitative",
    "text": "Années 2010 : tournant “digital” de la géographie quantitative\n\nQuantification de masse de phénomènes spatiaux sociaux:\n\nDéplacements, lieux fréquentés…\n\n\n\n\nIntersection avec d’autres sciences : data science, CSS\n\nExemple: le RIATE\n\n\n\n\n\nArribas-Bel, D, 2018. “Geography and Computers: Past, Present, and Future” Geography Compass."
  },
  {
    "objectID": "slides/introduction.html#principe-dun-langage-open-source",
    "href": "slides/introduction.html#principe-dun-langage-open-source",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Principe d’un langage open source",
    "text": "Principe d’un langage open source\n\n\n\n\n\n\nPrincipe général\n\n\n\n\n\n\n\nIllustration avec R"
  },
  {
    "objectID": "slides/introduction.html#quest-ce-que-r",
    "href": "slides/introduction.html#quest-ce-que-r",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Qu’est-ce que R ?",
    "text": "Qu’est-ce que R ?\n\nLogiciel statistique open source:\n\nLangage de base\nPackages étendent les fonctionnalités\n\n\n\n\nAdoption importante dans le monde académique et l’administration\n\n\n\n\nBeaucoup de ressources d’aide en ligne\n\n\n\n\n\n\n\nNote\n\n\n\nNaissance dans les années 1990 ;\nSuccès depuis les années 2010 (succès parallèle à Python)"
  },
  {
    "objectID": "slides/introduction.html#un-logiciel-couteau-suisse",
    "href": "slides/introduction.html#un-logiciel-couteau-suisse",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Un logiciel couteau-suisse",
    "text": "Un logiciel couteau-suisse\n\nManipulation de données de tout type ;\n\n\n\nVisualisation de données (dataviz), cartographie & SIG ;\n\n\n\n\nModélisation (machine learning, analyse de réseaux…) ;\n\n\n\n\nRédaction de mémoires, de site web, de slides (comme celles-ci 🤓)…"
  },
  {
    "objectID": "slides/introduction.html#un-logiciel-couteau-suisse-1",
    "href": "slides/introduction.html#un-logiciel-couteau-suisse-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Un logiciel couteau-suisse",
    "text": "Un logiciel couteau-suisse\nOn peut tout faire en R:\n\nExtrait de R for data science (la bible)"
  },
  {
    "objectID": "slides/introduction.html#transparence-et-reproductibilité",
    "href": "slides/introduction.html#transparence-et-reproductibilité",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Transparence et reproductibilité",
    "text": "Transparence et reproductibilité\n\nTraçabilité des statistiques et réalisations graphiques\n\n\n\nPartage de code R permet une transparence méthodologique:\n\nDe plus en plus de journaux exigent les codes !\nEncore des progrès à faire dans le domaine\n\n\n\n\n\nL’utilisation de R Markdown rend plus efficace 🐢🔜🐇:\n\nSuppression des fichiers intermédiaires (texte, excel, images…)\nGain de temps sur la mise en page (des millions d’heures économisées au bas mot)\n\n\n\n\n\n\n\n\nNote\n\n\nVoir cours dédié sur le sujet des bonnes pratiques (Insee très impliquée sur le sujet!)"
  },
  {
    "objectID": "slides/introduction.html#une-communauté-dutilisateurs",
    "href": "slides/introduction.html#une-communauté-dutilisateurs",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Une communauté d’utilisateurs",
    "text": "Une communauté d’utilisateurs\n\nUn logiciel opensource :\n\nGratuit, collaboratif\n\n\n\n\nBeaucoup de packages:\n\nsur le CRAN (The Comprehensive R Archive Network)\nsur Github\n\n\n\n\n\nUne communauté d’idéalistes de la science ouverte\n\n\n\n\nUn pont vers les autres disciplines : sociologie, économie, biologie, sciences politiques etc."
  },
  {
    "objectID": "slides/introduction.html#le-ssp-cloud-cest-quoi",
    "href": "slides/introduction.html#le-ssp-cloud-cest-quoi",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le SSP Cloud, c’est quoi ?",
    "text": "Le SSP Cloud, c’est quoi ?"
  },
  {
    "objectID": "slides/introduction.html#le-ssp-cloud-cest-quoi-1",
    "href": "slides/introduction.html#le-ssp-cloud-cest-quoi-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le SSP Cloud, c’est quoi ?",
    "text": "Le SSP Cloud, c’est quoi ?\n\nDes serveurs hébergés à l’Insee avec de nombreux logiciels statistiques (dont R) dessus\nEnvironnement ouvert aux agents de l’Etat et à des formations en data science pour découvrir et expérimenter\nSeulement avec des données en open data\n\n\n\n\n\n\n\nNote\n\n\nPlus de détails dans la documentation du SSP Cloud ou dans utilitR"
  },
  {
    "objectID": "slides/introduction.html#pourquoi-utiliser-le-ssp-cloud",
    "href": "slides/introduction.html#pourquoi-utiliser-le-ssp-cloud",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Pourquoi utiliser le SSP Cloud ?",
    "text": "Pourquoi utiliser le SSP Cloud ?\n\nPénible d’installer R, RStudio et une ribambelle de packages\nMise à disposition d’un environnement standardisé:\n\nTP parfaitement reproductibles\n\nUn TP peut être lancé en un clic-bouton:\n\nExemple bouton TO DO"
  },
  {
    "objectID": "slides/introduction.html#créer-un-compte",
    "href": "slides/introduction.html#créer-un-compte",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Créer un compte",
    "text": "Créer un compte\n\nUtiliser votre adresse @ens.fr pour créer un compte sur https://datalab.sspcloud.fr/\nVotre nom d’utilisateur ne doit contenir ni caractères accentués, ni caractère spécial, ni signe de ponctuation:\n\n\nVous pouvez adopter le format prenomnom en faisant attention aux règles précédentes. Par exemple, si vous vous appelez Jérôme-Gérard L’Hâltère, votre nom d’utilisateur pourra être jeromegerardlhaltere."
  },
  {
    "objectID": "slides/introduction.html#lancer-un-service-rstudio",
    "href": "slides/introduction.html#lancer-un-service-rstudio",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Lancer un service RStudio",
    "text": "Lancer un service RStudio\nAide-mémoire\n\nCliquer à gauche sur Catalogue de service"
  },
  {
    "objectID": "slides/introduction.html#lancer-un-service-rstudio-1",
    "href": "slides/introduction.html#lancer-un-service-rstudio-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Lancer un service RStudio",
    "text": "Lancer un service RStudio\nAide-mémoire\n\nLaisser les options par défaut de RStudio"
  },
  {
    "objectID": "slides/introduction.html#lancer-un-service-rstudio-2",
    "href": "slides/introduction.html#lancer-un-service-rstudio-2",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Lancer un service RStudio",
    "text": "Lancer un service RStudio\nAide-mémoire\n\nRécupérer le mot de passe des services RStudio"
  },
  {
    "objectID": "slides/introduction.html#lancer-un-service-rstudio-3",
    "href": "slides/introduction.html#lancer-un-service-rstudio-3",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Lancer un service RStudio",
    "text": "Lancer un service RStudio\nAide-mémoire\n\nAutre manière de récupérer le mot de passe des services RStudio"
  },
  {
    "objectID": "slides/introduction.html#lancer-un-service-rstudio-4",
    "href": "slides/introduction.html#lancer-un-service-rstudio-4",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Lancer un service RStudio",
    "text": "Lancer un service RStudio\nAide-mémoire\n\nS’authentifier sur le service"
  },
  {
    "objectID": "slides/introduction.html#linterface-rstudio",
    "href": "slides/introduction.html#linterface-rstudio",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "L’interface RStudio",
    "text": "L’interface RStudio\n\nIllustration empruntée à ce livre"
  },
  {
    "objectID": "slides/wrangling.html#chapitre-introductif",
    "href": "slides/wrangling.html#chapitre-introductif",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Chapitre introductif",
    "text": "Chapitre introductif\n\n\n\n\n\n\nNote\n\n\n\nExercices associés à ce chapitre ici\n\n\n\n\n\n\nRetour à la page principale"
  },
  {
    "objectID": "slides/wrangling.html#introduction",
    "href": "slides/wrangling.html#introduction",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Introduction",
    "text": "Introduction\n\n centré autour du dataframe\n\n\n\nMais manipulations parfois un peu lourdes :\n\ndf$var: un peu lourd\ndf[,]: un peu trop calqué sur les matrices\n\n\n\n\n\nDonnées textuelles: une base perfectible\n\nDes outputs alambiqués\nDes fonctionnalités manquantes par rapport à Python"
  },
  {
    "objectID": "slides/wrangling.html#la-réponse-le-tidyverse",
    "href": "slides/wrangling.html#la-réponse-le-tidyverse",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "La réponse: le tidyverse !",
    "text": "La réponse: le tidyverse !\n\nL’écosystème du tidyverse"
  },
  {
    "objectID": "slides/wrangling.html#la-réponse-le-tidyverse-1",
    "href": "slides/wrangling.html#la-réponse-le-tidyverse-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "La réponse: le tidyverse !",
    "text": "La réponse: le tidyverse !\nUn ensemble de packages développés par RStudio qui facilite :\n\nLa lecture (readr) et la manipulation de bases de données (dplyr)\nL’exploitation de données textuelles (stringr), temporelles (lubridate) ou catégorielles (forcats)\nLa création de graphiques (ggplot2)\nLa programmation à partir de dataframes (purrr)\nEt bien d’autres choses…"
  },
  {
    "objectID": "slides/wrangling.html#le-concept-de-données-tidy",
    "href": "slides/wrangling.html#le-concept-de-données-tidy",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le concept de données tidy",
    "text": "Le concept de données tidy\n\nChaque variable possède sa propre colonne ;\nChaque observation possède sa propre ligne ;\nUne valeur, matérialisant une observation d’une variable, se trouve sur une unique cellule.\n\n\n\n\n\n\n\nNote\n\n\nConcept popularisé par Hadley Wickham."
  },
  {
    "objectID": "slides/wrangling.html#readr",
    "href": "slides/wrangling.html#readr",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "readr",
    "text": "readr\n\n\nLe package pour lire des fichiers plats (.csv, .txt…)\nPermet d’obtenir un tibble, le dataframe augmenté du tidyverse"
  },
  {
    "objectID": "slides/wrangling.html#dplyr",
    "href": "slides/wrangling.html#dplyr",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "dplyr",
    "text": "dplyr\n\n\nLe package central de l’écosystème de manipulation de données ;\nManipulation de données et statistiques descriptives ;"
  },
  {
    "objectID": "slides/wrangling.html#dplyr-1",
    "href": "slides/wrangling.html#dplyr-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "dplyr",
    "text": "dplyr\nPrincipaux verbes\nOn travaille sur un tibble (dataframe augmenté)\n\nselect() : sélectionner des variables par leur nom ;\nrename() : renommer des variables ;\nfilter() : sélectionner des observations selon une ou plusieurs conditions ;\narrange() : trier la table selon une ou plusieurs variables ;\nmutate() : ajouter des variables qui sont fonction d’autres variables ;\nsummarise() : calculer une statistique à partir de données ;\ngroup_by() : faire des opérations par groupe.- `"
  },
  {
    "objectID": "slides/wrangling.html#dplyr-2",
    "href": "slides/wrangling.html#dplyr-2",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "dplyr",
    "text": "dplyr\nManipulation de données\nOn enchaine des séquences avec les pipe (%&gt;%)\n\nlibrary(doremifasol)\nlibrary(dplyr)\n\nbase_publique_equipements &lt;- telechargerDonnees(\"BPE_ENS\")\nbase_publique_equipements %&gt;%\n1  as_tibble() %&gt;%\n2  filter(TYPEQU == \"B316\") %&gt;%\n3  mutate(x = paste0(AN, \"_\", NB_EQUIP))\n\n\n1\n\nOn convertit le dataframe standard en tibble\n\n2\n\nOn ne garde que les stations services (valeurs B316 de TYPEQU)\n\n3\n\nOn crée une nouvelle colonne en faisant référence à celles existantes (sans guillemets!)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nPlus de détails dans utilitR"
  },
  {
    "objectID": "slides/wrangling.html#dplyr-3",
    "href": "slides/wrangling.html#dplyr-3",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "dplyr",
    "text": "dplyr\nStatistiques agrégées\n\nLogique du split-apply-combine avec groupby\n\n\n\nIllustration du split-apply-combine\n\n\n\n\nlibrary(doremifasol)\nlibrary(dplyr)\n\nbase_publique_equipements &lt;- telechargerDonnees(\"BPE_ENS\")\nbase_publique_equipements %&gt;%\n1  as_tibble() %&gt;%\n2  filter(TYPEQU == \"B316\") %&gt;%\n3  group_by(DEP) %&gt;%\n4  summarise(nombre_station_serv = sum(NB_EQUIP, na.rm = TRUE))\n\n\n1\n\nOn convertit le dataframe standard en tibble\n\n2\n\nOn ne garde que les stations services (valeurs B316 de TYPEQU)\n\n3\n\nOn définit DEP comme une variable de stratification pour définir des groupes\n\n4\n\nOn résume les données en faisant la somme des stations services dans chaque groupe"
  },
  {
    "objectID": "slides/wrangling.html#ggplot",
    "href": "slides/wrangling.html#ggplot",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "ggplot",
    "text": "ggplot\n\n\nLe package indispensable pour faire des graphiques ❤️ ;\nApproche cohérente et flexible basée sur la grammaire des graphiques\n\nObjet d’un chapitre dédié"
  },
  {
    "objectID": "slides/wrangling.html#stringr-forcats-et-lubridate",
    "href": "slides/wrangling.html#stringr-forcats-et-lubridate",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "stringr, forcats et lubridate",
    "text": "stringr, forcats et lubridate\n\n  \n\n\nPlein de fonctions facilitant la manipulation:\n\nDonnées textuelles: stringr\nDonnées catégorielles: forcats\nDonnées temporelles: lubridate"
  },
  {
    "objectID": "slides/wrangling.html#généralités",
    "href": "slides/wrangling.html#généralités",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Généralités",
    "text": "Généralités\n\nDonnées peuvent être stockées dans de nombreux formats différents\n\nStandards différents\nManières d’importer différentes\n\n\n\n\nFonctionnalités de  limitées:\n\nPackages spécialisés pour certains formats\nObjectif: applatir l’information dans un dataframe\n\n\n\n\n\n\n\n\nNote\n\n\nOn verra les formats géographiques, et leurs enjeux, ultérieurement"
  },
  {
    "objectID": "slides/wrangling.html#le-csv",
    "href": "slides/wrangling.html#le-csv",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le CSV",
    "text": "Le CSV\n\nFormat de fichier plat avec des colonnes délimitées:\n\nStandard: , en délimitateur, . en décimale ;\nVariante européenne 😮‍💨: ; en délimitateur, , en décimale\n\nFormat universel, simple d’utilisation (quelques limites)\n\n\nviewof info_csv = Inputs.radio(\n  [\"Fichier brut\", \"Ficher après import\"], {value: \"Fichier brut\"}\n)\n\n\n\n\n\n\n\ninfo_csv == \"Fichier brut\" ? html`&lt;div&gt;${md_csv}&lt;div&gt;` : html`&lt;div&gt;${df_csv}&lt;div&gt;`\n\n\n\n\n\n\n\ndf_csv = Inputs.table(\n  d3.csvParse(raw_csv)\n)\nmd_csv = md`\n\\`\\`\\`\n${raw_csv}\n\\`\\`\\`\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nraw_csv = `DEP,REG,CHEFLIEU,TNCC,NCC,NCCENR,LIBELLE\n01,84,01053,5,AIN,Ain,Ain\n02,32,02408,5,AISNE,Aisne,Aisne\n03,84,03190,5,ALLIER,Allier,Allier\n04,93,04070,4,ALPES DE HAUTE PROVENCE,Alpes-de-Haute-Provence,Alpes-de-Haute-Provence\n05,93,05061,4,HAUTES ALPES,Hautes-Alpes,Hautes-Alpes\n06,93,06088,4,ALPES MARITIMES,Alpes-Maritimes,Alpes-Maritimes\n`"
  },
  {
    "objectID": "slides/wrangling.html#le-csv-1",
    "href": "slides/wrangling.html#le-csv-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le CSV",
    "text": "Le CSV\n\nLecture avec la fonction read_csv du package readr!\n\n\n1library(readr)\n2read_csv(\"dossier_donnees/nom_fichier.csv\")\n\n\n1\n\nOn importe la librairie readr pour avoir accès à la fonction read_csv\n\n2\n\nOn utilise read_csv pour lire les données stockées dans le chemin relatif dossier_donnees/nom_fichier.csv\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nCSV avec délimitateur ;: fonction read_csv2.\nFormats plats plus exotiques (.txt par exemple): read_delim\n\nPlus de détails dans la documentation utilitR"
  },
  {
    "objectID": "slides/wrangling.html#le-json",
    "href": "slides/wrangling.html#le-json",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le JSON",
    "text": "Le JSON\n\nLe format du web, notamment des API\n\nAPI: on verra ça plus tard\n\n\n\nviewof info_json = Inputs.radio(\n  [\"Fichier brut\", \"Ficher après import\"], {value: \"Fichier brut\"}\n)\n\n\n\n\n\n\n\ninfo_json == \"Fichier brut\" ? html`&lt;div&gt;${md_json}&lt;div&gt;` : html`&lt;div&gt;${df_json}&lt;div&gt;`\n\n\n\n\n\n\n\njson_string = `[\n  {\"DEP\": \"01\", \"REG\": \"84\", \"CHEFLIEU\": \"01053\", \"TNCC\": \"5\", \"NCC\": \"AIN\", \"NCCENR\": \"Ain\", \"LIBELLE\": \"Ain\"},\n  {\"DEP\": \"02\", \"REG\": \"32\", \"CHEFLIEU\": \"02408\", \"TNCC\": \"5\", \"NCC\": \"AISNE\", \"NCCENR\": \"Aisne\", \"LIBELLE\": \"Aisne\"},\n  {\"DEP\": \"03\", \"REG\": \"84\", \"CHEFLIEU\": \"03190\", \"TNCC\": \"5\", \"NCC\": \"ALLIER\", \"NCCENR\": \"Allier\", \"LIBELLE\": \"Allier\"},\n  {\"DEP\": \"04\", \"REG\": \"93\", \"CHEFLIEU\": \"04070\", \"TNCC\": \"4\", \"NCC\": \"ALPES DE HAUTE PROVENCE\", \"NCCENR\": \"Alpes-de-Haute-Provence\", \"LIBELLE\": \"Alpes-de-Haute-Provence\"},\n  {\"DEP\": \"05\", \"REG\": \"93\", \"CHEFLIEU\": \"05061\", \"TNCC\": \"4\", \"NCC\": \"HAUTES ALPES\", \"NCCENR\": \"Hautes-Alpes\", \"LIBELLE\": \"Hautes-Alpes\"},\n  {\"DEP\": \"06\", \"REG\": \"93\", \"CHEFLIEU\": \"06088\", \"TNCC\": \"4\", \"NCC\": \"ALPES MARITIMES\", \"NCCENR\": \"Alpes-Maritimes\", \"LIBELLE\": \"Alpes-Maritimes\"}\n]`\nraw_json = [\n  {\"DEP\": \"01\", \"REG\": \"84\", \"CHEFLIEU\": \"01053\", \"TNCC\": \"5\", \"NCC\": \"AIN\", \"NCCENR\": \"Ain\", \"LIBELLE\": \"Ain\"},\n  {\"DEP\": \"02\", \"REG\": \"32\", \"CHEFLIEU\": \"02408\", \"TNCC\": \"5\", \"NCC\": \"AISNE\", \"NCCENR\": \"Aisne\", \"LIBELLE\": \"Aisne\"},\n  {\"DEP\": \"03\", \"REG\": \"84\", \"CHEFLIEU\": \"03190\", \"TNCC\": \"5\", \"NCC\": \"ALLIER\", \"NCCENR\": \"Allier\", \"LIBELLE\": \"Allier\"},\n  {\"DEP\": \"04\", \"REG\": \"93\", \"CHEFLIEU\": \"04070\", \"TNCC\": \"4\", \"NCC\": \"ALPES DE HAUTE PROVENCE\", \"NCCENR\": \"Alpes-de-Haute-Provence\", \"LIBELLE\": \"Alpes-de-Haute-Provence\"},\n  {\"DEP\": \"05\", \"REG\": \"93\", \"CHEFLIEU\": \"05061\", \"TNCC\": \"4\", \"NCC\": \"HAUTES ALPES\", \"NCCENR\": \"Hautes-Alpes\", \"LIBELLE\": \"Hautes-Alpes\"},\n  {\"DEP\": \"06\", \"REG\": \"93\", \"CHEFLIEU\": \"06088\", \"TNCC\": \"4\", \"NCC\": \"ALPES MARITIMES\", \"NCCENR\": \"Alpes-Maritimes\", \"LIBELLE\": \"Alpes-Maritimes\"}\n]\nmd_json = md`\n\\`\\`\\`\n${json_string}\n\\`\\`\\`\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndf_json = Inputs.table(raw_json)"
  },
  {
    "objectID": "slides/wrangling.html#le-json-1",
    "href": "slides/wrangling.html#le-json-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Le JSON",
    "text": "Le JSON\n\nImporté comme une liste hiérarchisée\nObjectif: transformer cette information dans un dataframe tidy\n\nPas toujours évident !\n\n\n\n1library(jsonlite)\n2df &lt;- fromJSON(file=\"dossier_donnees/nom_fichier.json\")\n\n\n1\n\nOn importe la librairie jsonlite pour avoir accès à la fonction fromJSON\n\n2\n\nOn utilise fromJSON pour lire les données stockées dans le chemin relatif dossier_donnees/nom_fichier.csv"
  },
  {
    "objectID": "slides/wrangling.html#les-formats-excel",
    "href": "slides/wrangling.html#les-formats-excel",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Les formats Excel",
    "text": "Les formats Excel"
  },
  {
    "objectID": "slides/wrangling.html#les-formats-excel-1",
    "href": "slides/wrangling.html#les-formats-excel-1",
    "title": "Introduction aux méthodes quantitatives avec ",
    "section": "Les formats Excel",
    "text": "Les formats Excel\n\nFormat propriétaire\nMélange mise en forme et données brute\n\nPas approprié pour l’analyse de données\nDangereux pour la reproductibilité et la transparence\n\nPlus de détails sur utilitR\n\n\n\nIntroduction aux méthodes quantitatives avec , École Normale Supérieure (retour page principale)"
  },
  {
    "objectID": "exercises/geospatial-wrangling.html",
    "href": "exercises/geospatial-wrangling.html",
    "title": "Manipuler des données spatiales avec sf",
    "section": "",
    "text": "Dans ce troisième TP, nous allons apprendre à importer et manipuler des données spatiales avec . Ce logiciel propose des fonctionnalités très intéressantes pour ce type de données complexes qui le rendent capable de se comporter comme un SIG. Grâce à la librairie sf, une extension de dplyr aux données spatiales, les données géographiques pourront être manipulées comme n’importe quel type de données avec . La complexité induite par la dimension spatiale ne sera pas ressentie.\nSi vous êtes intéressés par Python , une version très proche de ce TP est disponible dans mon cours de l’ENSAE.\nDans ce chapitre, nous allons utiliser les packages suivants:\nlibrary(units)\nlibrary(dplyr)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(leaflet)\nlibrary(cartiflette)"
  },
  {
    "objectID": "exercises/geospatial-wrangling.html#lire-et-enrichir-des-données-spatiales",
    "href": "exercises/geospatial-wrangling.html#lire-et-enrichir-des-données-spatiales",
    "title": "Manipuler des données spatiales avec sf",
    "section": "1 Lire et enrichir des données spatiales",
    "text": "1 Lire et enrichir des données spatiales\nDans cette partie, nous utiliserons les fonds de carte de l’IGN dont la mise à disposition est facilitée par le projet cartiflette1.\n\n\n\n\n\n\nExercice 1: lire et explorer la structure de fichiers géographiques\n\n\n\n\nS’inspirer des exemples de code présents dans les slides mobilisant le package cartiflette pour télécharger les données communales des départements 75, 92, 93 et 94. Vous pouvez nommer l’objet communes_borders\nRegarder les premières lignes des données. Identifier la différence avec un DataFrame standard.\nAfficher le crs de communes_borders. Ce dernier contrôle la transformation de l’espace tridimensionnel terrestre en une surface plane. Utiliser st_transform pour transformer les données en Lambert 93, le système officiel (code EPSG 2154).\nAfficher les communes des Hauts de Seine (département 92) et représenter rapidement la carte.\nRéprésenter la carte de Paris : quel est le problème ?\n\n\n\n\n\nSi vous désirez observer l’aspect de la carte du 92 (question 4), déroulez cette partie.\n\n\n\n\n\n\n\nEn ce qui concerne Paris, à l’issue de la question 5, la carte aura l’aspect suivant:\n\n\n\n\n\nOn remarque rapidement le problème. On ne dispose ainsi pas des limites des arrondissements parisiens, ce qui appauvrit grandement la carte de Paris.\nOn pourrait les récupérer directement depuis le site d’open-data du Grand Paris mais on propose ici d’utiliser à nouveau cartiflette afin de disposer du fonds de carte officiel des arrondissements.\n\n\n\n\n\n\nExercice 2: compléter des données spatiales issues de sources différentes\n\n\n\n\nImporter les données de découpage des arrondissements parisiens à l’adresse à l’aide de cartiflette.\nVérifier sur une carte que les découpages des arrondissements sont bien présents.\nVérifier l’attribut crs. Est-il cohérent avec celui des données communales ? Si non, transformer en Lambert 93 (code EPSG 2154).\nRetirer Paris du jeu de données communales et utiliser les arrondissements pour enrichir (nommer l’objet obtenu data_borders).\nReprésenter à nouveau les communes de la petite couronne parisienne (75, 92, 93, 94)\n\n\n\n\n\nReading layer `raw' from data source \n  `https://minio.lab.sspcloud.fr/projet-cartiflette/diffusion/shapefiles-test2/year=2022/administrative_level=ARRONDISSEMENT_MUNICIPAL/crs=4326/DEPARTEMENT=75/vectorfile_format=geojson/provider=IGN/source=EXPRESS-COG-CARTO-TERRITOIRE/raw.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 20 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2.224217 ymin: 48.81556 xmax: 2.469851 ymax: 48.90215\nGeodetic CRS:  WGS 84\n\n\nSimple feature collection with 20 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2.224217 ymin: 48.81556 xmax: 2.469851 ymax: 48.90215\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                         ID                      NOM                    NOM_M\n1  ARR_MUNI0000000009736045  Paris 3e Arrondissement  PARIS 3E ARRONDISSEMENT\n2  ARR_MUNI0000000009736046  Paris 2e Arrondissement  PARIS 2E ARRONDISSEMENT\n3  ARR_MUNI0000000009736545  Paris 4e Arrondissement  PARIS 4E ARRONDISSEMENT\n4  ARR_MUNI0000000009736544  Paris 5e Arrondissement  PARIS 5E ARRONDISSEMENT\n5  ARR_MUNI0000000009736543  Paris 6e Arrondissement  PARIS 6E ARRONDISSEMENT\n6  ARR_MUNI0000000009736043  Paris 9e Arrondissement  PARIS 9E ARRONDISSEMENT\n7  ARR_MUNI0000000009736042 Paris 10e Arrondissement PARIS 10E ARRONDISSEMENT\n8  ARR_MUNI0000000009736035 Paris 11e Arrondissement PARIS 11E ARRONDISSEMENT\n9  ARR_MUNI0000000009736531 Paris 13e Arrondissement PARIS 13E ARRONDISSEMENT\n10 ARR_MUNI0000000009736044  Paris 8e Arrondissement  PARIS 8E ARRONDISSEMENT\n   INSEE_ARM INSEE_COM POPULATION INSEE_DEP                           source\n1      75103     75056      34025        75 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n2      75102     75056      21595        75 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n3      75104     75056      29131        75 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n4      75105     75056      58227        75 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n5      75106     75056      40303        75 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n6      75109     75056      60026        75 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n7      75110     75056      86472        75 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n8      75111     75056     145208        75 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n9      75113     75056     180005        75 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n10     75108     75056      35655        75 IGN:EXPRESS-COG-CARTO-TERRITOIRE\n                         geometry\n1  POLYGON ((2.350164 48.86199...\n2  POLYGON ((2.347918 48.87069...\n3  POLYGON ((2.368491 48.85581...\n4  POLYGON ((2.336657 48.83967...\n5  POLYGON ((2.332916 48.85934...\n6  POLYGON ((2.325888 48.86958...\n7  POLYGON ((2.364714 48.88437...\n8  POLYGON ((2.376905 48.87205...\n9  POLYGON ((2.364204 48.8164,...\n10 POLYGON ((2.327165 48.88346...\n\n\n\n\n\n\n\nLa carte de Paris intra-muros est, après la récupération des arrondissements avec cartiflette de ce type là:"
  },
  {
    "objectID": "exercises/geospatial-wrangling.html#utiliser-des-données-géographiques-comme-des-couches-graphiques",
    "href": "exercises/geospatial-wrangling.html#utiliser-des-données-géographiques-comme-des-couches-graphiques",
    "title": "Manipuler des données spatiales avec sf",
    "section": "2 Utiliser des données géographiques comme des couches graphiques",
    "text": "2 Utiliser des données géographiques comme des couches graphiques\nSouvent, le découpage communal ne sert qu’en fond de cartes, pour donner des repères. En complément de celui-ci, on peut désirer exploiter un autre jeu de données.\nOn va partir des données de localisation des stations velib, disponibles sur le site d’open data de la ville de Paris et requêtables directement par l’url https://opendata.paris.fr/explore/dataset/velib-emplacement-des-stations/download/?format=geojson&timezone=Europe/Berlin&lang=fr\n\n\n\n\n\n\nExercice 3: importer et explorer les données velib\n\n\n\n\nImporter les données velib sous le nom station\nVérifier la projection géographique de station (attribut crs). Si celle-ci est différente des données communales, reprojeter ces dernières dans le même système de projection que les stations de vélib\nReprésenter sur une carte les 50 stations les plus importantes (variable capacity). Vous pouvez également afficher le fonds de carte des arrondissements de Paris. Cette page peut vous aider pour comprendre comment afficher plusieurs couches à la fois. Vous pouvez customiser la carte en retirant les axes grâce à la méthode set_axis_off et mettre un titre tel que “Les 50 principales stations de Vélib” avec la méthode set_title.\nAfficher également (trait bleu et épais) les réseaux de transport en communs, disponibles ici. L’url à requêter est https://data.iledefrance-mobilites.fr/explore/dataset/traces-du-reseau-ferre-idf/download/?format=geojson&timezone=Europe/Berlin&lang=fr\n\n\n\n\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.318569 ymin: 48.82436 xmax: 2.424739 ymax: 48.88321\nGeodetic CRS:  WGS 84\n  capacity                          name stationcode     coordonnees_geo\n1       23              Lacépède - Monge        5110 48.843893, 2.351966\n2       28                Raspail Barbès       31028 48.852995, 2.424739\n3       63              Regnault - Patay       13118 48.824358, 2.377065\n4       22         Las Cases - Bourgogne        7011 48.859091, 2.318569\n5       27             Douai - Bruxelles        9038 48.883208, 2.330845\n6       17 Quai de l'Horloge - Pont Neuf        1001 48.857059, 2.341798\n                   geometry\n1 POINT (2.351966 48.84389)\n2 POINT (2.424739 48.85299)\n3 POINT (2.377065 48.82436)\n4 POINT (2.318569 48.85909)\n5 POINT (2.330845 48.88321)\n6 POINT (2.341798 48.85706)\n\n\n\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nLa carte attendu à l’issue de la question 3 a l’aspect suivant:\n\n\n\n\n\n\n\nReading layer `OGRGeoJSON' from data source \n  `https://data.iledefrance-mobilites.fr/explore/dataset/traces-du-reseau-ferre-idf/download/?format=geojson&timezone=Europe/Berlin&lang=fr' \n  using driver `GeoJSON'\nSimple feature collection with 1638 features and 21 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 1.149741 ymin: 47.95678 xmax: 3.512889 ymax: 49.4262\nGeodetic CRS:  WGS 84\n\n\nL’ajout du réseau de métro permet d’obtenir une carte ressemblant à celle-ci:\n\n\n\n\n\nPour faire une belle carte, il faudrait couper les lignes de métro via une jointure spatiale ou privilégier un fonds de carte conceptuel. La méthode pour faire des cartes contextuelles est proposée en exercice supplémentaire 👇️. puisqu’elle implique des connaissances minimales avec leaflet que nous verrons ultérieurement."
  },
  {
    "objectID": "exercises/geospatial-wrangling.html#jointures-spatiales",
    "href": "exercises/geospatial-wrangling.html#jointures-spatiales",
    "title": "Manipuler des données spatiales avec sf",
    "section": "3 Jointures spatiales",
    "text": "3 Jointures spatiales\nLes jointures attributaires fonctionnent comme avec un tibble classique. Pour conserver un objet spatial in fine, il faut faire attention à utiliser en premier (base de gauche) l’objet sf. En revanche, l’un des intérêts des objets geopandas est qu’on peut également faire une jointure sur la dimension spatiale grâce à plusieurs fonctions:\n\n\n\n\n\n\n\nFonction\nOpération\n\n\n\n\nst_intersects()\nQuelles géométries de x intersectent celles de y ?\n\n\nst_contains()\nQuelles géométries de x contiennent celles de y ?\n\n\nst_disjoint()\nQuelles géométries de x sont disjointes à celles de y ?\n\n\nst_is_within_distance()\nQuelles géométries de x est à moins de\n\n\nm/km de celles de y ?\n\n\n\n\nLa documentation à laquelle se référer est ici. Une version pédagogique se trouve dans la documentation utilitR.\n\n\n\n\n\n\nExercice 4: Associer les stations aux communes et arrondissements auxquels elles appartiennent\n\n\n\n\nFaire une jointure spatiale pour enrichir les données de stations en y ajoutant des informations de data_paris. Appeler cet objet stations_info\nReprésenter la carte des stations du 19e arrondissement (s’aider de la variable NOM). Vous pouvez mettre en fond de carte les arrondissements parisiens.\nCompter le nombre de stations velib et le nombre de places velib par arrondissement ou commune (pour vous aider, vous pouvez compléter vos connaissances avec ce tutoriel). Représenter sur une carte chacune des informations\nReprésenter les mêmes informations mais en densité (diviser par la surface de l’arrondissement ou commune en km2)\n(optionnel) Choisir une des cartes de densité et la nettoyer (retirer les axes, mettre les titres…)\n\n\n\nPour la question 2, la première méthode consiste à afficher toute la ville mais à ne représenter que les points des stations du 19e:\n\n\n\n\n\n\n\n\nJoining with `by = join_by(ID, NOM, NOM_M, INSEE_COM, STATUT, POPULATION,\nINSEE_CAN, INSEE_ARR, INSEE_DEP, INSEE_REG, SIREN_EPCI, source, INSEE_ARM)`\n\n\nEnfin, dans la question 4, si on représente plutôt la capacité sous forme de densité, pour tenir compte de la taille différente des arrondissements, on obtient cette carte:\n\n\nSimple feature collection with 1531 features and 21 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 637298.9 ymin: 6843146 xmax: 671750.3 ymax: 6879246\nProjected CRS: RGF93 / Lambert-93\nFirst 10 features:\n                         ID              NOM            NOM_M INSEE_COM\n1  COMMUNE_0000000009736037 Levallois-Perret LEVALLOIS-PERRET     92044\n2  COMMUNE_0000000009736037 Levallois-Perret LEVALLOIS-PERRET     92044\n3  COMMUNE_0000000009736037 Levallois-Perret LEVALLOIS-PERRET     92044\n4  COMMUNE_0000000009736037 Levallois-Perret LEVALLOIS-PERRET     92044\n5  COMMUNE_0000000009736037 Levallois-Perret LEVALLOIS-PERRET     92044\n6  COMMUNE_0000000009736037 Levallois-Perret LEVALLOIS-PERRET     92044\n7  COMMUNE_0000000009736037 Levallois-Perret LEVALLOIS-PERRET     92044\n8  COMMUNE_0000000009736037 Levallois-Perret LEVALLOIS-PERRET     92044\n9  COMMUNE_0000000009736037 Levallois-Perret LEVALLOIS-PERRET     92044\n10 COMMUNE_0000000009736037 Levallois-Perret LEVALLOIS-PERRET     92044\n           STATUT POPULATION INSEE_CAN INSEE_ARR INSEE_DEP INSEE_REG\n1  Commune simple      66082        16         2        92        11\n2  Commune simple      66082        16         2        92        11\n3  Commune simple      66082        16         2        92        11\n4  Commune simple      66082        16         2        92        11\n5  Commune simple      66082        16         2        92        11\n6  Commune simple      66082        16         2        92        11\n7  Commune simple      66082        16         2        92        11\n8  Commune simple      66082        16         2        92        11\n9  Commune simple      66082        16         2        92        11\n10 Commune simple      66082        16         2        92        11\n            SIREN_EPCI                           source INSEE_ARM\n1  200054781/200057982 IGN:EXPRESS-COG-CARTO-TERRITOIRE      &lt;NA&gt;\n2  200054781/200057982 IGN:EXPRESS-COG-CARTO-TERRITOIRE      &lt;NA&gt;\n3  200054781/200057982 IGN:EXPRESS-COG-CARTO-TERRITOIRE      &lt;NA&gt;\n4  200054781/200057982 IGN:EXPRESS-COG-CARTO-TERRITOIRE      &lt;NA&gt;\n5  200054781/200057982 IGN:EXPRESS-COG-CARTO-TERRITOIRE      &lt;NA&gt;\n6  200054781/200057982 IGN:EXPRESS-COG-CARTO-TERRITOIRE      &lt;NA&gt;\n7  200054781/200057982 IGN:EXPRESS-COG-CARTO-TERRITOIRE      &lt;NA&gt;\n8  200054781/200057982 IGN:EXPRESS-COG-CARTO-TERRITOIRE      &lt;NA&gt;\n9  200054781/200057982 IGN:EXPRESS-COG-CARTO-TERRITOIRE      &lt;NA&gt;\n10 200054781/200057982 IGN:EXPRESS-COG-CARTO-TERRITOIRE      &lt;NA&gt;\n              area capacity                                  name stationcode\n1  2.417473 [km^2]       50        Anatole France - Louise Michel       23009\n2  2.417473 [km^2]       39     Paul Vaillant Couturier - Chaptal       23001\n3  2.417473 [km^2]       26    Hôtel de Ville de Levallois Perret       23008\n4  2.417473 [km^2]       50               Pont de Levallois-bécon       23002\n5  2.417473 [km^2]       27             Voltaire - Anatole France       23010\n6  2.417473 [km^2]       26              Gare de Clichy-Levallois       23005\n7  2.417473 [km^2]       28             Président Wilson - Baudin       23003\n8  2.417473 [km^2]       25                 Jules Guesde - Alsace       23006\n9  2.417473 [km^2]        0                Bineau - Louise Michel       23011\n10 2.417473 [km^2]       36 Paul Vaillant-Couturier - Victor Hugo       23004\n       coordonnees_geo stationcode_count capacity_sum\n1  48.888732, 2.288158                11          334\n2  48.893480, 2.277525                11          334\n3  48.893145, 2.288882                11          334\n4  48.898418, 2.279131                11          334\n5  48.891999, 2.284263                11          334\n6  48.896798, 2.298468                11          334\n7  48.898269, 2.284934                11          334\n8  48.890566, 2.295078                11          334\n9  48.886662, 2.284327                11          334\n10 48.898197, 2.293848                11          334\n                         geometry  capacity_density\n1  POLYGON ((647761.4 6867307,... 20.68275 [1/km^2]\n2  POLYGON ((647761.4 6867307,... 16.13255 [1/km^2]\n3  POLYGON ((647761.4 6867307,... 10.75503 [1/km^2]\n4  POLYGON ((647761.4 6867307,... 20.68275 [1/km^2]\n5  POLYGON ((647761.4 6867307,... 11.16869 [1/km^2]\n6  POLYGON ((647761.4 6867307,... 10.75503 [1/km^2]\n7  POLYGON ((647761.4 6867307,... 11.58234 [1/km^2]\n8  POLYGON ((647761.4 6867307,... 10.34138 [1/km^2]\n9  POLYGON ((647761.4 6867307,...  0.00000 [1/km^2]\n10 POLYGON ((647761.4 6867307,... 14.89158 [1/km^2]"
  },
  {
    "objectID": "exercises/geospatial-wrangling.html#exercices-supplémentaires",
    "href": "exercises/geospatial-wrangling.html#exercices-supplémentaires",
    "title": "Manipuler des données spatiales avec sf",
    "section": "4 Exercices supplémentaires",
    "text": "4 Exercices supplémentaires"
  },
  {
    "objectID": "exercises/geospatial-wrangling.html#footnotes",
    "href": "exercises/geospatial-wrangling.html#footnotes",
    "title": "Manipuler des données spatiales avec sf",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLa librairie  est expérimentale mais les prochaines semaines devraient permettre de combler ce manque. Une documentation interactive illustrant le code nécessaire pour reproduire telle ou telle carte est disponible sur linogaliana.github.io/cartiflette-website.↩︎"
  },
  {
    "objectID": "exercises/r-base.html",
    "href": "exercises/r-base.html",
    "title": "Découverte des objets de base de ",
    "section": "",
    "text": "Dans ce premier TP, nous allons rentrer tranquillement dans notre parcours de découverte de .\nCela se fera par les étapes suivantes:"
  },
  {
    "objectID": "exercises/r-base.html#numeric",
    "href": "exercises/r-base.html#numeric",
    "title": "Découverte des objets de base de ",
    "section": "2.1 Les vecteurs numériques (numeric)",
    "text": "2.1 Les vecteurs numériques (numeric)\n\n2.1.1 Les deux types de vecteurs numériques\n propose différents types d’objets numériques. Pour l’analyse de données, nous allons principalement nous intéresser principalement à deux types :\n\nles entiers (type int pour integer)\nles nombres réels (type double pour nombres à virgule flottante)\n\nEn pratique, les premiers sont un cas spécial des seconds. Contrairement à d’autres langages,  ne tente pas de contraindre de manière automatique les nombres sans virgules à être des entiers (integers). C’est pratique mais sur de gros volumes de données ça peut poser problème car les double sont plus lourds que les int.\nEn général, on utilise la fonction class pour afficher le type d’un objet  et si on veut être plus précis on peut utiliser typeof:\n\nclass(3)\ntypeof(3)\nclass(3.14)\ntypeof(3.14)\n\nLes fonctions as.numeric et as.integer peuvent être utilisées pour convertir d’un type à l’autre:\n\n# Conversion en int\nas.integer(3.79)\n\n[1] 3\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAttention à la conversion double \\(\\to\\) int, qui tronque la partie décimale.\n\n# double -&gt; int -&gt; double\nas.numeric(\n    as.integer(3.79)\n)\n\n[1] 3\n\n\n\n\nLes floats peuvent également être écrits en notation scientifique :\n\n2e3\n\n[1] 2000\n\nclass(2e3)\n\n[1] \"numeric\"\n\n\n\n\n2.1.2 Opérations arithmétiques de base\n\n\n\n\n\nComme tout langage informatique,  est avant tout une calculette. On est sauvé, on peut donc faire des additions:\n\n# Addition\n8 + 9\n\n[1] 17\n\n\n\n\n\n\n\n\nNote\n\n\n\n est bien fait, il adapte le type des variables pour les mettre en cohérence lorsqu’elles peuvent l’être:\n\n# Addition\n8.1 + as.integer(9)\n\n[1] 17.1\n\n\n\n\nOn a bien-sûr accès à d’autres opérations standards:\n\n# Soustraction\n5 - 2\n\n[1] 3\n\n# Multiplication\n2 * 6\n\n[1] 12\n\n# Division\n9 / 4\n\n[1] 2.25\n\n\nIl faut tout de même faire attention à la division par 0\n\n# Division par 0\n3 / 0\n\n[1] Inf\n\n-5 / 0\n\n[1] -Inf\n\n\n\n\n\n\n\n\nWarning\n\n\n\nCertains langages, comme Python, ne permettent pas la division par 0, ils renvoient une erreur plutôt qu’Inf. C’est un peu piégeux en R car cela peut arriver d’avoir des divisions par 0 sans qu’on s’en rende compte…\n\n\nComme toute calculette, on peut appliquer d’autres types d’opérations\n\n# Division euclidienne : quotient\n9 %/% 4\n\n[1] 2\n\n# Division euclidienne : reste\n9 %% 4\n\n[1] 1\n\n\n\n# Puissance\n2 ^ 5\n\n[1] 32\n\n# Racine carrée\nsqrt(5)\n\n[1] 2.236068\n\n# Log\nlog(2)\n\n[1] 0.6931472\n\n# Exponentielle\nexp(2)\n\n[1] 7.389056\n\n\nL’ordre des opérations suit la convention usuelle:\n\n2 + 5 * (10 - 4)\n\n[1] 32\n\n\n\n\n2.1.3 Vectorisation\nSi on ne pouvait utiliser  qu’en mode calculette peu raffinée, ça ne serait pas un langage très intéressant pour l’analyse de données. L’avantage principal de  est qu’on va pouvoir manipuler des vecteurs, c’est à dire des suites de nombres. On va considérer que les vecteurs sont des suites de nombres ordonnés en une seule colonne:\n\\[\n\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix}\n\\]\net on va appliquer des opérations sur chaque ligne de ces vecteurs. On parle de vectorisation des opérations pour désigner une opération qui s’appliquera de manière automatique à chaque élément de notre vecteur.\nPar exemple, la multiplication est vectorielle par défaut:\n\n5*c(1,20,2)\n\n[1]   5 100  10\n\n\nDe même l’addition, à condition de mettre des vecteurs de taille cohérente:\n\nc(1,20,2) + c(21,2,20)\n\n[1] 22 22 22\n\nc(1,20,2) - 3\n\n[1] -2 17 -1\n\n\n\n\n\n\n\n\nWarning\n\n\n\nSi la taille des vecteurs n’est pas cohérente,  recycle le vecteur le plus petit jusqu’à atteindre la bonne taille\n\nc(1,20,2) - c(1,20)\n\nWarning in c(1, 20, 2) - c(1, 20): longer object length is not a multiple of\nshorter object length\n\n\n[1] 0 0 1"
  },
  {
    "objectID": "exercises/r-base.html#characters",
    "href": "exercises/r-base.html#characters",
    "title": "Découverte des objets de base de ",
    "section": "2.2 Les chaînes de caractères (characters)",
    "text": "2.2 Les chaînes de caractères (characters)\nLes chaînes de caractères (ou strings) sont utilisées pour stocker de l’information textuelle. Plus précisément, elles peuvent stocker tout caractère de type Unicode, ce qui inclut les lettres des différentes langues, mais également la ponctuation, les chiffres, les smileys, etc.\n\n2.2.1 Créer un string\nPour créer une chaine de caractères (string), on peut utiliser de manière indifférente les guillemets ou les apostrophes.\n\n1'mot'\n2\"ça fonctionne aussi\"\n\n\n1\n\nPremière méthode: '\n\n2\n\nDeuxième méthode (préférable): \"\n\n\n\n\n[1] \"mot\"\n[1] \"ça fonctionne aussi\"\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAttention au mélange des deux !\n\nprint('l'apostrophe, quelle catastrophe')\n\nError: &lt;text&gt;:1:10: unexpected symbol\n1: print('l'apostrophe\n             ^\n\n\nLa deuxième apostrophe est comprise comme la fin du string, et  ne sait pas interpréter le reste de la séquence.\nIl faut donc varier en cas de besoin :\n\n1\"l'apostrophe, aucun problème\"\n\n\n1\n\nCette fois, l’apostrophe ' est bien enchassée au sein des guillemets qui délimitent notre string.\n\n\n\n\n[1] \"l'apostrophe, aucun problème\"\n\n\nCela fonctionne également en sens inverse: les guillements sont bien interprétés lorsqu’ils sont entre apostrophes.\n\n'les guillemets, \"aucun problème\"'\n\n[1] \"les guillemets, \\\"aucun problème\\\"\"\n\n\nComme l’illustre la sortie ci-dessus, il est possible de bien définir les caractères spéciaux de cette sorte en les échappant avec des antislashs \\:\n\n1\"les guillemets, \\\"aucun problème\\\"\"\n'l\\'apostrophe, aucun problème'\n\n\n1\n\n\\ permet à  de comprendre que l’apostrophe ou le guillemet fait partie de la chaine de caractère et non de sa délimitation.\n\n\n\n\n[1] \"les guillemets, \\\"aucun problème\\\"\"\n[1] \"l'apostrophe, aucun problème\"\n\n\n\n\n\n\n2.2.2 Quelques fonctions utiles\n propose par défaut un certain nombre de fonctions utiles pour extraire ou transformer des vecteurs textuels. On en découvrira des plus pratiques et plus générales lorsqu’on se focalisera sur les données textuelles et le package stringr.\nLa fonction nchar permet de compter le nombre de caractères d’un string, tous caractères inclus (lettres, chiffres, espaces, ponctuation…).\n\nnchar(\"J'ai 19 charactères\")\n\n[1] 19\n\n\nIl ne faut pas la confondre avec la fonction length. Celle-ci nous donne la longueur du vecteur. Par exemple,\n\nlength(\"J'ai 19 charactères\")\n\n[1] 1\n\n\nest de taille 1 puisqu’on a un seul élément dans notre vecteur. Si on prend un vecteur de plus grande dimension:\n\nlength(c(\"J'ai 19 charactères\", \"pas moi\"))\n\n[1] 2\n\n\nOn retrouve bien le nombre d’éléments de notre vecteur en sortie de length.\nnchar est une opération vectorielle, on peut donc compter la longueur de chaque ligne de notre jeu de données:\n\nnchar(c(\"J'ai 19 charactères\", \"pas moi\"))\n\n[1] 19  7\n\n\nL’un des intérêts des fonctions de base de traitement des données textuelles est la possibilité de remettre en forme nos chaînes de caractères de manière automatique. Par exemple, l’opération la plus simple est de changer la capitalisation de notre texte:\n\n1toupper(c(\"sequence 850\", \"Sequence 850\"))\n2tolower(c(\"SEQuEnce 850\", \"SEQUENCE 850\"))\n\n\n1\n\nMettre en majuscules tout le texte.\n\n2\n\nMettre en minuscules.\n\n\n\n\n[1] \"SEQUENCE 850\" \"SEQUENCE 850\"\n[1] \"sequence 850\" \"sequence 850\"\n\n\nMais on peut aussi nettoyer des chaines textuelles avec quelques fonctions de base :\n\nstrsplit(c(\"une séquence    à séparer\", \"uneautreàséparer\"), split = \" \")\n\n[[1]]\n[1] \"une\"      \"séquence\" \"\"         \"\"         \"\"         \"à\"        \"séparer\" \n\n[[2]]\n[1] \"uneautreàséparer\"\n\n\nA ce stade, la sortie obtenue, avec des [[]] peut vous paraître étrange car nous n’avons pas encore découvert le type list.\nCe type de données n’étant pas forcément pratique pour l’analyse statistique, pour laquelle on préfère des formats comme le vecteur, ce sera beaucoup plus pratique d’utiliser le package stringr pour faire un split.\nOn peut tout à fait découper notre string sur autre chose que les espaces!\n\nstrsplit(c(\"une séquence    à séparer\", \"uneautreàséparer\"), split = \"à\")\n\n[[1]]\n[1] \"une séquence    \" \" séparer\"        \n\n[[2]]\n[1] \"uneautre\" \"séparer\" \n\n\nOn peut concaténer des chaines de caractère ensemble, c’est très pratique. Malheureusement le + ne fonctionne pas en R pour les chaines de caractères (contrairement à Python). Pour effectuer cela on utilise paste ou paste0 (une version moins générale mais qui est pensée pour les concaténations simples):\n\npaste0(\n    \"La première fois qu'Aurélien vit Bérénice,\",\n    \" \",\n    \"il la trouva franchement laide. Elle lui déplut, enfin.\",\n    \" \",\n    \"Il n'aima pas comment elle était habillée.\"\n1)\n\npaste(\n    \"La première fois qu'Aurélien vit Bérénice,\",\n    \"il la trouva franchement laide. Elle lui déplut, enfin.\",\n    \"Il n'aima pas comment elle était habillée.\",\n    sep = \" \"\n2)\n\n\n1\n\nAvec paste0, on concatène en accolant les strings, sans espace.\n\n2\n\nAvec paste, on peut choisir la manière d’accoler les strings, ici en mettant des espaces.\n\n\n\n\n[1] \"La première fois qu'Aurélien vit Bérénice, il la trouva franchement laide. Elle lui déplut, enfin. Il n'aima pas comment elle était habillée.\"\n[1] \"La première fois qu'Aurélien vit Bérénice, il la trouva franchement laide. Elle lui déplut, enfin. Il n'aima pas comment elle était habillée.\"\n\n\nOn peut utiliser les strings comme templates. C’est particulièrement pratique pour automatiquement créer du texte à partir de valeurs issues de nos données. Pour cela on utilise sprintf:\n\nsprintf(\"La première fois qu'%s vit %s\", \"Aurélien\", \"Bérénice\")\n\n[1] \"La première fois qu'Aurélien vit Bérénice\"\n\nsprintf(\"%s et %s font %s\", 2, 2, 2+2)\n\n[1] \"2 et 2 font 4\"\n\n\n%s sert à définir l’endroit où sera collé le texte voulu."
  },
  {
    "objectID": "exercises/r-base.html#logicals",
    "href": "exercises/r-base.html#logicals",
    "title": "Découverte des objets de base de ",
    "section": "2.3 Vecteurs logiques (logicals)",
    "text": "2.3 Vecteurs logiques (logicals)\nEn , les vecteurs logiques sont utilisés pour stocker des valeurs booléennes, c’est-à-dire des valeurs vraies (TRUE) ou fausses (FALSE).\nLes vecteurs logiques sont couramment utilisés pour effectuer des opérations de logique, des filtres de données et des sélections conditionnelles. Nous y reviendrons par la suite, nous les utiliserons fréquemment mais de manière indirecte.\n\n15 &gt; 3\n22 == 2\n30 == (2 - 2)\n41 &lt; 0\n\n\n1\n\nTRUE, car 5 est supérieur à 3.\n\n2\n\nTRUE, car 2 est égal à 2.\n\n3\n\nTRUE, le chainage des opérations est respecté.\n\n4\n\nFALSE, car 1 n’est pas inférieur à 0.\n\n\n\n\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] FALSE\n\n\nOn peut généraliser les comparaisons pour obtenir des vecteurs:\n\nc(2, 4, 6, 8, 10, 1, 3) %% 2 == 0\n\n[1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE\n\n\nOn obtient TRUE pour les nombres pairs, FALSE pour les impairs.\nUtiliser des vecteurs logiques nous permettra, au quotidien, sélectionner des données. Par exemple si on a des données d’âge, on peut ne vouloir garder que les prénoms des adultes. Cela pourra être fait sur le modèle suivant:\n\nc('Pierre', 'Paul', 'François', 'et les autres')[\n    c(25, 3, 61, 17) &gt;= 18\n]\n\n[1] \"Pierre\"   \"François\"\n\n\nNéanmoins nous verrons dans les prochains chapitres comment intégrer ce principe dans une séquence plus générale d’opérations grâce au package dplyr."
  },
  {
    "objectID": "exercises/r-base.html#factors",
    "href": "exercises/r-base.html#factors",
    "title": "Découverte des objets de base de ",
    "section": "2.4 Les facteurs (factors)",
    "text": "2.4 Les facteurs (factors)\nLes facteurs (factors) sont utilisés pour représenter des variables catégorielles, c’est-à-dire des variables qui prennent un nombre fini et prédéterminé de niveaux ou de catégories.\nPour convertir un vecteur numérique ou textuel en vecteur, on utilise la fonction factor:\n\nfactor(\n    c(\"capitale\",\"préfecture\",\"sous-préfecture\",\"préfecture\")\n)\n\n[1] capitale        préfecture      sous-préfecture préfecture     \nLevels: capitale préfecture sous-préfecture\n\nfactor(c(1,10,3))\n\n[1] 1  10 3 \nLevels: 1 3 10\n\n\nLes niveaux d’un facteur sont les différentes catégories ou valeurs possibles que la variable peut prendre. On peut les lister avec la fonction levels\n\n\n[1] \"capitale\"        \"préfecture\"      \"sous-préfecture\"\n\n\nOn peut aussi ordonner ces niveaux si cela a un sens lors de la définition du facteur. Cela implique néanmoins de connaître, a priori nos différents niveaux et les renseigner à  dans l’ordre:\n\n\n[1] capitale        préfecture      sous-préfecture préfecture     \nLevels: capitale &lt; préfecture &lt; sous-préfecture"
  },
  {
    "objectID": "exercises/r-base.html#les-matrices",
    "href": "exercises/r-base.html#les-matrices",
    "title": "Découverte des objets de base de ",
    "section": "7.1 Les matrices",
    "text": "7.1 Les matrices\nLes matrices peuvent être vues comme le prolongement en deux dimensions des vecteurs. Au lieu d’avoir des données sur une seule dimension, on empile des colonnes côte à côte.\n\\[\nX = \\begin{bmatrix}\nx_{11} & x_{12} \\\\\nx_{21} & x_{22} \\\\\n\\end{bmatrix}\n\\]\nNéanmoins, les matrices présentent une limite fondamentale: on ne peut stocker dans une matrice que des éléments de même type. Autrement dit, on aura exclusivement des matrices numériques, des matrices de caractères ou des matrices logiques. Il est impossible de construire une matrice dont certaines variables sont de type numérique (par exemple l’âge des personnes enquêtées) et d’autres de type caractère (par exemple leur secteur d’activité).\nLes matrices ne constituent donc pas un type d’objet susceptible de stocker l’information statistique habituellement mobilisée dans les enquêtes sociales. Le mix des types n’est pas pratique, c’est pour cette raison que les praticiens de l’analyse de données les utilisent peu4.\nOn propose donc un exercice sur les matrices mais on va rapidement passer à des types plus flexibles, plus utiles pour l’analyse de données où les variables sont de type diverses.\n\n\n\n\n\n\nExercice 7\n\n\n\nSoit une matrice:\n\nX &lt;- matrix(letters[1:20], nrow = 4, ncol = 5)\n\n\nSélectionner l’élement le plus à gauche de notre matrice (première ligne, première colonne)\nSélectionner l’ensemble de la première ligne\nSélectionner l’ensemble de la première colonne\nSélectionner les éléments à l’intersection :\n\nDes 2e et 3e ligne\nDes 1ères et 3e colonne\n\n\n\n\nIndice si vous êtes bloqués\n\nAvec un vecteur, on accédait aux positions d’un élément avec X[*]. Avec les matrices le principe est le même mais on ajoute une dimension X[*,*]"
  },
  {
    "objectID": "exercises/r-base.html#les-listes",
    "href": "exercises/r-base.html#les-listes",
    "title": "Découverte des objets de base de ",
    "section": "7.2 Les listes",
    "text": "7.2 Les listes\nLes listes constituent un type d’objet beaucoup plus riche qui permet précisément de rassembler des types d’objets très différents : une liste peut contenir tous les types d’objet (vecteurs numériques, caractères, logiques, matrices, etc.), y compris d’autres listes.\nCette très grande souplesse fait de la liste l’objet de prédilection pour stocker une information complexe et structurée, en particulier les résultats de procédures statistiques complexes (régression, classification, etc.). Pour des données plus structurées, comme le sont les jeux de données, nous allons voir ensuite que nous allons utiliser un type spécial de liste: le dataframe.\n\n\n\nProposition d’illustration du principe des listes avec R par Dall-E-2\n\n\n\n\n\n\n\n\nExercice 8\n\n\n\nVoici une liste illustrant le principe de stockage de données hétérogènes dans un même objet:\n\nAfficher la liste et observer la différence avec l’affichage des objets précédents\nUtiliser la notation [[]] pour accéder au 2e élément de notre liste pour au 2e nombre au sein du dernier élément de notre matrice\nOn peut utiliser des noms pour les éléments de notre liste (c’est d’ailleurs une bonne pratique). Créer un élément nommé communes dans votre liste stockant les données suivantes c('01363', '02644', '03137', '11311')\nCréer un élément departements en extrayant les deux premiers chiffres de votre élément communes\n\n\n\nLorsqu’on utilise des listes, on peut effectuer des opérations sur chaque élément de notre liste. On appelle cela boucler sur notre liste.\n\n\n\n\n\n\n\nExercice 9\n\n\n\nDans cet exercice, nous allons découvrir comment appliquer la même fonction aux éléments de notre liste grâce à lapply.\n\nAvant cela, combien d’éléments comporte le premier niveau de notre liste ?\nCombien d’éléments comportent chaque niveaux de notre liste ?\nCréer un vecteur numérique qui est égal à 1 si typeof de l’élément est “double” et 0 sinon\n\n\n\nSi ?lapply ne vous aide pas\n\nExemple d’utilisation de lapply pour faire la somme dans chaque élément de notre liste\n\nma_liste_nombres &lt;- list(c(1,2), seq(1,10))\nlapply(ma_liste_nombres, sum)\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] 55"
  },
  {
    "objectID": "exercises/r-base.html#les-dataframes",
    "href": "exercises/r-base.html#les-dataframes",
    "title": "Découverte des objets de base de ",
    "section": "7.3 Les dataframes",
    "text": "7.3 Les dataframes\nC’est l’objet central de l’analyse de données avec . Ces objets permettent en effet de représenter sous la forme d’une table (i.e. d’un objet à deux dimensions) des données de nature tant quantitatives (variables numériques) que qualitatives (variables de type caractère ou facteur).\n\n\n\nIllustration du principe du dataframe (empruntée à H. Wickham)\n\n\nVoici par exemple un dataframe:\n\n# Création du data.frame df\ndf &lt;- data.frame(\n  var1 = 1:10,\n  var2 = letters[1:10],\n  var3 = rep(c(TRUE, FALSE), times = 5)\n)\n\nSa structure interne peut être vérifiée avec la fonction str:\n\nstr(df)\n\n'data.frame':   10 obs. of  3 variables:\n $ var1: int  1 2 3 4 5 6 7 8 9 10\n $ var2: chr  \"a\" \"b\" \"c\" \"d\" ...\n $ var3: logi  TRUE FALSE TRUE FALSE TRUE FALSE ...\n\n\nQuand on travaille avec R, l’une des fonctions qu’on utilise le plus est head. Elle permet d’afficher les \\(n\\) premières lignes de notre jeu de données:\n\n\n  var1 var2  var3\n1    1    a  TRUE\n2    2    b FALSE\n3    3    c  TRUE\n4    4    d FALSE\n5    5    e  TRUE\n6    6    f FALSE\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIl est également possible d’utiliser le viewer de RStudio pour afficher des jeux de données.\nAttention cependant, ce viewer peut rencontrer des problèmes de performance et faire planter votre session R quand le jeu de données commence à être d’une taille conséquente.\nJe recommande plutôt de toucher utiliser head ou de sélectionner des lignes aléatoirement avec sample:\n\n\n   var1 var2  var3\n7     7    g  TRUE\n10   10    j FALSE\n9     9    i  TRUE\n\n\n\n\nDu point de vue de sa structure, un data.frame est en réalité une liste dont tous les éléments ont la même longueur : c’est ce qui permet de le représenter sous la forme d’un tableau à deux dimensions.\n\nis.list(df)\n\n[1] TRUE\n\nlapply(df, length)\n\n$var1\n[1] 10\n\n$var2\n[1] 10\n\n$var3\n[1] 10\n\n\nDe ce fait, les data.frame empruntent leurs caractéristiques tantôt aux listes, tantôt aux matrices comme le montre l’exercice suivant:\n\n\n\n\n\n\nExercice 10\n\n\n\n\nVérifier la dimension du dataframe df\nCompter le nombre de lignes et de colonnes de df\nVérifier la longueur (length) de df. Est-ce le comportement d’une matrice ou d’une liste ?\nExtraire l’élement à la 2e ligne, 3e colonne de df. Est-ce le comportement d’indexation d’une matrice ou d’une liste ?\nRécupérer la 3e ligne des variables var1 et var2.\n\n\n\nL’intérêt d’utiliser un data.frame est qu’on peut facilement mettre à jour nos données lors d’une analyse statistique. Les opérations les plus classiques, sur lesquelles nous reviendrons lors du prochain chapitre, sont\n\nCréer une nouvelle colonne à partir des colonnes pré-existantes ;\nSélectionner un sous-échantillon des données correspondant à certaines valeurs observées.\n\nIl existe plusieurs manières de faire référence à une colonne déjà existante d’un dataframe. La plus simple est d’utiliser la structure dataframe$colonne. Cela nous donnera un vecteur et on retombe sur ce format qu’on connaît déjà:\n\nclass(df$var1)\n\n[1] \"integer\"\n\n\n\n\n\n\n\n\nExercice 11\n\n\n\n\nCréer une colonne var4 de notre jeu de données égale au carré de var1\nCréer une colonne var5 de notre jeu de données concaténant les deux premières variables en généralisant le schéma 1=a.\nCréer un dataframe df_small1 pour les lignes où la condition logique var3 est vérifiée\nCréer un dataframe df_small2 pour les lignes où var1 est paire (voir plus haut l’exemple sur la division euclidienne pour le modèle)\n\n\n\nLe prochain chapitre va nous permettre d’aller beaucoup plus loin grâce à l’écosystème du tidyverse et notamment son package phare dplyr. Sans cet ensemble de packages facilitant grandement l’analyse statistique,  ne serait pas devenu l’un des deux langages phares de la statistique."
  },
  {
    "objectID": "exercises/r-base.html#footnotes",
    "href": "exercises/r-base.html#footnotes",
    "title": "Découverte des objets de base de ",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPour installer soi-même RStudio, les instructions sont ici. Néanmoins, dans le cadre de ce cours, vous n’aurez pas besoin de faire l’installation, nous allons utiliser une infrastructure préconfigurée. De cette manière, nous aurons accès au même environnement.↩︎\nCette remarque peut paraître triviale mais, en informatique, elle ne l’est pas. Beaucoup de langages (Python, C) ont une indexation qui commence à 0, comme c’est la convention en algèbre. Cela signifie que le premier élément a un indice 0, le deuxième indice 1 et le dernier un indice \\(n-1\\).↩︎\nLa suite du cours sera l’occasion d’amplement utiliser ce jeu de données.↩︎\nL’objet matrice sera surtout utilisé par les les chercheurs en statistique mathématique ou les spécialistes d’algorithmique qui manipuleront des objets numériques bas niveau.↩︎"
  }
]